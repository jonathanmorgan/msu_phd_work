{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#notes-and-questions\" data-toc-modified-id=\"notes-and-questions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>notes and questions</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---working-folder-paths\" data-toc-modified-id=\"Setup---working-folder-paths-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - working folder paths</a></span></li><li><span><a href=\"#Setup---logging\" data-toc-modified-id=\"Setup---logging-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - logging</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li><li><span><a href=\"#Setup---ExportToContext-instance\" data-toc-modified-id=\"Setup---ExportToContext-instance-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Setup - ExportToContext instance</a></span></li><li><span><a href=\"#Setup---Initialize-LoggingHelper\" data-toc-modified-id=\"Setup---Initialize-LoggingHelper-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Setup - Initialize LoggingHelper</a></span></li></ul></li><li><span><a href=\"#load-sourcenet-data-into-context\" data-toc-modified-id=\"load-sourcenet-data-into-context-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>load sourcenet data into context</a></span><ul class=\"toc-item\"><li><span><a href=\"#Retrieve-Article-instances\" data-toc-modified-id=\"Retrieve-Article-instances-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Retrieve Article instances</a></span></li><li><span><a href=\"#build-load-code-and-unit-tests\" data-toc-modified-id=\"build-load-code-and-unit-tests-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>build load code and unit tests</a></span><ul class=\"toc-item\"><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Testing</a></span></li></ul></li><li><span><a href=\"#Load-data-from-Article-instances\" data-toc-modified-id=\"Load-data-from-Article-instances-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Load data from Article instances</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes and questions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Notes:\n",
    "\n",
    "- probably will need a class that is an Article_Data container - reference to Article_Data, and then all the logic to process the entities and relations contained within.\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Do we want an Identifier Type separate from Entity and Relation identifiers?  I think we do, so we can specify the entity type(s) a given identifier should be used on.\n",
    "\n",
    "    - Created abstract one, and created a concrete entity identifier type.  Will create one for relation identifiers if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:41.109878Z",
     "start_time": "2019-11-26T16:41:41.105613Z"
    }
   },
   "outputs": [],
   "source": [
    "me = \"sourcenet-to-context\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:42.169727Z",
     "start_time": "2019-11-26T16:41:42.166600Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:43.013886Z",
     "start_time": "2019-11-26T16:41:42.943941Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from django.db.models import Avg, Max, Min\n",
    "from django.utils.text import slugify\n",
    "import json\n",
    "import logging\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - working folder paths\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:44.677853Z",
     "start_time": "2019-11-26T16:41:44.668669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/phd_work/analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:45.217253Z",
     "start_time": "2019-11-26T16:41:45.213218Z"
    }
   },
   "outputs": [],
   "source": [
    "# current working folder\n",
    "current_working_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work/analysis\"\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date_string = current_datetime.strftime( \"%Y-%m-%d-%H-%M-%S\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:46.645492Z",
     "start_time": "2019-11-26T16:41:46.638446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging initialized, to /home/jonathanmorgan/work/django/research/work/phd_work/analysis/sourcenet-to-context-2019-11-26-16-41-45.log.txt\n"
     ]
    }
   ],
   "source": [
    "logging_file_name = \"{}/{}-{}.log.txt\".format( current_working_folder, me, current_date_string )\n",
    "logging.basicConfig(\n",
    "    level = logging.INFO,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = logging_file_name,\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")\n",
    "print( \"Logging initialized, to {}\".format( logging_file_name ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:48.978396Z",
     "start_time": "2019-11-26T16:41:48.974380Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:50.638882Z",
     "start_time": "2019-11-26T16:41:49.918429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2019-11-26 16:41:50.635059\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:51.401381Z",
     "start_time": "2019-11-26T16:41:51.332956Z"
    }
   },
   "outputs": [],
   "source": [
    "# context imports\n",
    "from context.models import Entity\n",
    "from context.models import Entity_Identifier_Type\n",
    "from context.models import Entity_Identifier\n",
    "from context.models import Entity_Type\n",
    "\n",
    "# context_text imports\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.export.to_context_base.export_to_context import ExportToContext\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Subject\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - ExportToContext instance\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Make instance, set instance variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:52.728159Z",
     "start_time": "2019-11-26T16:41:52.693407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Entity_Identifier_Type: 4 - article_newsbank_id - Newsbank - ( article )>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_exporter = ExportToContext()\n",
    "\n",
    "# no variables to set, yet...\n",
    "my_exporter.set_article_uuid_id_type_name( ExportToContext.ENTITY_ID_TYPE_ARTICLE_NEWSBANK_ID )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize LoggingHelper\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Create a LoggingHelper instance to use to log debug and also print at the same time.\n",
    "\n",
    "Preconditions: Must be run after Django is initialized, since `python_utilities` is in the django path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:41:54.298425Z",
     "start_time": "2019-11-26T16:41:54.293536Z"
    }
   },
   "outputs": [],
   "source": [
    "# python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# init\n",
    "my_logging_helper = LoggingHelper()\n",
    "my_logging_helper.set_logger_name( me )\n",
    "log_message = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load sourcenet data into context\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "logic:\n",
    "\n",
    "- get all Article_Data created by automated coder, open calais coder type.\n",
    "- for each:\n",
    "\n",
    "    - Article processing:\n",
    "    \n",
    "        - look for article entity in context.  If not created, create one of type \"article\".  Store the sourcenet ID as identifier of type \"article_sourcenet_id\".\n",
    "        - Store the ID and entity reference for the Article (in object?  Should I make a place for the article to hold an Entity ID?).\n",
    "        - check to see if the newspaper has an entity (using its sourcenet ID as the lookup identifier).  If not, create one.\n",
    "\n",
    "    - Person processing:\n",
    "    \n",
    "        - Add all people who are either reporters/authors or subjects to `context` as entities of type \"person\", with identifier of type `person_sourcenet_id` set to their internal django/database \"id\", and with identifier of type `person_open_calais_uuid` set to their OpenCalais ID, if they have one.  If they have any other types of IDs, add them too, untyped.  Once entity is created, store ForeignKey of entity in Person record.\n",
    "        - Author/Reporter processing:\n",
    "\n",
    "            - look for each author's person entity.  If not found, create one.\n",
    "    \n",
    "        - Subject/Source processing:\n",
    "    \n",
    "            - look for a person entity for each subject/source.  If not found, create one.\n",
    "\n",
    "    - Relations - create the following:\n",
    "    \n",
    "        - from newspaper\n",
    "        \n",
    "            - newspaper_reporter - Reporter at a newspaper, evidence of which is byline on an article in that newspaper. FROM newspaper TO person (reporter) THROUGH article.\n",
    "            - newspaper_source - Person quoted in an article published by a newspaper. FROM newspaper TO person (source) THROUGH article.\n",
    "            - newspaper_subject - Subject of an article published in a given newspaper. FROM newspaper TO person (subject, including sources) THROUGH article.\n",
    "            - newspaper_article - Article published in a particular newspaper. FROM newspaper TO article.\n",
    "\n",
    "        - from article\n",
    "\n",
    "            - author - Author/Reporter of an article - FROM article TO reporter.\n",
    "            - subject - Subject of a story. FROM article TO subject person.\n",
    "            - source - Source quoted in an article - FROM article TO source person.\n",
    "\n",
    "        - through article\n",
    "\n",
    "            - article_container - Parent for relations based on entities being mentioned in the same article. To start, just people, but eventually, for example, could also include location.\n",
    "            - mentioned - Mentioned in an article. FROM reporter/author TO subject THROUGH article.\n",
    "            - quoted - The \"from\" person quoted the \"to\" person in a publication. FROM reporter TO source THROUGH article.\n",
    "            - same_article_sources - Sources in the same article, FROM source person TO source person THROUGH article.\n",
    "            - same_article_subjects - Two people who are in a particular article together (includes subjects and sources).\n",
    "            - shared_byline - Shared Byline on an article - joint authors - FROM author TO author THROUGH article.\n",
    "\n",
    "Relations broken out by person type:\n",
    "\n",
    "- For all reporters/authors:\n",
    "\n",
    "    - create a relation of type \"`author`\" between the article's entity (FROM) and the entity of the person (TO) for each author.\n",
    "    - if multiple authors, for each pair of authors, create a relation of type \"`shared_byline`\" between the two (it is undirected), THROUGH the article.\n",
    "\n",
    "- For all subjects, including sources:\n",
    "\n",
    "    - create a relation of type \"`subject`\" between the article's entity (FROM) and the entity of the subject person (TO).\n",
    "    - if multiple subjects, for each pair of subjects, create a relation of type \"`same_article_subjects`\" between the two (it is undirected), THROUGH the article.\n",
    "    - create a relation of type \"`mentioned`\" between each of the article's authors (FROM) and the subject (TO), THROUGH the article.\n",
    "\n",
    "- For all sources\n",
    "\n",
    "    - create a relation of type \"`source`\" between the article's entity and the entity for the source person.\n",
    "    - if multiple sources, for each pair of sources, create a relation of type \"`same_article_sources`\" between the two (it is undirected), THROUGH the article.\n",
    "    - create a relation of type \"`quoted`\" between each of the article's authors (FROM) and the source (TO), THROUGH the article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience methods:\n",
    "\n",
    "- method to find entity - based on type and identifier (accept all the fields that make sense, including optional identifier type instance).\n",
    "- method to find relation - based on type, etc.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- all ties are undirected.\n",
    "- relations can have three foreign keys into Entity - FROM, TO, and THROUGH (for a containing relationship, like the article that included two sources that we are relating)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Article instances\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Before we do anything else, need to be able to pull back all the articles whose data we want to load into the context store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:42:00.549354Z",
     "start_time": "2019-11-26T16:42:00.542158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:42:00.546618 - Loaded automated user: automated, id = 2\n"
     ]
    }
   ],
   "source": [
    "# look for publications that have article data:\n",
    "# - coded by automated coder\n",
    "# - with coder type of \"OpenCalais_REST_API_v2\"\n",
    "\n",
    "# get automated coder\n",
    "automated_coder_user = ContextTextBase.get_automated_coding_user()\n",
    "\n",
    "log_message = \"{} - Loaded automated user: {}, id = {}\".format( datetime.datetime.now(), automated_coder_user, automated_coder_user.id )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T16:42:01.505369Z",
     "start_time": "2019-11-26T16:42:01.310146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43843 articles\n"
     ]
    }
   ],
   "source": [
    "# find articles with Article_Data created by the automated user...\n",
    "article_qs = Article.objects.filter( article_data__coder = automated_coder_user )\n",
    "\n",
    "# ...and specifically coded using OpenCalais V2...\n",
    "article_qs = article_qs.filter( article_data__coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION )\n",
    "\n",
    "# ...and finally, we just want the distinct articles by ID.\n",
    "article_qs = article_qs.order_by( \"id\" ).distinct( \"id\" )\n",
    "\n",
    "# count?\n",
    "article_count = article_qs.count()\n",
    "log_message = \"Found {} articles\".format( article_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build load code and unit tests\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make unit tests to test convenience methods added to the following models, in `context/tests/models/`:\n",
    "\n",
    "- // `Entity_Identifier_Type` - test_Entity_Identifier_Type_model.py\n",
    "- // `Entity_Identifier` - test_Entity_Identifier_model.py\n",
    "- // `Entity` - test_Entity_model.py\n",
    "\n",
    "Also, // move instance creation class methods along with their constants over into \"TestHelper\" from test_Entity_Identifier_model.py, so they can be re-used across test classes.\n",
    "\n",
    "To run: `python manage.py test context.tests`\n",
    "\n",
    "In test data:\n",
    "\n",
    "- article 21925:\n",
    "\n",
    "    - Article_Data: `SELECT * FROM context_text_article_data WHERE article_id = 21925;`\n",
    "\n",
    "TODO:\n",
    "\n",
    "- test_entity_model.py\n",
    "\n",
    "    - test_get_entity_for_identifier\n",
    "\n",
    "- test_export_to_context.py\n",
    "\n",
    "    - test_get_article_uuid_id_type\n",
    "    - test_set_article_uuid_id_type_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Article instances\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now, we actually load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-26T16:42:05.884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In create_q_filter_automated_by_coder_type: automated coder user: 2 - automated\n",
      "----> Processed 100 of 43843 articles at 2019-11-26 16:44:10.194920 ( elapsed: 0:02:04.258806; average: 0:00:01.242588 )\n",
      "----> Processed 200 of 43843 articles at 2019-11-26 16:46:08.333038 ( elapsed: 0:04:02.396924; average: 0:00:01.211985 )\n",
      "----> Processed 300 of 43843 articles at 2019-11-26 16:48:03.126190 ( elapsed: 0:05:57.190076; average: 0:00:01.190634 )\n",
      "----> Processed 400 of 43843 articles at 2019-11-26 16:50:09.831284 ( elapsed: 0:08:03.895170; average: 0:00:01.209738 )\n",
      "----> Processed 500 of 43843 articles at 2019-11-26 16:52:15.175648 ( elapsed: 0:10:09.239534; average: 0:00:01.218479 )\n",
      "----> Processed 600 of 43843 articles at 2019-11-26 16:54:02.125858 ( elapsed: 0:11:56.189744; average: 0:00:01.193650 )\n",
      "----> Processed 700 of 43843 articles at 2019-11-26 16:55:50.575779 ( elapsed: 0:13:44.639665; average: 0:00:01.178057 )\n",
      "----> Processed 800 of 43843 articles at 2019-11-26 16:57:46.909539 ( elapsed: 0:15:40.973425; average: 0:00:01.176217 )\n",
      "----> Processed 900 of 43843 articles at 2019-11-26 17:00:16.328511 ( elapsed: 0:18:10.392397; average: 0:00:01.211547 )\n",
      "----> Processed 1000 of 43843 articles at 2019-11-26 17:02:57.319914 ( elapsed: 0:20:51.383800; average: 0:00:01.251384 )\n",
      "----> Processed 1100 of 43843 articles at 2019-11-26 17:05:19.597141 ( elapsed: 0:23:13.661027; average: 0:00:01.266965 )\n",
      "----> Processed 1200 of 43843 articles at 2019-11-26 17:07:10.695290 ( elapsed: 0:25:04.759176; average: 0:00:01.253966 )\n",
      "----> Processed 1300 of 43843 articles at 2019-11-26 17:08:53.076286 ( elapsed: 0:26:47.140172; average: 0:00:01.236262 )\n",
      "----> Processed 1400 of 43843 articles at 2019-11-26 17:10:38.930465 ( elapsed: 0:28:32.994351; average: 0:00:01.223567 )\n",
      "----> Processed 1500 of 43843 articles at 2019-11-26 17:12:32.446537 ( elapsed: 0:30:26.510423; average: 0:00:01.217674 )\n",
      "----> Processed 1600 of 43843 articles at 2019-11-26 17:14:36.126887 ( elapsed: 0:32:30.190773; average: 0:00:01.218869 )\n",
      "----> Processed 1700 of 43843 articles at 2019-11-26 17:17:30.073742 ( elapsed: 0:35:24.137628; average: 0:00:01.249493 )\n",
      "----> Processed 1800 of 43843 articles at 2019-11-26 17:19:25.695391 ( elapsed: 0:37:19.759277; average: 0:00:01.244311 )\n",
      "----> Processed 1900 of 43843 articles at 2019-11-26 17:21:26.225025 ( elapsed: 0:39:20.288911; average: 0:00:01.242257 )\n",
      "----> Processed 2000 of 43843 articles at 2019-11-26 17:23:17.627725 ( elapsed: 0:41:11.691611; average: 0:00:01.235846 )\n",
      "----> Processed 2100 of 43843 articles at 2019-11-26 17:25:13.942034 ( elapsed: 0:43:08.005920; average: 0:00:01.232384 )\n",
      "----> Processed 2200 of 43843 articles at 2019-11-26 17:27:23.756139 ( elapsed: 0:45:17.820025; average: 0:00:01.235373 )\n",
      "----> Processed 2300 of 43843 articles at 2019-11-26 17:29:07.810023 ( elapsed: 0:47:01.873909; average: 0:00:01.226902 )\n",
      "----> Processed 2400 of 43843 articles at 2019-11-26 17:31:04.676557 ( elapsed: 0:48:58.740443; average: 0:00:01.224475 )\n",
      "----> Processed 2500 of 43843 articles at 2019-11-26 17:32:55.089099 ( elapsed: 0:50:49.152985; average: 0:00:01.219661 )\n",
      "----> Processed 2600 of 43843 articles at 2019-11-26 17:34:59.420708 ( elapsed: 0:52:53.484594; average: 0:00:01.220571 )\n",
      "----> Processed 2700 of 43843 articles at 2019-11-26 17:36:53.421622 ( elapsed: 0:54:47.485508; average: 0:00:01.217587 )\n",
      "----> Processed 2800 of 43843 articles at 2019-11-26 17:38:35.985405 ( elapsed: 0:56:30.049291; average: 0:00:01.210732 )\n",
      "----> Processed 2900 of 43843 articles at 2019-11-26 17:40:33.208870 ( elapsed: 0:58:27.272756; average: 0:00:01.209404 )\n",
      "----> Processed 3000 of 43843 articles at 2019-11-26 17:42:32.830741 ( elapsed: 1:00:26.894627; average: 0:00:01.208965 )\n",
      "----> Processed 3100 of 43843 articles at 2019-11-26 17:46:03.607073 ( elapsed: 1:03:57.670959; average: 0:00:01.237958 )\n",
      "----> Processed 3200 of 43843 articles at 2019-11-26 17:50:09.052286 ( elapsed: 1:08:03.116172; average: 0:00:01.275974 )\n",
      "----> Processed 3300 of 43843 articles at 2019-11-26 17:53:36.330680 ( elapsed: 1:11:30.394566; average: 0:00:01.300120 )\n",
      "----> Processed 3400 of 43843 articles at 2019-11-26 17:57:49.089027 ( elapsed: 1:15:43.152913; average: 0:00:01.336221 )\n",
      "----> Processed 3500 of 43843 articles at 2019-11-26 18:01:44.579324 ( elapsed: 1:19:38.643210; average: 0:00:01.365327 )\n",
      "----> Processed 3600 of 43843 articles at 2019-11-26 18:06:40.386743 ( elapsed: 1:24:34.450629; average: 0:00:01.409570 )\n",
      "----> Processed 3700 of 43843 articles at 2019-11-26 18:10:38.925266 ( elapsed: 1:28:32.989152; average: 0:00:01.435943 )\n",
      "----> Processed 3800 of 43843 articles at 2019-11-26 18:14:46.654699 ( elapsed: 1:32:40.718585; average: 0:00:01.463347 )\n",
      "----> Processed 3900 of 43843 articles at 2019-11-26 18:20:07.782462 ( elapsed: 1:38:01.846348; average: 0:00:01.508166 )\n",
      "----> Processed 4000 of 43843 articles at 2019-11-26 18:23:11.294705 ( elapsed: 1:41:05.358591; average: 0:00:01.516340 )\n",
      "----> Processed 4100 of 43843 articles at 2019-11-26 18:26:44.736837 ( elapsed: 1:44:38.800723; average: 0:00:01.531415 )\n",
      "----> Processed 4200 of 43843 articles at 2019-11-26 18:30:24.397241 ( elapsed: 1:48:18.461127; average: 0:00:01.547253 )\n",
      "----> Processed 4300 of 43843 articles at 2019-11-26 18:34:28.204090 ( elapsed: 1:52:22.267976; average: 0:00:01.567969 )\n",
      "----> Processed 4400 of 43843 articles at 2019-11-26 18:38:04.609245 ( elapsed: 1:55:58.673131; average: 0:00:01.581517 )\n",
      "----> Processed 4500 of 43843 articles at 2019-11-26 18:41:21.110445 ( elapsed: 1:59:15.174331; average: 0:00:01.590039 )\n",
      "----> Processed 4600 of 43843 articles at 2019-11-26 18:45:33.810919 ( elapsed: 2:03:27.874805; average: 0:00:01.610408 )\n",
      "----> Processed 4700 of 43843 articles at 2019-11-26 18:49:06.638649 ( elapsed: 2:07:00.702535; average: 0:00:01.621426 )\n",
      "----> Processed 4800 of 43843 articles at 2019-11-26 18:52:52.406460 ( elapsed: 2:10:46.470346; average: 0:00:01.634681 )\n",
      "----> Processed 4900 of 43843 articles at 2019-11-26 18:56:29.179518 ( elapsed: 2:14:23.243404; average: 0:00:01.645560 )\n",
      "----> Processed 5000 of 43843 articles at 2019-11-26 19:02:13.296841 ( elapsed: 2:20:07.360727; average: 0:00:01.681472 )\n",
      "----> Processed 5100 of 43843 articles at 2019-11-26 19:06:58.625758 ( elapsed: 2:24:52.689644; average: 0:00:01.704449 )\n",
      "----> Processed 5200 of 43843 articles at 2019-11-26 19:11:21.327417 ( elapsed: 2:29:15.391303; average: 0:00:01.722191 )\n",
      "----> Processed 5300 of 43843 articles at 2019-11-26 19:15:36.031445 ( elapsed: 2:33:30.095331; average: 0:00:01.737754 )\n",
      "----> Processed 5400 of 43843 articles at 2019-11-26 19:18:55.019429 ( elapsed: 2:36:49.083315; average: 0:00:01.742423 )\n",
      "----> Processed 5500 of 43843 articles at 2019-11-26 19:22:54.184396 ( elapsed: 2:40:48.248282; average: 0:00:01.754227 )\n",
      "----> Processed 5600 of 43843 articles at 2019-11-26 19:26:59.775733 ( elapsed: 2:44:53.839619; average: 0:00:01.766757 )\n",
      "----> Processed 5700 of 43843 articles at 2019-11-26 19:31:47.284202 ( elapsed: 2:49:41.348088; average: 0:00:01.786201 )\n",
      "----> Processed 5800 of 43843 articles at 2019-11-26 19:34:58.337896 ( elapsed: 2:52:52.401782; average: 0:00:01.788345 )\n",
      "----> Processed 5900 of 43843 articles at 2019-11-26 19:39:04.235011 ( elapsed: 2:56:58.298897; average: 0:00:01.799712 )\n",
      "----> Processed 6000 of 43843 articles at 2019-11-26 19:42:31.286389 ( elapsed: 3:00:25.350275; average: 0:00:01.804225 )\n",
      "----> Processed 6100 of 43843 articles at 2019-11-26 19:46:22.257518 ( elapsed: 3:04:16.321404; average: 0:00:01.812512 )\n",
      "----> Processed 6200 of 43843 articles at 2019-11-26 19:50:38.462080 ( elapsed: 3:08:32.525966; average: 0:00:01.824601 )\n",
      "----> Processed 6300 of 43843 articles at 2019-11-26 19:55:11.230241 ( elapsed: 3:13:05.294127; average: 0:00:01.838936 )\n",
      "----> Processed 6400 of 43843 articles at 2019-11-26 19:59:43.002655 ( elapsed: 3:17:37.066541; average: 0:00:01.852667 )\n",
      "----> Processed 6500 of 43843 articles at 2019-11-26 20:03:41.842053 ( elapsed: 3:21:35.905939; average: 0:00:01.860909 )\n",
      "----> Processed 6600 of 43843 articles at 2019-11-26 20:08:30.770567 ( elapsed: 3:26:24.834453; average: 0:00:01.876490 )\n",
      "----> Processed 6700 of 43843 articles at 2019-11-26 20:12:26.706347 ( elapsed: 3:30:20.770233; average: 0:00:01.883697 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Processed 6800 of 43843 articles at 2019-11-26 20:15:53.821748 ( elapsed: 3:33:47.885634; average: 0:00:01.886454 )\n",
      "----> Processed 6900 of 43843 articles at 2019-11-26 20:19:51.879550 ( elapsed: 3:37:45.943436; average: 0:00:01.893615 )\n",
      "----> Processed 7000 of 43843 articles at 2019-11-26 20:23:44.463678 ( elapsed: 3:41:38.527564; average: 0:00:01.899790 )\n",
      "----> Processed 7100 of 43843 articles at 2019-11-26 20:28:01.227684 ( elapsed: 3:45:55.291570; average: 0:00:01.909196 )\n",
      "----> Processed 7200 of 43843 articles at 2019-11-26 20:34:57.971819 ( elapsed: 3:52:52.035705; average: 0:00:01.940561 )\n",
      "----> Processed 7300 of 43843 articles at 2019-11-26 20:39:36.914506 ( elapsed: 3:57:30.978392; average: 0:00:01.952189 )\n",
      "----> Processed 7400 of 43843 articles at 2019-11-26 20:44:19.426220 ( elapsed: 4:02:13.490106; average: 0:00:01.963985 )\n",
      "----> Processed 7500 of 43843 articles at 2019-11-26 20:48:00.090877 ( elapsed: 4:05:54.154763; average: 0:00:01.967221 )\n",
      "----> Processed 7600 of 43843 articles at 2019-11-26 20:51:57.038899 ( elapsed: 4:09:51.102785; average: 0:00:01.972514 )\n",
      "----> Processed 7700 of 43843 articles at 2019-11-26 20:55:41.641957 ( elapsed: 4:13:35.705843; average: 0:00:01.976066 )\n",
      "----> Processed 7800 of 43843 articles at 2019-11-26 20:59:25.213092 ( elapsed: 4:17:19.276978; average: 0:00:01.979394 )\n",
      "----> Processed 7900 of 43843 articles at 2019-11-26 21:03:08.191502 ( elapsed: 4:21:02.255388; average: 0:00:01.982564 )\n",
      "----> Processed 8000 of 43843 articles at 2019-11-26 21:06:59.082168 ( elapsed: 4:24:53.146054; average: 0:00:01.986643 )\n",
      "----> Processed 8100 of 43843 articles at 2019-11-26 21:10:52.721260 ( elapsed: 4:28:46.785146; average: 0:00:01.990961 )\n",
      "----> Processed 8200 of 43843 articles at 2019-11-26 21:14:56.484004 ( elapsed: 4:32:50.547890; average: 0:00:01.996408 )\n",
      "----> Processed 8300 of 43843 articles at 2019-11-26 21:18:19.326441 ( elapsed: 4:36:13.390327; average: 0:00:01.996794 )\n",
      "----> Processed 8400 of 43843 articles at 2019-11-26 21:21:50.452919 ( elapsed: 4:39:44.516805; average: 0:00:01.998157 )\n",
      "----> Processed 8500 of 43843 articles at 2019-11-26 21:26:47.538497 ( elapsed: 4:44:41.602383; average: 0:00:02.009600 )\n",
      "----> Processed 8600 of 43843 articles at 2019-11-26 21:30:50.051903 ( elapsed: 4:48:44.115789; average: 0:00:02.014432 )\n",
      "----> Processed 8700 of 43843 articles at 2019-11-26 21:34:41.736370 ( elapsed: 4:52:35.800256; average: 0:00:02.017908 )\n",
      "----> Processed 8800 of 43843 articles at 2019-11-26 21:39:23.884606 ( elapsed: 4:57:17.948492; average: 0:00:02.027040 )\n",
      "----> Processed 8900 of 43843 articles at 2019-11-26 21:42:44.253042 ( elapsed: 5:00:38.316928; average: 0:00:02.026777 )\n",
      "----> Processed 9000 of 43843 articles at 2019-11-26 21:45:53.736646 ( elapsed: 5:03:47.800532; average: 0:00:02.025311 )\n",
      "----> Processed 9100 of 43843 articles at 2019-11-26 21:50:09.792514 ( elapsed: 5:08:03.856400; average: 0:00:02.031193 )\n",
      "----> Processed 9200 of 43843 articles at 2019-11-26 21:54:07.344806 ( elapsed: 5:12:01.408692; average: 0:00:02.034936 )\n",
      "----> Processed 9300 of 43843 articles at 2019-11-26 21:57:13.388702 ( elapsed: 5:15:07.452588; average: 0:00:02.033059 )\n",
      "----> Processed 9400 of 43843 articles at 2019-11-26 22:00:45.876494 ( elapsed: 5:18:39.940380; average: 0:00:02.034036 )\n",
      "----> Processed 9500 of 43843 articles at 2019-11-26 22:04:03.418176 ( elapsed: 5:21:57.482062; average: 0:00:02.033419 )\n",
      "----> Processed 9600 of 43843 articles at 2019-11-26 22:07:37.408268 ( elapsed: 5:25:31.472154; average: 0:00:02.034528 )\n",
      "----> Processed 9700 of 43843 articles at 2019-11-26 22:11:04.980134 ( elapsed: 5:28:59.044020; average: 0:00:02.034953 )\n",
      "----> Processed 9800 of 43843 articles at 2019-11-26 22:14:17.763880 ( elapsed: 5:32:11.827766; average: 0:00:02.033860 )\n",
      "----> Processed 9900 of 43843 articles at 2019-11-26 22:17:42.986897 ( elapsed: 5:35:37.050783; average: 0:00:02.034046 )\n",
      "----> Processed 10000 of 43843 articles at 2019-11-26 22:21:16.407191 ( elapsed: 5:39:10.471077; average: 0:00:02.035047 )\n",
      "----> Processed 10100 of 43843 articles at 2019-11-26 22:25:17.089014 ( elapsed: 5:43:11.152900; average: 0:00:02.038728 )\n",
      "----> Processed 10200 of 43843 articles at 2019-11-26 22:30:12.117255 ( elapsed: 5:48:06.181141; average: 0:00:02.047665 )\n",
      "----> Processed 10300 of 43843 articles at 2019-11-26 22:34:53.145336 ( elapsed: 5:52:47.209222; average: 0:00:02.055069 )\n",
      "----> Processed 10400 of 43843 articles at 2019-11-26 22:38:41.760835 ( elapsed: 5:56:35.824721; average: 0:00:02.057291 )\n",
      "----> Processed 10500 of 43843 articles at 2019-11-26 22:42:32.872200 ( elapsed: 6:00:26.936086; average: 0:00:02.059708 )\n",
      "----> Processed 10600 of 43843 articles at 2019-11-26 22:46:00.797512 ( elapsed: 6:03:54.861398; average: 0:00:02.059893 )\n",
      "----> Processed 10700 of 43843 articles at 2019-11-26 22:49:53.775310 ( elapsed: 6:07:47.839196; average: 0:00:02.062415 )\n",
      "----> Processed 10800 of 43843 articles at 2019-11-26 22:54:15.244116 ( elapsed: 6:12:09.308002; average: 0:00:02.067529 )\n",
      "----> Processed 10900 of 43843 articles at 2019-11-26 22:58:25.720434 ( elapsed: 6:16:19.784320; average: 0:00:02.071540 )\n",
      "----> Processed 11000 of 43843 articles at 2019-11-26 23:02:12.470261 ( elapsed: 6:20:06.534147; average: 0:00:02.073321 )\n",
      "----> Processed 11100 of 43843 articles at 2019-11-26 23:06:51.371137 ( elapsed: 6:24:45.435023; average: 0:00:02.079769 )\n",
      "----> Processed 11200 of 43843 articles at 2019-11-26 23:11:47.402795 ( elapsed: 6:29:41.466681; average: 0:00:02.087631 )\n",
      "----> Processed 11300 of 43843 articles at 2019-11-26 23:15:31.389333 ( elapsed: 6:33:25.453219; average: 0:00:02.088978 )\n",
      "----> Processed 11400 of 43843 articles at 2019-11-26 23:19:08.762900 ( elapsed: 6:37:02.826786; average: 0:00:02.089722 )\n",
      "----> Processed 11500 of 43843 articles at 2019-11-26 23:23:26.235526 ( elapsed: 6:41:20.299412; average: 0:00:02.093939 )\n",
      "----> Processed 11600 of 43843 articles at 2019-11-26 23:27:02.125713 ( elapsed: 6:44:56.189599; average: 0:00:02.094499 )\n",
      "----> Processed 11700 of 43843 articles at 2019-11-26 23:30:46.137980 ( elapsed: 6:48:40.201866; average: 0:00:02.095744 )\n",
      "----> Processed 11800 of 43843 articles at 2019-11-26 23:35:14.646216 ( elapsed: 6:53:08.710102; average: 0:00:02.100738 )\n",
      "----> Processed 11900 of 43843 articles at 2019-11-26 23:38:38.622314 ( elapsed: 6:56:32.686200; average: 0:00:02.100226 )\n",
      "----> Processed 12000 of 43843 articles at 2019-11-26 23:41:45.688316 ( elapsed: 6:59:39.752202; average: 0:00:02.098313 )\n",
      "----> Processed 12100 of 43843 articles at 2019-11-26 23:46:28.160572 ( elapsed: 7:04:22.224458; average: 0:00:02.104316 )\n",
      "----> Processed 12200 of 43843 articles at 2019-11-26 23:50:30.426148 ( elapsed: 7:08:24.490034; average: 0:00:02.106925 )\n",
      "----> Processed 12300 of 43843 articles at 2019-11-26 23:54:12.358100 ( elapsed: 7:12:06.421986; average: 0:00:02.107839 )\n",
      "----> Processed 12400 of 43843 articles at 2019-11-26 23:58:21.640777 ( elapsed: 7:16:15.704663; average: 0:00:02.110944 )\n",
      "----> Processed 12500 of 43843 articles at 2019-11-27 00:02:14.667693 ( elapsed: 7:20:08.731579; average: 0:00:02.112699 )\n",
      "----> Processed 12600 of 43843 articles at 2019-11-27 00:05:53.094748 ( elapsed: 7:23:47.158634; average: 0:00:02.113267 )\n",
      "----> Processed 12700 of 43843 articles at 2019-11-27 00:09:35.872550 ( elapsed: 7:27:29.936436; average: 0:00:02.114168 )\n",
      "----> Processed 12800 of 43843 articles at 2019-11-27 00:14:04.850503 ( elapsed: 7:31:58.914389; average: 0:00:02.118665 )\n",
      "----> Processed 12900 of 43843 articles at 2019-11-27 00:17:50.002286 ( elapsed: 7:35:44.066172; average: 0:00:02.119695 )\n",
      "----> Processed 13000 of 43843 articles at 2019-11-27 00:21:34.035874 ( elapsed: 7:39:28.099760; average: 0:00:02.120623 )\n",
      "----> Processed 13100 of 43843 articles at 2019-11-27 00:25:05.922711 ( elapsed: 7:42:59.986597; average: 0:00:02.120610 )\n",
      "----> Processed 13200 of 43843 articles at 2019-11-27 00:29:56.381665 ( elapsed: 7:47:50.445551; average: 0:00:02.126549 )\n",
      "----> Processed 13300 of 43843 articles at 2019-11-27 00:34:07.394497 ( elapsed: 7:52:01.458383; average: 0:00:02.129433 )\n",
      "----> Processed 13400 of 43843 articles at 2019-11-27 00:37:45.895880 ( elapsed: 7:55:39.959766; average: 0:00:02.129848 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Processed 13500 of 43843 articles at 2019-11-27 00:41:51.046239 ( elapsed: 7:59:45.110125; average: 0:00:02.132230 )\n",
      "----> Processed 13600 of 43843 articles at 2019-11-27 00:45:35.271025 ( elapsed: 8:03:29.334911; average: 0:00:02.133039 )\n",
      "----> Processed 13700 of 43843 articles at 2019-11-27 00:49:50.928313 ( elapsed: 8:07:44.992199; average: 0:00:02.136131 )\n",
      "----> Processed 13800 of 43843 articles at 2019-11-27 00:54:11.054125 ( elapsed: 8:12:05.118011; average: 0:00:02.139501 )\n",
      "----> Processed 13900 of 43843 articles at 2019-11-27 00:58:14.435663 ( elapsed: 8:16:08.499549; average: 0:00:02.141619 )\n",
      "----> Processed 14000 of 43843 articles at 2019-11-27 01:01:54.309626 ( elapsed: 8:19:48.373512; average: 0:00:02.142027 )\n",
      "----> Processed 14100 of 43843 articles at 2019-11-27 01:04:58.391259 ( elapsed: 8:22:52.455145; average: 0:00:02.139890 )\n",
      "----> Processed 14200 of 43843 articles at 2019-11-27 01:09:26.276984 ( elapsed: 8:27:20.340870; average: 0:00:02.143686 )\n",
      "----> Processed 14300 of 43843 articles at 2019-11-27 01:13:55.022022 ( elapsed: 8:31:49.085908; average: 0:00:02.147489 )\n",
      "----> Processed 14400 of 43843 articles at 2019-11-27 01:17:45.661921 ( elapsed: 8:35:39.725807; average: 0:00:02.148592 )\n",
      "----> Processed 14500 of 43843 articles at 2019-11-27 01:21:38.213015 ( elapsed: 8:39:32.276901; average: 0:00:02.149812 )\n",
      "----> Processed 14600 of 43843 articles at 2019-11-27 01:25:56.375686 ( elapsed: 8:43:50.439572; average: 0:00:02.152770 )\n",
      "----> Processed 14700 of 43843 articles at 2019-11-27 01:30:11.589568 ( elapsed: 8:48:05.653454; average: 0:00:02.155487 )\n",
      "----> Processed 14800 of 43843 articles at 2019-11-27 01:33:55.276517 ( elapsed: 8:51:49.340403; average: 0:00:02.156037 )\n",
      "----> Processed 14900 of 43843 articles at 2019-11-27 01:38:00.181971 ( elapsed: 8:55:54.245857; average: 0:00:02.158003 )\n",
      "----> Processed 15000 of 43843 articles at 2019-11-27 01:42:10.083333 ( elapsed: 9:00:04.147219; average: 0:00:02.160276 )\n",
      "----> Processed 15100 of 43843 articles at 2019-11-27 01:47:10.002962 ( elapsed: 9:05:04.066848; average: 0:00:02.165832 )\n",
      "----> Processed 15200 of 43843 articles at 2019-11-27 01:51:49.709727 ( elapsed: 9:09:43.773613; average: 0:00:02.169985 )\n",
      "----> Processed 15300 of 43843 articles at 2019-11-27 01:56:35.455594 ( elapsed: 9:14:29.519480; average: 0:00:02.174478 )\n",
      "----> Processed 15400 of 43843 articles at 2019-11-27 02:00:50.784525 ( elapsed: 9:18:44.848411; average: 0:00:02.176938 )\n",
      "----> Processed 15500 of 43843 articles at 2019-11-27 02:04:44.392085 ( elapsed: 9:22:38.455971; average: 0:00:02.177965 )\n",
      "----> Processed 15600 of 43843 articles at 2019-11-27 02:08:22.316324 ( elapsed: 9:26:16.380210; average: 0:00:02.177973 )\n",
      "----> Processed 15700 of 43843 articles at 2019-11-27 02:12:06.030867 ( elapsed: 9:30:00.094753; average: 0:00:02.178350 )\n",
      "----> Processed 15800 of 43843 articles at 2019-11-27 02:16:03.641286 ( elapsed: 9:33:57.705172; average: 0:00:02.179602 )\n",
      "----> Processed 15900 of 43843 articles at 2019-11-27 02:20:25.096026 ( elapsed: 9:38:19.159912; average: 0:00:02.182337 )\n",
      "----> Processed 16000 of 43843 articles at 2019-11-27 02:23:48.298504 ( elapsed: 9:41:42.362390; average: 0:00:02.181398 )\n",
      "----> Processed 16100 of 43843 articles at 2019-11-27 02:27:14.545662 ( elapsed: 9:45:08.609548; average: 0:00:02.180659 )\n",
      "----> Processed 16200 of 43843 articles at 2019-11-27 02:31:22.213692 ( elapsed: 9:49:16.277578; average: 0:00:02.182486 )\n",
      "----> Processed 16300 of 43843 articles at 2019-11-27 02:35:09.195290 ( elapsed: 9:53:03.259176; average: 0:00:02.183022 )\n",
      "----> Processed 16400 of 43843 articles at 2019-11-27 02:38:38.486632 ( elapsed: 9:56:32.550518; average: 0:00:02.182473 )\n",
      "----> Processed 16500 of 43843 articles at 2019-11-27 02:42:45.835533 ( elapsed: 10:00:39.899419; average: 0:00:02.184236 )\n",
      "----> Processed 16600 of 43843 articles at 2019-11-27 02:46:31.575700 ( elapsed: 10:04:25.639586; average: 0:00:02.184677 )\n",
      "----> Processed 16700 of 43843 articles at 2019-11-27 02:50:52.386802 ( elapsed: 10:08:46.450688; average: 0:00:02.187213 )\n",
      "----> Processed 16800 of 43843 articles at 2019-11-27 02:55:04.258980 ( elapsed: 10:12:58.322866; average: 0:00:02.189186 )\n",
      "----> Processed 16900 of 43843 articles at 2019-11-27 02:59:37.667746 ( elapsed: 10:17:31.731632; average: 0:00:02.192410 )\n",
      "----> Processed 17000 of 43843 articles at 2019-11-27 03:03:14.618819 ( elapsed: 10:21:08.682705; average: 0:00:02.192275 )\n",
      "----> Processed 17100 of 43843 articles at 2019-11-27 03:06:51.036332 ( elapsed: 10:24:45.100218; average: 0:00:02.192111 )\n",
      "----> Processed 17200 of 43843 articles at 2019-11-27 03:10:23.931001 ( elapsed: 10:28:17.994887; average: 0:00:02.191744 )\n",
      "----> Processed 17300 of 43843 articles at 2019-11-27 03:16:08.681218 ( elapsed: 10:34:02.745104; average: 0:00:02.199003 )\n",
      "----> Processed 17400 of 43843 articles at 2019-11-27 03:21:12.832410 ( elapsed: 10:39:06.896296; average: 0:00:02.203845 )\n",
      "----> Processed 17500 of 43843 articles at 2019-11-27 03:25:00.748969 ( elapsed: 10:42:54.812855; average: 0:00:02.204275 )\n",
      "----> Processed 17600 of 43843 articles at 2019-11-27 03:29:27.973992 ( elapsed: 10:47:22.037878; average: 0:00:02.206934 )\n",
      "----> Processed 17700 of 43843 articles at 2019-11-27 03:34:01.024636 ( elapsed: 10:51:55.088522; average: 0:00:02.209892 )\n",
      "----> Processed 17800 of 43843 articles at 2019-11-27 03:37:50.531022 ( elapsed: 10:55:44.594908; average: 0:00:02.210371 )\n",
      "----> Processed 17900 of 43843 articles at 2019-11-27 03:41:47.996824 ( elapsed: 10:59:42.060710; average: 0:00:02.211288 )\n",
      "----> Processed 18000 of 43843 articles at 2019-11-27 03:45:44.236004 ( elapsed: 11:03:38.299890; average: 0:00:02.212128 )\n",
      "----> Processed 18100 of 43843 articles at 2019-11-27 03:50:04.870308 ( elapsed: 11:07:58.934194; average: 0:00:02.214306 )\n",
      "----> Processed 18200 of 43843 articles at 2019-11-27 03:54:13.788238 ( elapsed: 11:12:07.852124; average: 0:00:02.215816 )\n",
      "----> Processed 18300 of 43843 articles at 2019-11-27 03:58:12.815664 ( elapsed: 11:16:06.879550; average: 0:00:02.216769 )\n",
      "----> Processed 18400 of 43843 articles at 2019-11-27 04:02:21.655507 ( elapsed: 11:20:15.719393; average: 0:00:02.218246 )\n",
      "----> Processed 18500 of 43843 articles at 2019-11-27 04:06:10.486413 ( elapsed: 11:24:04.550299; average: 0:00:02.218624 )\n",
      "----> Processed 18600 of 43843 articles at 2019-11-27 04:10:08.969193 ( elapsed: 11:28:03.033079; average: 0:00:02.219518 )\n",
      "----> Processed 18700 of 43843 articles at 2019-11-27 04:13:57.605429 ( elapsed: 11:31:51.669315; average: 0:00:02.219875 )\n",
      "----> Processed 18800 of 43843 articles at 2019-11-27 04:17:18.406513 ( elapsed: 11:35:12.470399; average: 0:00:02.218748 )\n",
      "----> Processed 18900 of 43843 articles at 2019-11-27 04:20:55.415985 ( elapsed: 11:38:49.479871; average: 0:00:02.218491 )\n",
      "----> Processed 19000 of 43843 articles at 2019-11-27 04:24:24.664850 ( elapsed: 11:42:18.728736; average: 0:00:02.217828 )\n",
      "----> Processed 19100 of 43843 articles at 2019-11-27 04:28:37.008651 ( elapsed: 11:46:31.072537; average: 0:00:02.219428 )\n",
      "----> Processed 19200 of 43843 articles at 2019-11-27 04:32:51.417227 ( elapsed: 11:50:45.481113; average: 0:00:02.221119 )\n",
      "----> Processed 19300 of 43843 articles at 2019-11-27 04:36:49.809620 ( elapsed: 11:54:43.873506; average: 0:00:02.221962 )\n"
     ]
    }
   ],
   "source": [
    "result = my_exporter.process_articles( article_qs )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
