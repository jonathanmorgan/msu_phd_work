{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#notes-and-questions\" data-toc-modified-id=\"notes-and-questions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>notes and questions</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---working-folder-paths\" data-toc-modified-id=\"Setup---working-folder-paths-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - working folder paths</a></span></li><li><span><a href=\"#Setup---logging\" data-toc-modified-id=\"Setup---logging-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - logging</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li><li><span><a href=\"#Setup---Initialize-LoggingHelper\" data-toc-modified-id=\"Setup---Initialize-LoggingHelper-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Setup - Initialize LoggingHelper</a></span></li></ul></li><li><span><a href=\"#Render-network-data\" data-toc-modified-id=\"Render-network-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Render network data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Specify-filter-criteria\" data-toc-modified-id=\"Specify-filter-criteria-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Specify filter criteria</a></span><ul class=\"toc-item\"><li><span><a href=\"#Old-filter-criteria\" data-toc-modified-id=\"Old-filter-criteria-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Old filter criteria</a></span></li><li><span><a href=\"#JSON-files-of-filter-criteria-for-just-automated-coding\" data-toc-modified-id=\"JSON-files-of-filter-criteria-for-just-automated-coding-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>JSON files of filter criteria for just automated coding</a></span></li></ul></li></ul></li><li><span><a href=\"#Network-output\" data-toc-modified-id=\"Network-output-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Network output</a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-output---sourcenet-logic\" data-toc-modified-id=\"Network-output---sourcenet-logic-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Network output - sourcenet logic</a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-output---sourcenet-logic---NetworkOutput\" data-toc-modified-id=\"Network-output---sourcenet-logic---NetworkOutput-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Network output - sourcenet logic - NetworkOutput</a></span></li><li><span><a href=\"#Network-output---sourcenet-logic---NetworkDataOutput\" data-toc-modified-id=\"Network-output---sourcenet-logic---NetworkDataOutput-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Network output - sourcenet logic - NetworkDataOutput</a></span></li></ul></li><li><span><a href=\"#Network-output---context-logic\" data-toc-modified-id=\"Network-output---context-logic-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Network output - context logic</a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-output---context-logic---NetworkOutput\" data-toc-modified-id=\"Network-output---context-logic---NetworkOutput-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Network output - context logic - NetworkOutput</a></span></li><li><span><a href=\"#Network-output---context-logic---NetworkDataOutput\" data-toc-modified-id=\"Network-output---context-logic---NetworkDataOutput-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Network output - context logic - NetworkDataOutput</a></span></li></ul></li><li><span><a href=\"#Context-network-output-test-code\" data-toc-modified-id=\"Context-network-output-test-code-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Context network output test code</a></span></li></ul></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-data-creation-TODO\" data-toc-modified-id=\"Network-data-creation-TODO-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Network data creation TODO</a></span></li><li><span><a href=\"#general-TODO\" data-toc-modified-id=\"general-TODO-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>general TODO</a></span></li></ul></li><li><span><a href=\"#DONE\" data-toc-modified-id=\"DONE-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>DONE</a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-data-creation-TODO---DONE\" data-toc-modified-id=\"Network-data-creation-TODO---DONE-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Network data creation TODO - DONE</a></span></li><li><span><a href=\"#general-TODO-DONE\" data-toc-modified-id=\"general-TODO-DONE-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>general TODO DONE</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes and questions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Notes:\n",
    "\n",
    "- probably will need a class that is an Article_Data container - reference to Article_Data, and then all the logic to process the entities and relations contained within.\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Do we want an Identifier Type separate from Entity and Relation identifiers?  I think we do, so we can specify the entity type(s) a given identifier should be used on.\n",
    "\n",
    "    - Created abstract one, and created a concrete entity identifier type.  Will create one for relation identifiers if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.770643Z",
     "start_time": "2020-01-08T20:00:42.766374Z"
    }
   },
   "outputs": [],
   "source": [
    "me = \"render-context-networks-dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.777062Z",
     "start_time": "2020-01-08T20:00:42.773211Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.863519Z",
     "start_time": "2020-01-08T20:00:42.780729Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from django.db.models import Avg, Max, Min, Q\n",
    "from django.utils.text import slugify\n",
    "import json\n",
    "import logging\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - working folder paths\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.880047Z",
     "start_time": "2020-01-08T20:00:42.865779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/phd_work/analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.885966Z",
     "start_time": "2020-01-08T20:00:42.882010Z"
    }
   },
   "outputs": [],
   "source": [
    "# current working folder\n",
    "current_working_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work/analysis\"\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date_string = current_datetime.strftime( \"%Y-%m-%d-%H-%M-%S\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.895129Z",
     "start_time": "2020-01-08T20:00:42.888540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging initialized, to /home/jonathanmorgan/work/django/research/work/phd_work/analysis/logs/render-context-networks-dev-2020-01-08-20-00-42.log.txt\n"
     ]
    }
   ],
   "source": [
    "logging_file_name = \"{}/logs/{}-{}.log.txt\".format( current_working_folder, me, current_date_string )\n",
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = logging_file_name,\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")\n",
    "print( \"Logging initialized, to {}\".format( logging_file_name ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:42.903660Z",
     "start_time": "2020-01-08T20:00:42.898876Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:43.713834Z",
     "start_time": "2020-01-08T20:00:42.905921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2020-01-08 20:00:43.710888\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:43.794228Z",
     "start_time": "2020-01-08T20:00:43.716022Z"
    }
   },
   "outputs": [],
   "source": [
    "# context imports\n",
    "from context.export.network.filter_spec import FilterSpec\n",
    "from context.export.network.network_data_request import NetworkDataRequest\n",
    "from context.export.network.network_output import NetworkOutput\n",
    "from context.models import Entity\n",
    "from context.models import Entity_Identifier_Type\n",
    "from context.models import Entity_Identifier\n",
    "from context.models import Entity_Relation\n",
    "from context.models import Entity_Type\n",
    "from context.tests.export.network.test_helper import TestHelper\n",
    "\n",
    "# context_text imports\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.export.to_context_base.export_to_context import ExportToContext\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Subject\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize LoggingHelper\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Create a LoggingHelper instance to use to log debug and also print at the same time.\n",
    "\n",
    "Preconditions: Must be run after Django is initialized, since `python_utilities` is in the django path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:43.805636Z",
     "start_time": "2020-01-08T20:00:43.796456Z"
    }
   },
   "outputs": [],
   "source": [
    "# python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# init\n",
    "my_logging_helper = LoggingHelper()\n",
    "my_logging_helper.set_logger_name( me )\n",
    "log_message = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render network data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now, we need to render out our network data from context, so we can then test it out and make sure we are getting the same answers we got from the old way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify filter criteria\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First step is to translate the filter criteria for nodes and ties from the existing admin for the querying context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old filter criteria\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Configuration of [Network Builder](https://research.local/research/context/text/output/network), from [methods-network_analysis-create_network_data.ipynb](../methods/network_analysis/methods-network_analysis-create_network_data.ipynb):\n",
    "\n",
    "* Configuration to generate network files for prelim:\n",
    "\n",
    "    * Config of \"Select Articles\" - **fields in bold** need to be changed from default values:\n",
    "\n",
    "        * **`Start date (YYYY-MM-DD):`** 2009-12-01\n",
    "        * **`End date (YYYY-MM-DD):`** 2009-12-31\n",
    "        * `Fancy date range:` - Empty.\n",
    "        * **`Publications:`** \"Grand Rapids Press, The\"\n",
    "        * `Coders:` None selected.\n",
    "        * **`Coder IDs to include, in order of highest to lowest priority:`**\n",
    "\n",
    "            * for human sample: 13,8,9,10\n",
    "            * for automated: 2\n",
    "\n",
    "        * **if automated**: `Article_Data coder_type Filter Type` and `coder_type 'Value In' List (comma-delimited):`\n",
    "        \n",
    "            * only for coder \"automated\" (2), for now.\n",
    "            * use the coder_type filter fields to filter automatically coded Article_Data on coder type if you have tried different automated coder types:\n",
    "           \n",
    "                * **`Article_Data coder_type Filter Type:`** - `Just automated`\n",
    "                * **`coder_type 'Value In' List (comma-delimited):`** - Enter the coder types you want included.  Examples:\n",
    "                \n",
    "                    * OpenCalais v2: \"OpenCalais_REST_API_v2\"\n",
    "        \n",
    "        * `Topics`: None selected.\n",
    "        * **`Article Tag List (comma-delimited):`** - \"grp_month\"\n",
    "        * `Unique Identifier List (comma-delimited):` - Empty.\n",
    "        * **`Allow duplicate articles:`** - \"No\"\n",
    "    \n",
    "    * Configure \"Network Settings\" - **fields in bold** need to be changed from default values:\n",
    "        \n",
    "        * `relations - Include source contact types` - All selected.\n",
    "        * `relations - Include source capacities:` - None selected.\n",
    "        * `relations - Exclude source capacities:` - None selected.\n",
    "        * **`Download as File?`** - \"Yes\"\n",
    "        * `Include render details?` - \"No\"\n",
    "        * **`Data Format:`** - \"Tab-Delimited Matrix\"\n",
    "        * **`Data Output Type:`** - \"Network + Attribute Columns\"\n",
    "        * `Network Label:` - Empty.\n",
    "        * **`Include Headers:`** - \"Yes\"\n",
    "    \n",
    "    * Config of \"Select People\" - **fields in bold** need to be changed from default values:\n",
    "        \n",
    "        * _NOTE: This will be the same for all networks you want to compare (different weeks within a month, compared to the whole month, for instance). For each, get people from articles that are filtered to include all people used by either human or automated, and all the days covered by any of the networks you want to compare.  This means you'll have the same dimensions of network (same set of nodes/people) regardless of the particular network you are generating, allowing the matrices that result to be compared._\n",
    "        * **`Person Query Type:`** - \"Custom, defined below\"\n",
    "        * **`People from (YYYY-MM-DD):`** - 2009-12-01\n",
    "        * **`People to (YYYY-MM-DD):`** - 2009-12-31\n",
    "        * `Fancy person date range:` - Empty.\n",
    "        * **`Person publications:`** - \"Grand Rapids Press, The\"\n",
    "        * **`Person coders:`** - \"automated\", \"minnesota1\", \"minnesota2\", \"minnesota3\", \"ground_truth\"\n",
    "        * `Coder IDs to include, in order of highest to lowest priority:` - Empty.\n",
    "        * **`Article_Data coder_type Filter Type` and `coder_type 'Value In' List (comma-delimited):`**\n",
    "            \n",
    "            * _NOTE: not just for automated - since this includes all coders, automated and human, you need to always specify the coder type filter if you need it for automated network._\n",
    "            * use the coder_type filter fields to filter automatically coded Article_Data on coder type if you have tried different automated coder types:\n",
    "            \n",
    "                * **`Article_Data coder_type Filter Type:`** - `Just automated`\n",
    "                * **`coder_type 'Value In' List (comma-delimited):`** - Enter the coder types you want included.  Examples:\n",
    "                \n",
    "                    * OpenCalais v2: \"OpenCalais_REST_API_v2\"\n",
    "        \n",
    "        * `Person Topics`: None\n",
    "        * **`Article Tag List (comma-delimited):`** - \"grp_month\"\n",
    "        * `Unique Identifier List (comma-delimited):` - Empty.\n",
    "        * **`Person allow duplicate articles:`** - \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON files of filter criteria for just automated coding\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Below is a JSON file that is just the automated coding for the month from 2009-12-01 through 2009-12-31.  Just about all of the complexity of the original screens is possible here, as long as you loaded the entities and ties and all of the needed traits, including some way of adding tags..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    {\n",
    "        \"output_specification\": {\n",
    "            \"output_type\": \"file\",\n",
    "            \"output_file_path\": \"./NetworkDataRequest_test_output.txt\",\n",
    "            \"output_format\": \"TSV_matrix\",\n",
    "            \"output_structure\": \"both_trait_columns\",\n",
    "            \"output_include_column_headers\": true\n",
    "        },\n",
    "        \"relation_selection\": {\n",
    "            \"relation_type_slug_filter_combine_type\": \"AND\",\n",
    "            \"relation_type_slug_filters\": [\n",
    "                {\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ \"mentioned\", \"qouted\", \"shared_byline\" ]\n",
    "                }\n",
    "            ],\n",
    "            \"relation_trait_filter_combine_type\": \"AND\",\n",
    "            \"relation_trait_filters\": [\n",
    "                {\n",
    "                    \"name\": \"pub_date\",\n",
    "                    \"data_type\": \"date\",\n",
    "                    \"comparison_type\": \"in_range\",\n",
    "                    \"value_from\": \"2009-12-01\",\n",
    "                    \"value_to\": \"2009-12-31\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"sourcenet-coder-User-username\",\n",
    "                    \"data_type\": \"string\",\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ \"automated\" ]\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"coder_type\",\n",
    "                    \"data_type\": \"string\",\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ \"OpenCalais_REST_API_v2\" ]\n",
    "                }\n",
    "            ],\n",
    "            \"entity_type_slug_filter_combine_type\": \"AND\",\n",
    "            \"entity_type_slug_filters\": [\n",
    "                {\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ \"person\" ],\n",
    "                    \"relation_roles_list\": [ \"FROM\" ]\n",
    "                },\n",
    "                {\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ \"person\" ],\n",
    "                    \"relation_roles_list\": [ \"TO\" ]\n",
    "                },\n",
    "                {\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ \"article\" ],\n",
    "                    \"relation_roles_list\": [ \"THROUGH\" ]\n",
    "                }            \n",
    "            ],\n",
    "            \"entity_trait_filter_combine_type\": \"AND\",\n",
    "            \"entity_trait_filters\": [\n",
    "                {\n",
    "                    \"name\": \"sourcenet-Newspaper-ID\",\n",
    "                    \"data_type\": \"int\",\n",
    "                    \"comparison_type\": \"includes\",\n",
    "                    \"value_list\": [ 1 ],\n",
    "                    \"relation_roles_list\": [ \"THROUGH\" ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network output\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Convert code from using Article_Data to derive ties to just loop over Entity_Relation instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network output - sourcenet logic\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network output - sourcenet logic - NetworkOutput\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "- NetworkOutput.render_network_data( query_set_IN )\n",
    "\n",
    "    - accepts Article_Data QuerySet.\n",
    "    - create person dictionary - self.create_person_dict()\n",
    "    \n",
    "        - retrieve Article_Data QuerySet to traverse to pull in all authors and subjects - self.create_person_query_set()\n",
    "        \n",
    "            - if ALL, return all Article_Data\n",
    "            - if type of articles, retrieve just those specified as being used for ties - self.create_person_query_set()\n",
    "            - if type of custom, retrieve Article_Data to match custom person lookup parameters - self.create_query_set( NetworkOutput.PARAM_PERSON_PREFIX )\n",
    "            \n",
    "        - for each Article_Data:\n",
    "        \n",
    "            - retrieve author and source QuerySets.\n",
    "            - for each, call self.add_people_to_dict() on the QuerySet.\n",
    "            \n",
    "                - for each person, retrieve person instance and ID, add to dictionary, storing instance as value if store_person_IN == True.\n",
    "                \n",
    "        - return dictionary into \"person_dictionary\".\n",
    "    \n",
    "    - get NetworkDataOutput (NDO) instance - self.get_NDO_instance()\n",
    "    - initialize NDO\n",
    "    \n",
    "        - NDO.set_query_set( query_set_IN )\n",
    "        - NDO.set_person_dictionary( person_dictionary )\n",
    "        - initialize from parameters: NDO.initialize_from_params()\n",
    "        \n",
    "    - render - NDO.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network output - sourcenet logic - NetworkDataOutput\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "- NetworkDataOutput.render()\n",
    "\n",
    "    - get query_set and person_dictionary.\n",
    "    - create ties\n",
    "\n",
    "        - loop over query_set:\n",
    "        \n",
    "            - check if authors.  If none, move on.\n",
    "            - if authors:\n",
    "            \n",
    "                - retrieve author and sources QuerySets from Article_Data\n",
    "                - process author relations (shared byline and qouted): `self.process_author_relations( author_qs, source_qs )`\n",
    "                \n",
    "                    - makes list of author IDs in Article_Data by building dictionary that maps author person ID to author Person instance, then getting `.keys()`.\n",
    "                    - loops over authors:\n",
    "                    \n",
    "                        - for each, pop from dictionary, make relation to all authors remaining in the dictionary (bi-directional, so just need to make relations to people past the current in the list): `self.add_reciprocal_relation()`\n",
    "                        \n",
    "                            - adds bidirectional ties between authors in nested connection map (calls `self.add_directed_relation( person_1_id_IN, person_2_id_IN )`, then `self.add_directed_relation( person_2_id_IN, person_1_id_IN )`).\n",
    "                            \n",
    "                                - `self.add_directed_relation()`: updates `self.relation_map`, map of FROM IDs to dictionary of TO IDs, where each TO maps to a count of the ties between the two.  **_Solely ID-based, so methods to add relations can stay as-is!  Yay!_**\n",
    "                        \n",
    "                        - set person's type to \"author\": `self.update_person_type( current_person_id, NetworkDataOutput.PERSON_TYPE_AUTHOR )`\n",
    "                        \n",
    "                            - accepts person ID and type.\n",
    "                            - looks for person ID in `self.person_type_dict`.\n",
    "                            \n",
    "                                - If not present, adds current type.\n",
    "                                - If present but not same as what is passed in, sets to BOTH.\n",
    "                        \n",
    "                        - add relations to sources: `self.process_source_relations( current_person_id, source_qs_IN )`\n",
    "                        \n",
    "                            - accepts author ID and source QuerySet.\n",
    "                            - if author ID and source QuerySet has something in it, proceeds.\n",
    "                            - checks if source is connected: `self.is_source_connected( current_source )`\n",
    "                            \n",
    "                                - calls `Article_Subject.is_connected( self.inclusion_params )`\n",
    "                            \n",
    "                            - if connected, retrieves person ID for source, if source has ID adds reciprocal relation between author and source: `self.add_reciprocal_relation()`.\n",
    "                            \n",
    "                - update the types of the sources (from source_qs): `self.update_source_person_types( source_qs )`\n",
    "                \n",
    "                    - for each source, calls `self.update_person_type( current_person_id, NetworkDataOutput.PERSON_TYPE_SOURCE )`\n",
    "                \n",
    "        - build master person list: `self.generate_master_person_list()`\n",
    "        \n",
    "            - combines the person dictionary with dictionary that maps person to source type based on Article_Data processed for ties.\n",
    "            \n",
    "        - actually render the network data: `self.render_network_data()`\n",
    "        \n",
    "            - based on output parameters, implemented in NDO child classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network output - context logic\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network output - context logic - NetworkOutput\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "- NetworkOutput.render_network_data( relation_qs_IN, network_data_request_IN )\n",
    "\n",
    "    - accepts optional Entity_Relation QuerySet and optional request.\n",
    "    - create entity dictionary - self.create_entity_dict()\n",
    "    \n",
    "        - retrieve Entity_Relation QuerySet to traverse to pull in all relations - network_data_request.filter_relation_query_set( use_entity_selection_IN = True )\n",
    "        - call self.add_entities_to_dict() to add entities from the relation QuerySet.\n",
    "        \n",
    "            - loops over relations, retrieves FROM, TO, and optionally THROUGH entities, calls self.add_entity_to_dict() on each entity to be added.\n",
    "            \n",
    "                - for each entity, retrieve Entity instance and ID, add to dictionary, storing instance as value if store_entity_IN == True.\n",
    "                \n",
    "        - return dictionary into \"entity_dictionary\".\n",
    "    \n",
    "    - get NetworkDataOutput (NDO) instance - self.get_NDO_instance()\n",
    "    - initialize NDO\n",
    "    \n",
    "        - NDO.set_query_set( query_set_IN )\n",
    "        - NDO.set_entity_dictionary( entity_dictionary )\n",
    "        - initialize from request: NDO.initialize_from_request( network_data_request )\n",
    "        \n",
    "    - render - NDO.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network output - context logic - NetworkDataOutput\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "- NetworkDataOutput.render()\n",
    "\n",
    "    - get Entity_Relation query_set and entity_dictionary.\n",
    "    - create ties\n",
    "\n",
    "        - loop over query_set:\n",
    "        \n",
    "            - // retrieve FROM and TO entities.\n",
    "            - // pull out their IDs.\n",
    "            - // add relation - check if directed:\n",
    "            \n",
    "                - directed:\n",
    "                \n",
    "                    - `self.add_directed_relation( from_id, to_id )`\n",
    "                    \n",
    "                - not directed:\n",
    "                \n",
    "                    - `self.add_reciprocal_relation( from_id, to_id )`\n",
    "            \n",
    "            - // update roles of entities...\n",
    "            \n",
    "                - one thought is to make a map of relation types for each person that maps to a dictionary of FROM, TO, and THROUGH, each mapped to counts of the times the person was in each role.\n",
    "                - replaces:\n",
    "\n",
    "                    - calls to: `self.update_person_type( current_person_id, NetworkDataOutput.PERSON_TYPE_SOURCE )` with `update_entity_relations_details( self, entity_id_IN, relation_type_slug_IN, relation_role_IN ):`\n",
    "                    - references to `self.person_type_dict` with something more nuanced (no longer can depend on a single type).\n",
    "                \n",
    "        - // build master entity list: `self.generate_master_entity_list()`\n",
    "        \n",
    "            - combines the person dictionary with dictionary that maps person to source type based on Article_Data processed for ties.\n",
    "            - should be able to use it as is with some variable name changes.\n",
    "            - // also, change name to \"m_master_entity_list\", and make a getter(), and then always retrieve using get().\n",
    "            \n",
    "        - actually render the network data: `self.render_network_data()`\n",
    "        \n",
    "            - based on output parameters, implemented in NDO child classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context network output test code\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Try loading the basic file and using it to render network data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:43.811419Z",
     "start_time": "2020-01-08T20:00:43.807976Z"
    }
   },
   "outputs": [],
   "source": [
    "# load basic NetworkDataRequest\n",
    "data_request_basic = TestHelper.load_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:43.818172Z",
     "start_time": "2020-01-08T20:00:43.813160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<context.export.network.network_data_request.NetworkDataRequest at 0x7ff09f60b940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make and initialize instance of NetworkOutput\n",
    "network_output = NetworkOutput()\n",
    "network_output.set_network_data_request( data_request_basic )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:44.455595Z",
     "start_time": "2020-01-08T20:00:43.819834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_selection_filters(): use_entity_selection_IN is True\n",
      "In get_selection_filters(): \"entity_selection\" filtering was requested, but not specified in the request.  Defaulting to \"relation_selection\".\n",
      "In get_selection_filters(): use_entity_selection_IN is False\n"
     ]
    }
   ],
   "source": [
    "# call render, see what happens.\n",
    "network_data = network_output.render_network_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T20:00:44.463966Z",
     "start_time": "2020-01-08T20:00:44.457800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{35: {'quoted': {'FROM': 1, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 1, 'TO': 0, 'THROUGH': 0}}, 36: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 18: {'quoted': {'FROM': 6, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 7, 'TO': 0, 'THROUGH': 0}}, 24: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 23: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 22: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 21: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 20: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 19: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 25: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 8: {'shared_byline': {'FROM': 1, 'TO': 1, 'THROUGH': 0}, 'quoted': {'FROM': 4, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 7, 'TO': 0, 'THROUGH': 0}}, 9: {'shared_byline': {'FROM': 1, 'TO': 1, 'THROUGH': 0}, 'quoted': {'FROM': 9, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 24, 'TO': 0, 'THROUGH': 0}}, 16: {'quoted': {'FROM': 0, 'TO': 2, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 13: {'quoted': {'FROM': 0, 'TO': 2, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 12: {'quoted': {'FROM': 0, 'TO': 2, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 11: {'quoted': {'FROM': 0, 'TO': 2, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 15: {'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 14: {'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 10: {'mentioned': {'FROM': 0, 'TO': 2, 'THROUGH': 0}}, 80: {'quoted': {'FROM': 3, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 3, 'TO': 0, 'THROUGH': 0}}, 83: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 82: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 81: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 69: {'quoted': {'FROM': 3, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 3, 'TO': 0, 'THROUGH': 0}}, 72: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 71: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 70: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 46: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 44: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 40: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 47: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 45: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 43: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 42: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 41: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 39: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 38: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 32: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 28: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 33: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 31: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 30: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 29: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 27: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 85: {'quoted': {'FROM': 2, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 5, 'TO': 0, 'THROUGH': 0}}, 89: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 87: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 90: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 88: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 86: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 74: {'quoted': {'FROM': 4, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 4, 'TO': 0, 'THROUGH': 0}}, 78: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 77: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 76: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 75: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 63: {'quoted': {'FROM': 4, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 4, 'TO': 0, 'THROUGH': 0}}, 67: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 66: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 65: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 64: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 49: {'quoted': {'FROM': 3, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 4, 'TO': 0, 'THROUGH': 0}}, 53: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 52: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 51: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 50: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 55: {'quoted': {'FROM': 3, 'TO': 0, 'THROUGH': 0}, 'mentioned': {'FROM': 6, 'TO': 0, 'THROUGH': 0}}, 61: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 59: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 58: {'quoted': {'FROM': 0, 'TO': 1, 'THROUGH': 0}, 'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 60: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 57: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}, 56: {'mentioned': {'FROM': 0, 'TO': 1, 'THROUGH': 0}}}\n",
      "\n",
      "\n",
      "Entity_Relation_Type slug list: ['mentioned', 'quoted', 'shared_byline']\n",
      "\n",
      "\n",
      "Entity_Relation_Type slug to instance map: {'quoted': <Entity_Relation_Type: 1 - quoted - quoted>, 'mentioned': <Entity_Relation_Type: 2 - mentioned - mentioned>, 'shared_byline': <Entity_Relation_Type: 3 - shared_byline - Shared Byline>}\n"
     ]
    }
   ],
   "source": [
    "ndo_instance = network_output.m_NDO_instance\n",
    "test1 = ndo_instance.get_entity_relation_type_summary_dict()\n",
    "print( test1 )\n",
    "\n",
    "test2 = ndo_instance.m_relation_type_slug_list\n",
    "print( \"\\n\\nEntity_Relation_Type slug list: {}\".format( test2 ) )\n",
    "\n",
    "test3 = ndo_instance.m_relation_type_slug_to_instance_map\n",
    "print( \"\\n\\nEntity_Relation_Type slug to instance map: {}\".format( test3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network data creation TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Network data creation TODO:\n",
    "\n",
    "- build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "\n",
    "    - have child NDO classes implement \"`initialize_from_request`\" if needed, call parent, then init format-specific stuff.\n",
    "    - update to use StatusContainer instead of status strings.\n",
    "\n",
    "- testing\n",
    "\n",
    "    - // first, get it running, then unit tests.\n",
    "    - make plan for unit testing for all export instances, fill in outline below.\n",
    "    - unit testing:\n",
    "\n",
    "        - NetworkOutput\n",
    "        \n",
    "            - `add_entity_to_dict()`\n",
    "            - `add_entities_to_dict()`\n",
    "            - `create_entity_dict()`\n",
    "            - // `create_ndo_instance()`\n",
    "            - // `get_NDO_instance()`\n",
    "            - // `get_network_data_request()`\n",
    "            - // `get_relation_query_set()`\n",
    "            - `render_network_data()`\n",
    "            - // `set_NDO_instance()`\n",
    "            - // `set_network_data_request()`\n",
    "            - // `set_relation_query_set()`\n",
    "            \n",
    "        - NetworkDataOutput\n",
    "            \n",
    "            - `update_entity_relation_type()`\n",
    "            - **_`update_entity_relations_details()`_**\n",
    "            - `add_relation_type_to_map()`, and related (get, set, etc.).\n",
    "            - `register_relation_type()`, and the places that call it: `render()`, optionally also `update_entity_relation_details()`\n",
    "            - `get_master_entity_list()` - recursion...\n",
    "            - getters and setters\n",
    "            - make plan for the rest.\n",
    "            \n",
    "        - NDO children\n",
    "        \n",
    "            - !\n",
    "\n",
    "    - // look at relation filtering/tie creation/rendering - Entity 10 (person 872) has two ties in test output for \"basic\" (to entities 8 and 9), should only have 1.  Article (21409) had two authors, so single article resulted in two ties to the subject, one from each author.\n",
    "    - test by comparing to output from the original tool, including derived statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**general TODO:**\n",
    "\n",
    "- methods to find relations, similar to `filter_entities()` and `lookup_entities()` in `Entity` model class.  Include:\n",
    "\n",
    "    - // Entity_Relation_Type by either slug or instance\n",
    "    - // from = \n",
    "    - from_in\n",
    "    - from_type_in\n",
    "    - from_identifiers_in\n",
    "    - from_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // to = \n",
    "    - to_in\n",
    "    - to_type_in\n",
    "    - to_identifiers_in\n",
    "    - to_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // through =\n",
    "    - through_in\n",
    "    - through_identifiers_in\n",
    "    - through_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - either FROM or TO (so undirected search - \"I don't care which side\")\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - any of FROM, TO, THROUGH\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - relation_traits\n",
    "    \n",
    "        - // AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - _NOTE_ for trait matching types (and probably entity identifiers, also):\n",
    "\n",
    "        - \"AND dictionary\" - to start, accept a dictionary of trait names and values that all must match (AND match).\n",
    "        - \"OR dictionary\" - could add an \"OR\" trait match dictionary as well.\n",
    "        - \"fancy\" - Eventually, could add ability to spec trait name (or unsaved model instance?), then specify test for value (equals, contains, etc.) and test value.  This would likely be a new little object.\n",
    "        \n",
    "    - Tags on Entity and/or Entity_Relation.\n",
    "\n",
    "- make small dummy person and organization classes in context, so I can use them to test Abstract_Entity_Container without needing context_text.\n",
    "- come up with better way to seed entities and relations for sourcenet - store spec in context_text base, then method to create or update all.\n",
    "\n",
    "    - store the JSON from the context fixture in Context_Text_Base?  Or in a sourcenet class somewhere?\n",
    "    - make a class in context/shared that contains variables and methods to loops over the items in context fixture JSON and update the database based on what is inside.  For each item in the fixture JSON, looks each up based on unique idnetifying information (name, slug, label, etc.). If it finds it, moves on.  If not, creates it.  \n",
    "    - This will need to build up a basic object mapping based on foriegn keys before it creates anything, then create things in the right order (Entity_Types and related first, then Entity_Identifier_Types, then Relation_Types).  Order:\n",
    "    \n",
    "        - context.Trait_Type \\\n",
    "        - context.Entity_Type \\\n",
    "        - context.Entity_Type_Trait \\\n",
    "        - context.Entity_Identifier_Type\n",
    "        - context.Entity_Relation_Type \\\n",
    "        - context.Entity_Relation_Type_Trait \\\n",
    "        - context.Term_Relation_Type \\\n",
    "        - context.Vocabulary \\\n",
    "        - context.Term \\\n",
    "        - context.Term_Relation \\\n",
    "        \n",
    "    - for each type:\n",
    "    \n",
    "        - make a map of id to fields for each item of that type.\n",
    "        - make a method for creating an instance of that type from fields.\n",
    "        - to associate related, retrieve instance from in-memory map based on ID, then if db_id present, use it to look up, else look up in database based on name.  If not found, error, but could create.\n",
    "\n",
    "    - To actually load, go in order of types outlined above, creating as you go.\n",
    "    - When one of the items is added to the database, add a db_id field to their \"fields\".\n",
    "    \n",
    "- abstraction:\n",
    "\n",
    "    - make an abstract parent for a type that has associated trait specs (parent to `Entity_Type` and `Entity_Relation_Type`).\n",
    "    \n",
    "        - share method `get_trait_spec()`.\n",
    "    \n",
    "    - make an abstract parent for trait containers that have associated types with associated trait specs (parent to `Entity` and `Entity_Relation`).\n",
    "    \n",
    "        - share method `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network data creation TODO - DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Network data creation TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2020.01.06_**\n",
    "\n",
    "- then, build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "\n",
    "    - refactoring from old NetworkOutput, NetworkDataOutput, and NDO objects:\n",
    "\n",
    "        - // change so they refer to entities, not persons.\n",
    "        - // pull out all of the Article_Data stuff.\n",
    "        - // maintain the data structures used when actually rendering, just build from Entity_Relation, not Article_Data.  Might be able to get rid of some stuff, too.\n",
    "        - // terms to search for and consider replacing \"person\" with \"entity\" (if they aren't in sections that will just be ripped out because they are no longer needed):\n",
    "        \n",
    "            - // person_dictionary\n",
    "            - // person_dict\n",
    "            - // article_data_query_set\n",
    "            - // generate_master_person_list\n",
    "            - // person_ids_list\n",
    "            - // current_person_id \n",
    "            - // current_article_data\n",
    "            - // article_data_counter\n",
    "            - // master_person_list\n",
    "\n",
    "        - todo:\n",
    "\n",
    "            - // remove references to \"include_render_details\"\n",
    "            - // remove \"inclusion_params\"\n",
    "            \n",
    "                - // remove references to `self.inclusion_params`\n",
    "                - // remove references to `inclusion_params`\n",
    "                - // remove references to `self.is_source_connected( current_source )`\n",
    "            \n",
    "            - // remove network_label\n",
    "            - // update `generate_master_person_list()` to reference new variables (`generate_master_entity_list`).\n",
    "            - // what to do about `get_person_label()`? - updated to `get_entity_label`, for now just uses Entity ID.  Could make it also include more IF Entity instances are cached.  We'll see if that is helpful.\n",
    "            - // remove `get_person_type` and `get_person_type_id` (functions themselves are removed, need to mop up around the other classes: `grep -r -n \"get_person_type\" .`; `grep -r -n \"get_person_type_id\" .`\n",
    "            - // rename `get_relations_for_person` to `get_relations_for_entity`\n",
    "            - // rename `get_master_person_list` to `get_master_entity_list`\n",
    "            - // rename `create_person_id_list` to `create_entity_id_list`\n",
    "            - // rename `get_person_label` to `get_entity_label` (and made it a lot simpler).\n",
    "            - // remove `PERSON_QUERY_TYPE_CHOICES_LIST` and related.\n",
    "            - // remove `CODER_TYPE_FILTER_*`\n",
    "            - // remove `PERSON_TYPE_*` variables (check in all files)\n",
    "            - // search for \"person\", \"people\" in all NDO files in context.\n",
    "            \n",
    "                - // `ndo_simple_matrix.py`\n",
    "                - // `ndo_csv_matrix.py`\n",
    "                - // `ndo_tab_delimited_matrix.py`\n",
    "            \n",
    "            - // `Article_Subject`\n",
    "            - // `append_person_row`...\n",
    "            - // get rid of fancy date range code...\n",
    "            - // remove `PARAM_*`?  Not for now - used in places, is a good signal for needing changes.\n",
    "            \n",
    "        - update person type stuff so it stores a list, rather than \"author\", \"source\", or \"both\".\n",
    "        \n",
    "            - // As you build data, keep track centrally of all relation types seen - `register_relation_type( relation_type_IN )`, called from `render()`, optionally also from `update_entity_relation_details()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2020.01.08_**\n",
    "\n",
    "- build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "\n",
    "    - refactoring from old NetworkOutput, NetworkDataOutput, and NDO objects:\n",
    "\n",
    "        - // `NetworkOutput.render_network_data()`: add outputting to file if file output path specified in request.\n",
    "        - // add check to see if master list is larger after integrating items from network processing - if so, output error - for the entity filter to be effective, it must be a superset of the network set of relations.\n",
    "        - // update person type stuff so it stores a list, rather than \"author\", \"source\", or \"both\".\n",
    "        \n",
    "            - // remove `update_person_type()`\n",
    "            - // check for places that retrieve person type dictionary ( `self.person_type_dict` ) - removed all.\n",
    "            - // create a variable, getter and setter for `relation_type_slug_to_instance_map` and `relation_type_slug_list`.\n",
    "            - // removed `NDO.create_person_type_id_list` - figure out ramifications.  Might need to create a set of columns for each relation type, one for each of FROM, TO, and THROUGH, then populate appropriately from the new relation type map.    \n",
    "            - // As you build data, keep track centrally of all relation types seen - call `register_relation_type( relation_type_IN )` to update map and list created above.  Updated from `render()`, optionally also from `update_entity_relation_details()`.\n",
    "            - then, when outputting:\n",
    "                \n",
    "                - // for headers, grab this list of relation types and create FROM, TO, and THROUGH column headers for each.\n",
    "                - // for tabular (`ndo_csv_matrix` and children):\n",
    "                    \n",
    "                    - // `NetworkDataOutput.create_relation_type_roles_for_entity()`: for data rows (attribute columns at right), walk the entity's relation type data structure in the same order as the relation type list, and output FROM, TO, and THROUGH numbers for each, 0 if not found.  Will result in many attribute columns.\n",
    "                    - for data columns (attribute rows at bottom), pull in all relation types, then for each entity-->type-->role, walk all entities and output their value for that relation type in the row.  So, will result in many rows of attribute values.\n",
    "                    \n",
    "                        - // `NetworkDataOutput.create_relation_type_role_value_list()`: create method that accepts a relation type slug and a role, creates list of values for all entities in master entity list for that combination of slug and role.  If not present for a given entity, sets to 0.\n",
    "                        - // `NetworkDataOutput.create_relation_type_value_dict()`: create a method that accepts a relation type slug, loops over all roles, calls `NetworkDataOutput.create_relation_type_role_value_list()` to build the list of values for each, then makes and returns dictionary mapping roles to value lists.\n",
    "                        - // `NetworkDataOutput.create_all_relation_type_values_lists()`: create a method that loops over relation type slugs, then for each, calls `NetworkDataOutput.create_relation_type_value_dict()` to create dictionary that maps roles to values lists.  Creates a dictionary that maps relation type slugs to these dictionaries, then returns the new dictionary.\n",
    "                        - // `NDO_CSVMatrix.append_entity_relation_type_rows()`: implement logic in the ndo_csv_matrix class that retrieves the values lists and uses them appropriately.\n",
    "                    \n",
    "                - // for `ndo_simple_matrix.py` (UCINet native format), need to implement `create_entity_relation_types_attribute_string()` - it assumed a single entity type value per person - need to re-do it so it pulls in all relation types, then outputs a list per person-->type-->role.  So, will result in many lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general TODO DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Nothing yet..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
