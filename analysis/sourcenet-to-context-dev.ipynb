{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#notes-and-questions\" data-toc-modified-id=\"notes-and-questions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>notes and questions</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---working-folder-paths\" data-toc-modified-id=\"Setup---working-folder-paths-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - working folder paths</a></span></li><li><span><a href=\"#Setup---logging\" data-toc-modified-id=\"Setup---logging-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - logging</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li><li><span><a href=\"#Setup---ExportToContext-instance\" data-toc-modified-id=\"Setup---ExportToContext-instance-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Setup - ExportToContext instance</a></span></li><li><span><a href=\"#Setup---Initialize-LoggingHelper\" data-toc-modified-id=\"Setup---Initialize-LoggingHelper-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Setup - Initialize LoggingHelper</a></span></li></ul></li><li><span><a href=\"#set-up-context-entities-and-relations\" data-toc-modified-id=\"set-up-context-entities-and-relations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>set up context entities and relations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-to-database-from-fixture-file\" data-toc-modified-id=\"Load-to-database-from-fixture-file-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Load to database from fixture file</a></span></li></ul></li><li><span><a href=\"#load-sourcenet-data-into-context\" data-toc-modified-id=\"load-sourcenet-data-into-context-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>load sourcenet data into context</a></span><ul class=\"toc-item\"><li><span><a href=\"#Retrieve-Article-instances\" data-toc-modified-id=\"Retrieve-Article-instances-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Retrieve Article instances</a></span></li><li><span><a href=\"#build-load-code-and-unit-tests\" data-toc-modified-id=\"build-load-code-and-unit-tests-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>build load code and unit tests</a></span><ul class=\"toc-item\"><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Testing</a></span></li></ul></li><li><span><a href=\"#Load-data-from-Article-instances\" data-toc-modified-id=\"Load-data-from-Article-instances-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Load data from Article instances</a></span></li></ul></li><li><span><a href=\"#Render-network-data\" data-toc-modified-id=\"Render-network-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Render network data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Specify-filter-criteria\" data-toc-modified-id=\"Specify-filter-criteria-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Specify filter criteria</a></span><ul class=\"toc-item\"><li><span><a href=\"#Old-filter-criteria\" data-toc-modified-id=\"Old-filter-criteria-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Old filter criteria</a></span></li></ul></li><li><span><a href=\"#create-test-data\" data-toc-modified-id=\"create-test-data-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>create test data</a></span></li></ul></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#general-TODO\" data-toc-modified-id=\"general-TODO-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>general TODO</a></span></li><li><span><a href=\"#sourcenet-to-context-TODO\" data-toc-modified-id=\"sourcenet-to-context-TODO-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>sourcenet-to-context TODO</a></span></li></ul></li><li><span><a href=\"#DONE\" data-toc-modified-id=\"DONE-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>DONE</a></span><ul class=\"toc-item\"><li><span><a href=\"#general-TODO-DONE\" data-toc-modified-id=\"general-TODO-DONE-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>general TODO DONE</a></span></li><li><span><a href=\"#sourcenet-to-context-TODO-DONE\" data-toc-modified-id=\"sourcenet-to-context-TODO-DONE-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>sourcenet-to-context TODO DONE</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes and questions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Notes:\n",
    "\n",
    "- probably will need a class that is an Article_Data container - reference to Article_Data, and then all the logic to process the entities and relations contained within.\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Do we want an Identifier Type separate from Entity and Relation identifiers?  I think we do, so we can specify the entity type(s) a given identifier should be used on.\n",
    "\n",
    "    - Created abstract one, and created a concrete entity identifier type.  Will create one for relation identifiers if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:20.816622Z",
     "start_time": "2019-11-26T02:55:20.813176Z"
    }
   },
   "outputs": [],
   "source": [
    "me = \"sourcenet-to-context-dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:21.912359Z",
     "start_time": "2019-11-26T02:55:21.909079Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:22.764295Z",
     "start_time": "2019-11-26T02:55:22.693377Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from django.db.models import Avg, Max, Min\n",
    "from django.utils.text import slugify\n",
    "import json\n",
    "import logging\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - working folder paths\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:24.680469Z",
     "start_time": "2019-11-26T02:55:24.668210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/phd_work/analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:25.239804Z",
     "start_time": "2019-11-26T02:55:25.235859Z"
    }
   },
   "outputs": [],
   "source": [
    "# current working folder\n",
    "current_working_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work/analysis\"\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date_string = current_datetime.strftime( \"%Y-%m-%d-%H-%M-%S\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:27.257143Z",
     "start_time": "2019-11-26T02:55:27.251116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging initialized, to /home/jonathanmorgan/work/django/research/work/phd_work/analysis/sourcenet-to-context-dev-2019-11-26-02-55-25.log.txt\n"
     ]
    }
   ],
   "source": [
    "logging_file_name = \"{}/{}-{}.log.txt\".format( current_working_folder, me, current_date_string )\n",
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = logging_file_name,\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")\n",
    "print( \"Logging initialized, to {}\".format( logging_file_name ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:32.359630Z",
     "start_time": "2019-11-26T02:55:32.354169Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:34.138358Z",
     "start_time": "2019-11-26T02:55:33.368615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2019-11-26 02:55:34.136015\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:34.496254Z",
     "start_time": "2019-11-26T02:55:34.428860Z"
    }
   },
   "outputs": [],
   "source": [
    "# context imports\n",
    "from context.models import Entity\n",
    "from context.models import Entity_Identifier_Type\n",
    "from context.models import Entity_Identifier\n",
    "from context.models import Entity_Type\n",
    "\n",
    "# context_text imports\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.export.to_context_base.export_to_context import ExportToContext\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Subject\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - ExportToContext instance\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Make instance, set instance variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:35.764845Z",
     "start_time": "2019-11-26T02:55:35.738434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Entity_Identifier_Type: 4 - article_newsbank_id - Newsbank - ( article )>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_exporter = ExportToContext()\n",
    "\n",
    "# no variables to set, yet...\n",
    "my_exporter.set_article_uuid_id_type_name( ExportToContext.ENTITY_ID_TYPE_ARTICLE_NEWSBANK_ID )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize LoggingHelper\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Create a LoggingHelper instance to use to log debug and also print at the same time.\n",
    "\n",
    "Preconditions: Must be run after Django is initialized, since `python_utilities` is in the django path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:37.300355Z",
     "start_time": "2019-11-26T02:55:37.296328Z"
    }
   },
   "outputs": [],
   "source": [
    "# python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# init\n",
    "my_logging_helper = LoggingHelper()\n",
    "my_logging_helper.set_logger_name( me )\n",
    "log_message = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up context entities and relations\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Set up the following entities and relations in context:\n",
    "\n",
    "`Entity_Identifier_Type`s:\n",
    "\n",
    "- general:\n",
    "\n",
    "    - permalink: name `permalink` (fixture ID 5) - CONTEXT_ENTITY_ID_TYPE_PERMALINK\n",
    "\n",
    "- article:\n",
    "\n",
    "    - article archive identifier: name `article_archive_identifier` (fixture ID 6) - CONTEXT_ENTITY_ID_TYPE_ARTICLE_ARCHIVE_IDENTIFIER\n",
    "    - sourcenet article ID: name `article_sourcenet_id` (fixture ID 3) - CONTEXT_ENTITY_ID_TYPE_ARTICLE_SOURCENET_ID\n",
    "    - newsbank article ID: name `article_newsbank_id` (fixture ID 4) - CONTEXT_ENTITY_ID_TYPE_ARTICLE_NEWSBANK_ID\n",
    "\n",
    "- newspaper:\n",
    "\n",
    "    - sourcenet newspaper ID: name `newspaper_sourcenet_id` (fixture ID 7) - CONTEXT_ENTITY_ID_TYPE_NEWSPAPER_SOURCENET_ID\n",
    "    - newsbank newspaper code: name `newspaper_newsbank_code` (fixture ID 8) - CONTEXT_ENTITY_ID_TYPE_NEWSPAPER_NEWSBANK_CODE\n",
    "\n",
    "- organization:\n",
    "\n",
    "    - sourcenet organization ID: name `organization_sourcenet_id` (fixture ID 9) - CONTEXT_ENTITY_ID_TYPE_ORGANIZATION_SOURCENET_ID\n",
    "\n",
    "- person:\n",
    "\n",
    "    - sourcenet person ID: name `person_sourcenet_id` (fixture ID 1) - CONTEXT_ENTITY_ID_TYPE_NAME_PERSON_SOURCENET_ID\n",
    "    - OpenCalais URI for person: name `person_open_calais_uuid` (fixture ID 2) - CONTEXT_ENTITY_ID_TYPE_NAME_PERSON_OPEN_CALAIS_UUID\n",
    "\n",
    "Entities:\n",
    "\n",
    "- person - a person!\n",
    "- article - Article, used to detect reporters, subjects, and sources.\n",
    "- organization - Any type of organized group (of organizations, of people, etc.).\n",
    "- newspaper - A newspaper, which can be used to cluster articles, employees, sources, etc.\n",
    "\n",
    "Relations:\n",
    "\n",
    "- from newspaper\n",
    "\n",
    "    - newspaper_reporter - Reporter at a newspaper, evidence of which is byline on an article in that newspaper.  FROM newspaper TO person (reporter) THROUGH article.\n",
    "    - newspaper_source - Person quoted in an article published by a newspaper. FROM newspaper TO person (source) THROUGH article.\n",
    "    - newspaper_subject - Subject of an article published in a given newspaper.  FROM newspaper TO person (subject, including sources) THROUGH article.\n",
    "    - newspaper_article - Article published in a particular newspaper.  FROM newspaper TO article.\n",
    "\n",
    "- from article\n",
    "\n",
    "    - author - Author/Reporter of an article - FROM article TO reporter.\n",
    "    - subject - Subject of a story.  FROM article TO subject person.\n",
    "    - source - Source quoted in an article - FROM article TO source person.\n",
    "\n",
    "- through article\n",
    "\n",
    "    - article_container - Parent for relations based on entities being mentioned in the same article.  To start, just people, but eventually, for example, could also include location.\n",
    "    - mentioned - Mentioned in an article.  FROM reporter/author TO subject THROUGH article.\n",
    "    - quoted - The \\\"from\\\" person quoted the \\\"to\\\" person in a publication.  FROM reporter TO source THROUGH article.\n",
    "    - same_article_sources - Sources in the same article, FROM source person TO source person THROUGH article.\n",
    "    - same_article_subjects - Two people who are in a particular article together (includes subjects and sources).\n",
    "    - shared_byline - Shared Byline on an article - joint authors - FROM author TO author THROUGH article.\n",
    "\n",
    "Then, export them to JSON fixture files using manage.py / django-admin dumpdata ( [https://docs.djangoproject.com/en/dev/ref/django-admin/#django-admin-dumpdata](https://docs.djangoproject.com/en/dev/ref/django-admin/#django-admin-dumpdata) ) so they can be imported using python manage.py or django-admin loaddata ( [https://docs.djangoproject.com/en/dev/ref/django-admin/#django-admin-loaddata](https://docs.djangoproject.com/en/dev/ref/django-admin/#django-admin-loaddata) ) rather than having to input them in the admin:\n",
    "\n",
    "    python manage.py dumpdata [app_label[.ModelName] [app_label[.ModelName] ...]] --indent INDENT --output <output_file_path>\n",
    "    \n",
    "    python manage.py dumpdata \\\n",
    "        --indent 4 \\\n",
    "        --output context-sourcenet_entities_and_relations.json \\\n",
    "        context.Entity_Identifier_Type \\\n",
    "        context.Entity_Relation_Type \\\n",
    "        context.Entity_Relation_Type_Trait \\\n",
    "        context.Entity_Type \\\n",
    "        context.Entity_Type_Trait \\\n",
    "        context.Trait_Type \\\n",
    "        context.Term \\\n",
    "        context.Term_Relation \\\n",
    "        context.Term_Relation_Type \\\n",
    "        context.Vocabulary \\\n",
    "        \n",
    "    No line breaks:\n",
    "    \n",
    "        python manage.py dumpdata --indent 4 --output context-sourcenet_entities_and_relations.json context.Entity_Identifier_Type context.Entity_Relation_Type context.Entity_Relation_Type_Trait context.Entity_Type context.Entity_Type_Trait context.Trait_Type context.Term context.Term_Relation context.Term_Relation_Type context.Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load to database from fixture file\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Seed entities and relations for sourcenet from fixture file created above, stored as a fixture in context.\n",
    "\n",
    "- store the JSON from the context fixture in Context_Text_Base?\n",
    "- make a simple class method there that loops over the items in the JSON and looks each up. If it finds it, updates it.  If not, creates it.\n",
    "\n",
    "Example JSON:\n",
    "\n",
    "    {\n",
    "        \"model\": \"context.entity_identifier_type\",\n",
    "        \"pk\": 8,\n",
    "        \"fields\": {\n",
    "            \"create_date\": \"2019-11-01T15:27:29.526Z\",\n",
    "            \"last_modified\": \"2019-11-01T15:27:29.526Z\",\n",
    "            \"name\": \"newspaper_newsbank_code\",\n",
    "            \"label\": \"newspaper_newsbank_code\",\n",
    "            \"source\": \"Newsbank\",\n",
    "            \"notes\": \"3-letter code assigned to a given paper by NewsBank.\",\n",
    "            \"type_list\": [\n",
    "                7\n",
    "            ]\n",
    "        }\n",
    "    },\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T21:03:30.568444Z",
     "start_time": "2019-11-05T21:03:30.562902Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare variables\n",
    "path_to_context_fixture = None\n",
    "json_file = None\n",
    "fixture_json = None\n",
    "\n",
    "# read in the fixture file.\n",
    "path_to_context_fixture = \"/home/jonathanmorgan/work/django/research/context/fixtures/context-sourcenet_entities_and_relations.json\"\n",
    "\n",
    "# load the fixture JSON into memory.\n",
    "with open( path_to_context_fixture ) as json_file:  \n",
    "\n",
    "    # parse the JSON file.\n",
    "    fixture_json = json.load( json_file )\n",
    "    \n",
    "#-- END open of JSON file to read it into memory. --#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T21:03:31.578041Z",
     "start_time": "2019-11-05T21:03:31.570741Z"
    }
   },
   "outputs": [],
   "source": [
    "print( json.dumps( fixture_json, sort_keys = True, indent = 4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T21:06:56.626785Z",
     "start_time": "2019-11-05T21:06:56.579050Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare variables\n",
    "fixture_item = None\n",
    "item_model = None\n",
    "item_fields = None\n",
    "\n",
    "# declare variables - Entity_Identifier_Type\n",
    "id_type_model = None\n",
    "id_type_qs = None\n",
    "id_type_count = None\n",
    "id_type_instance = None\n",
    "id_type_name = None\n",
    "id_type_label = None\n",
    "id_type_source = None\n",
    "id_type_notes = None\n",
    "id_type_type_list = None\n",
    "\n",
    "# declare variables - associated Entity_Type s\n",
    "entity_type_id = None\n",
    "entity_type_qs = None\n",
    "entity_type_count = None\n",
    "entity_type_instance = None\n",
    "\n",
    "# init\n",
    "id_type_model = \"context.entity_identifier_type\"\n",
    "\n",
    "# create or update Entity_Idetifier_Types\n",
    "\n",
    "# loop over items in fixture JSON\n",
    "for fixture_item in fixture_json:\n",
    "    \n",
    "    # get model, so we can see what we do.\n",
    "    item_model = fixture_item.get( \"model\", None )\n",
    "    \n",
    "    # is it \"context.entity_identifier_type\"?\n",
    "    if ( item_model == id_type_model ):\n",
    "        \n",
    "        # it is an identifier type.  Retrieve fields.\n",
    "        item_fields = fixture_item.get( \"fields\", None )\n",
    "        id_type_name = item_fields.get( \"name\", None )\n",
    "        \n",
    "        # do we have a name?  (Better have one...)\n",
    "        if ( id_type_name is not None ):\n",
    "            \n",
    "            print( \"\\nEntity_Identifier_Type: {}\".format( id_type_name ) )\n",
    "        \n",
    "            # does it already exist?\n",
    "            id_type_qs = Entity_Identifier_Type.objects.all()\n",
    "            id_type_qs = id_type_qs.filter( name__iexact = id_type_name )\n",
    "            id_type_count = id_type_qs.count()\n",
    "            \n",
    "            # how many matches\n",
    "            if ( id_type_count == 0 ):\n",
    "                \n",
    "                # it does not exist.  Create.\n",
    "                \n",
    "                # retrieve values\n",
    "                id_type_label = item_fields.get( \"label\", None )\n",
    "                id_type_source = item_fields.get( \"source\", None )\n",
    "                id_type_notes = item_fields.get( \"notes\", None )\n",
    "                id_type_type_list = item_fields.get( \"type_list\", [] )\n",
    "                \n",
    "                # store values and save.\n",
    "                id_type_instance = Entity_Identifier_Type()\n",
    "                id_type_instance.name = id_type_name\n",
    "                id_type_instance.label = id_type_label\n",
    "                id_type_instance.source = id_type_source\n",
    "                id_type_instance.notes = id_type_notes\n",
    "                id_type_instance.save()\n",
    "                \n",
    "                # add related entity types.\n",
    "                for entity_type_id in id_type_type_list:\n",
    "                    \n",
    "                    # look up the Entity_Type\n",
    "                    entity_type_qs = Entity_Type.objects.all()\n",
    "                    entity_type_qs = entity_type_qs.filter( pk = entity_type_id )\n",
    "                    entity_type_count = entity_type_qs.count()\n",
    "                    \n",
    "                    # how many matches?\n",
    "                    if ( entity_type_count == 1 ):\n",
    "                        \n",
    "                        # one.  Associate it.\n",
    "                        entity_type_instance = entity_type_qs.get()\n",
    "                        id_type_instance.type_list.add( entity_type_instance )\n",
    "                        \n",
    "                    elif ( entity_type_count == 0 ):\n",
    "                        \n",
    "                        # no match - move on.\n",
    "                        print( \"no matching Entity_Type for id {}, moving on.\".format( entity_type_id ) )\n",
    "                        \n",
    "                    elif ( entity_type_count > 1 ):\n",
    "                        \n",
    "                        # multiple pk matches - ERROR.\n",
    "                        print( \"ERROR - multiple matching Entity_Type for id {}, moving on.\".format( entity_type_id ) )\n",
    "                        \n",
    "                    else:\n",
    "\n",
    "                        # multiple pk matches - ERROR.\n",
    "                        print( \"ERROR - multiple matching Entity_Type for id {}, moving on.\".format( entity_type_id ) )\n",
    "                    \n",
    "                    #-- END check to see if entity type found --#\n",
    "                    \n",
    "                #-- END loop over related entity types. --#\n",
    "                \n",
    "                print( \"----> ADDED Entity_Identifier_Type for name {}.\\n==> JSON:\\n{}\\n==> instance:\\n{}\".format( id_type_name, fixture_item, id_type_instance ) )\n",
    "\n",
    "            elif ( id_type_count == 1 ):\n",
    "                \n",
    "                # exists.  Update?\n",
    "                id_type_instance = id_type_qs.get()\n",
    "                print( \"Entity_Identifier_Type for name {} already exists.\\n==> JSON:\\n{}\\n==> instance:\\n{}\".format( id_type_name, fixture_item, id_type_instance ) )\n",
    "            \n",
    "            elif ( id_type_count > 1 ):\n",
    "                \n",
    "                # error.\n",
    "                print( \"ERROR - more than one type match ({}) for name {}\".format( id_type_count, id_type_name ) )\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # unexpected error.\n",
    "                print( \"ERROR - name {} does not have 0, 1, or > 1 matches (count = {}).\".format( id_type_name, id_type_count ) )\n",
    "                \n",
    "            #-- END check to see how many matches --#\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # ERROR\n",
    "            print( \"ERROR - no name for Entity_Identifier_Type.\" )\n",
    "            \n",
    "        #-- END check to see if name. --#\n",
    "        \n",
    "    #-- END check to see if Entity_Identifier_Type --#\n",
    "    \n",
    "#-- END loop over fixture items. --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load sourcenet data into context\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "logic:\n",
    "\n",
    "- get all Article_Data created by automated coder, open calais coder type.\n",
    "- for each:\n",
    "\n",
    "    - Article processing:\n",
    "    \n",
    "        - look for article entity in context.  If not created, create one of type \"article\".  Store the sourcenet ID as identifier of type \"article_sourcenet_id\".\n",
    "        - Store the ID and entity reference for the Article (in object?  Should I make a place for the article to hold an Entity ID?).\n",
    "        - check to see if the newspaper has an entity (using its sourcenet ID as the lookup identifier).  If not, create one.\n",
    "\n",
    "    - Person processing:\n",
    "    \n",
    "        - Add all people who are either reporters/authors or subjects to `context` as entities of type \"person\", with identifier of type `person_sourcenet_id` set to their internal django/database \"id\", and with identifier of type `person_open_calais_uuid` set to their OpenCalais ID, if they have one.  If they have any other types of IDs, add them too, untyped.  Once entity is created, store ForeignKey of entity in Person record.\n",
    "        - Author/Reporter processing:\n",
    "\n",
    "            - look for each author's person entity.  If not found, create one.\n",
    "    \n",
    "        - Subject/Source processing:\n",
    "    \n",
    "            - look for a person entity for each subject/source.  If not found, create one.\n",
    "\n",
    "    - Relations - create the following:\n",
    "    \n",
    "        - from newspaper\n",
    "        \n",
    "            - newspaper_reporter - Reporter at a newspaper, evidence of which is byline on an article in that newspaper. FROM newspaper TO person (reporter) THROUGH article.\n",
    "            - newspaper_source - Person quoted in an article published by a newspaper. FROM newspaper TO person (source) THROUGH article.\n",
    "            - newspaper_subject - Subject of an article published in a given newspaper. FROM newspaper TO person (subject, including sources) THROUGH article.\n",
    "            - newspaper_article - Article published in a particular newspaper. FROM newspaper TO article.\n",
    "\n",
    "        - from article\n",
    "\n",
    "            - author - Author/Reporter of an article - FROM article TO reporter.\n",
    "            - subject - Subject of a story. FROM article TO subject person.\n",
    "            - source - Source quoted in an article - FROM article TO source person.\n",
    "\n",
    "        - through article\n",
    "\n",
    "            - article_container - Parent for relations based on entities being mentioned in the same article. To start, just people, but eventually, for example, could also include location.\n",
    "            - mentioned - Mentioned in an article. FROM reporter/author TO subject THROUGH article.\n",
    "            - quoted - The \"from\" person quoted the \"to\" person in a publication. FROM reporter TO source THROUGH article.\n",
    "            - same_article_sources - Sources in the same article, FROM source person TO source person THROUGH article.\n",
    "            - same_article_subjects - Two people who are in a particular article together (includes subjects and sources).\n",
    "            - shared_byline - Shared Byline on an article - joint authors - FROM author TO author THROUGH article.\n",
    "\n",
    "Relations broken out by person type:\n",
    "\n",
    "- For all reporters/authors:\n",
    "\n",
    "    - create a relation of type \"`author`\" between the article's entity (FROM) and the entity of the person (TO) for each author.\n",
    "    - if multiple authors, for each pair of authors, create a relation of type \"`shared_byline`\" between the two (it is undirected), THROUGH the article.\n",
    "\n",
    "- For all subjects, including sources:\n",
    "\n",
    "    - create a relation of type \"`subject`\" between the article's entity (FROM) and the entity of the subject person (TO).\n",
    "    - if multiple subjects, for each pair of subjects, create a relation of type \"`same_article_subjects`\" between the two (it is undirected), THROUGH the article.\n",
    "    - create a relation of type \"`mentioned`\" between each of the article's authors (FROM) and the subject (TO), THROUGH the article.\n",
    "\n",
    "- For all sources\n",
    "\n",
    "    - create a relation of type \"`source`\" between the article's entity and the entity for the source person.\n",
    "    - if multiple sources, for each pair of sources, create a relation of type \"`same_article_sources`\" between the two (it is undirected), THROUGH the article.\n",
    "    - create a relation of type \"`quoted`\" between each of the article's authors (FROM) and the source (TO), THROUGH the article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience methods:\n",
    "\n",
    "- method to find entity - based on type and identifier (accept all the fields that make sense, including optional identifier type instance).\n",
    "- method to find relation - based on type, etc.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- all ties are undirected.\n",
    "- relations can have three foreign keys into Entity - FROM, TO, and THROUGH (for a containing relationship, like the article that included two sources that we are relating)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Article instances\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Before we do anything else, need to be able to pull back all the articles whose data we want to load into the context store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:44.558525Z",
     "start_time": "2019-11-26T02:55:44.551532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-26 02:55:44.555990 - Loaded automated user: automated, id = 7\n"
     ]
    }
   ],
   "source": [
    "# look for publications that have article data:\n",
    "# - coded by automated coder\n",
    "# - with coder type of \"OpenCalais_REST_API_v2\"\n",
    "\n",
    "# get automated coder\n",
    "automated_coder_user = ContextTextBase.get_automated_coding_user()\n",
    "\n",
    "log_message = \"{} - Loaded automated user: {}, id = {}\".format( datetime.datetime.now(), automated_coder_user, automated_coder_user.id )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:55:45.681597Z",
     "start_time": "2019-11-26T02:55:45.671686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 articles\n"
     ]
    }
   ],
   "source": [
    "# find articles with Article_Data created by the automated user...\n",
    "article_qs = Article.objects.filter( article_data__coder = automated_coder_user )\n",
    "\n",
    "# ...and specifically coded using OpenCalais V2...\n",
    "article_qs = article_qs.filter( article_data__coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION )\n",
    "\n",
    "# ...and finally, we just want the distinct articles by ID.\n",
    "article_qs = article_qs.order_by( \"id\" ).distinct( \"id\" )\n",
    "\n",
    "# count?\n",
    "article_count = article_qs.count()\n",
    "log_message = \"Found {} articles\".format( article_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build load code and unit tests\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make unit tests to test convenience methods added to the following models, in `context/tests/models/`:\n",
    "\n",
    "- // `Entity_Identifier_Type` - test_Entity_Identifier_Type_model.py\n",
    "- // `Entity_Identifier` - test_Entity_Identifier_model.py\n",
    "- // `Entity` - test_Entity_model.py\n",
    "\n",
    "Also, // move instance creation class methods along with their constants over into \"TestHelper\" from test_Entity_Identifier_model.py, so they can be re-used across test classes.\n",
    "\n",
    "To run: `python manage.py test context.tests`\n",
    "\n",
    "In test data:\n",
    "\n",
    "- article 21925:\n",
    "\n",
    "    - Article_Data: `SELECT * FROM context_text_article_data WHERE article_id = 21925;`\n",
    "\n",
    "TODO:\n",
    "\n",
    "- test_entity_model.py\n",
    "\n",
    "    - test_get_entity_for_identifier\n",
    "\n",
    "- test_export_to_context.py\n",
    "\n",
    "    - test_get_article_uuid_id_type\n",
    "    - test_set_article_uuid_id_type_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Article instances\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now, we actually load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:57:11.103403Z",
     "start_time": "2019-11-26T02:56:09.493433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In create_q_filter_automated_by_coder_type: automated coder user: 7 - automated\n",
      "\n",
      "Summary:\n",
      "- good count: 46\n",
      "- > 1 count: 0\n",
      "- 0 count: 0\n",
      "- unexpected count: 0\n"
     ]
    }
   ],
   "source": [
    "result = my_exporter.process_articles( article_qs )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render network data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now, we need to render out our network data from context, so we can then test it out and make sure we are getting the same answers we got from the old way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify filter criteria\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First step is to translate the filter criteria for nodes and ties from the existing admin for the querying context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old filter criteria\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Configuration of [Network Builder](https://research.local/research/context/text/output/network), from [methods-network_analysis-create_network_data.ipynb](../methods/network_analysis/methods-network_analysis-create_network_data.ipynb):\n",
    "\n",
    "* Configuration to generate network files for prelim:\n",
    "\n",
    "    * Config of \"Select Articles\" - **fields in bold** need to be changed from default values:\n",
    "\n",
    "        * **`Start date (YYYY-MM-DD):`** 2009-12-01\n",
    "        * **`End date (YYYY-MM-DD):`** 2009-12-31\n",
    "        * `Fancy date range:` - Empty.\n",
    "        * **`Publications:`** \"Grand Rapids Press, The\"\n",
    "        * `Coders:` None selected.\n",
    "        * **`Coder IDs to include, in order of highest to lowest priority:`**\n",
    "\n",
    "            * for human sample: 13,8,9,10\n",
    "            * for automated: 2\n",
    "\n",
    "        * **if automated**: `Article_Data coder_type Filter Type` and `coder_type 'Value In' List (comma-delimited):`\n",
    "        \n",
    "            * only for coder \"automated\" (2), for now.\n",
    "            * use the coder_type filter fields to filter automatically coded Article_Data on coder type if you have tried different automated coder types:\n",
    "           \n",
    "                * **`Article_Data coder_type Filter Type:`** - `Just automated`\n",
    "                * **`coder_type 'Value In' List (comma-delimited):`** - Enter the coder types you want included.  Examples:\n",
    "                \n",
    "                    * OpenCalais v2: \"OpenCalais_REST_API_v2\"\n",
    "        \n",
    "        * `Topics`: None selected.\n",
    "        * **`Article Tag List (comma-delimited):`** - \"grp_month\"\n",
    "        * `Unique Identifier List (comma-delimited):` - Empty.\n",
    "        * **`Allow duplicate articles:`** - \"No\"\n",
    "    \n",
    "    * Configure \"Network Settings\" - **fields in bold** need to be changed from default values:\n",
    "        \n",
    "        * `relations - Include source contact types` - All selected.\n",
    "        * `relations - Include source capacities:` - None selected.\n",
    "        * `relations - Exclude source capacities:` - None selected.\n",
    "        * **`Download as File?`** - \"Yes\"\n",
    "        * `Include render details?` - \"No\"\n",
    "        * **`Data Format:`** - \"Tab-Delimited Matrix\"\n",
    "        * **`Data Output Type:`** - \"Network + Attribute Columns\"\n",
    "        * `Network Label:` - Empty.\n",
    "        * **`Include Headers:`** - \"Yes\"\n",
    "    \n",
    "    * Config of \"Select People\" - **fields in bold** need to be changed from default values:\n",
    "        \n",
    "        * _NOTE: This will be the same for all networks you want to compare (different weeks within a month, compared to the whole month, for instance). For each, get people from articles that are filtered to include all people used by either human or automated, and all the days covered by any of the networks you want to compare.  This means you'll have the same dimensions of network (same set of nodes/people) regardless of the particular network you are generating, allowing the matrices that result to be compared._\n",
    "        * **`Person Query Type:`** - \"Custom, defined below\"\n",
    "        * **`People from (YYYY-MM-DD):`** - 2009-12-01\n",
    "        * **`People to (YYYY-MM-DD):`** - 2009-12-31\n",
    "        * `Fancy person date range:` - Empty.\n",
    "        * **`Person publications:`** - \"Grand Rapids Press, The\"\n",
    "        * **`Person coders:`** - \"automated\", \"minnesota1\", \"minnesota2\", \"minnesota3\", \"ground_truth\"\n",
    "        * `Coder IDs to include, in order of highest to lowest priority:` - Empty.\n",
    "        * **`Article_Data coder_type Filter Type` and `coder_type 'Value In' List (comma-delimited):`**\n",
    "            \n",
    "            * _NOTE: not just for automated - since this includes all coders, automated and human, you need to always specify the coder type filter if you need it for automated network._\n",
    "            * use the coder_type filter fields to filter automatically coded Article_Data on coder type if you have tried different automated coder types:\n",
    "            \n",
    "                * **`Article_Data coder_type Filter Type:`** - `Just automated`\n",
    "                * **`coder_type 'Value In' List (comma-delimited):`** - Enter the coder types you want included.  Examples:\n",
    "                \n",
    "                    * OpenCalais v2: \"OpenCalais_REST_API_v2\"\n",
    "        \n",
    "        * `Person Topics`: None\n",
    "        * **`Article Tag List (comma-delimited):`** - \"grp_month\"\n",
    "        * `Unique Identifier List (comma-delimited):` - Empty.\n",
    "        * **`Person allow duplicate articles:`** - \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create test data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**general TODO:**\n",
    "\n",
    "- methods to find relations, similar to `filter_entities()` and `lookup_entities()` in `Entity` model class.  Include:\n",
    "\n",
    "    - // Entity_Relation_Type by either slug or instance\n",
    "    - // from = \n",
    "    - from_in\n",
    "    - from_type_in\n",
    "    - from_identifiers_in\n",
    "    - from_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // to = \n",
    "    - to_in\n",
    "    - to_type_in\n",
    "    - to_identifiers_in\n",
    "    - to_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // through =\n",
    "    - through_in\n",
    "    - through_identifiers_in\n",
    "    - through_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - either FROM or TO (so undirected search - \"I don't care which side\")\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - any of FROM, TO, THROUGH\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - relation_traits\n",
    "    \n",
    "        - // AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - _NOTE_ for trait matching types (and probably entity identifiers, also):\n",
    "\n",
    "        - \"AND dictionary\" - to start, accept a dictionary of trait names and values that all must match (AND match).\n",
    "        - \"OR dictionary\" - could add an \"OR\" trait match dictionary as well.\n",
    "        - \"fancy\" - Eventually, could add ability to spec trait name (or unsaved model instance?), then specify test for value (equals, contains, etc.) and test value.  This would likely be a new little object.\n",
    "        \n",
    "    - Tags on Entity and/or Entity_Relation.\n",
    "\n",
    "- make a small dummy person and organization classes in context, so I can use them to test Abstract_Entity_Container without needing context_text.\n",
    "- come up with better way to seed entities and relations for sourcenet - store spec in context_text base, then method to create or update all.\n",
    "\n",
    "    - store the JSON from the context fixture in Context_Text_Base?  Or in a sourcenet class somewhere?\n",
    "    - make a class in context/shared that contains variables and methods to loops over the items in context fixture JSON and update the database based on what is inside.  For each item in the fixture JSON, looks each up based on unique idnetifying information (name, slug, label, etc.). If it finds it, moves on.  If not, creates it.  \n",
    "    - This will need to build up a basic object mapping based on foriegn keys before it creates anything, then create things in the right order (Entity_Types and related first, then Entity_Identifier_Types, then Relation_Types).  Order:\n",
    "    \n",
    "        - context.Trait_Type \\\n",
    "        - context.Entity_Type \\\n",
    "        - context.Entity_Type_Trait \\\n",
    "        - context.Entity_Identifier_Type\n",
    "        - context.Entity_Relation_Type \\\n",
    "        - context.Entity_Relation_Type_Trait \\\n",
    "        - context.Term_Relation_Type \\\n",
    "        - context.Vocabulary \\\n",
    "        - context.Term \\\n",
    "        - context.Term_Relation \\\n",
    "        \n",
    "    - for each type:\n",
    "    \n",
    "        - make a map of id to fields for each item of that type.\n",
    "        - make a method for creating an instance of that type from fields.\n",
    "        - to associate related, retrieve instance from in-memory map based on ID, then if db_id present, use it to look up, else look up in database based on name.  If not found, error, but could create.\n",
    "\n",
    "    - To actually load, go in order of types outlined above, creating as you go.\n",
    "    - When one of the items is added to the database, add a db_id field to their \"fields\".\n",
    "    \n",
    "- abstraction:\n",
    "\n",
    "    - make an abstract parent for a type that has associated trait specs (parent to `Entity_Type` and `Entity_Relation_Type`).\n",
    "    \n",
    "        - share method `get_trait_spec()`.\n",
    "    \n",
    "    - make an abstract parent for trait containers that have associated types with associated trait specs (parent to `Entity` and `Entity_Relation`).\n",
    "    \n",
    "        - share method `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sourcenet-to-context TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network data creation**\n",
    "\n",
    "- design JSON based on https://research.local/research/context/text/output/network: generalized, but not perfectly so:\n",
    "\n",
    "    - filter, same for entities and relations:\n",
    "\n",
    "        - // list of entity type slugs to include\n",
    "        - // list of entity type slugs to exclude\n",
    "        - // list of relation type slugs to include\n",
    "        - // list of relation type slugs to exclude\n",
    "        - trait-based filters (allow for \n",
    "\n",
    "            - // in general - per trait:\n",
    "\n",
    "                - trait name\n",
    "                - optional trait type (ID, or slug)\n",
    "                - data type (int, string, datetime - so you can cast in query for ranges - datetimes, for example)\n",
    "                - type of comparison (equals, includes, excludes, list of ranges of include - from, to)\n",
    "                - trait values (set appropriate depending on type of comparison):\n",
    "\n",
    "                    - trait_value\n",
    "                    - trait_value_from\n",
    "                    - trait_value_to\n",
    "                    - trait_value_list\n",
    "                    \n",
    "            - pub_date ranges - list of one or more pairs of pub-date start and end date ranges.\n",
    "            - newspaper IDs - include and exclude lists.\n",
    "            - coders to include or exclude.\n",
    "            - coder_types to include or exclude.\n",
    "\n",
    "                - Do we include the \"only check type for automated user\" thing?\n",
    "\n",
    "            - topics (terms, in the context) - terms to include, terms to exclude.\n",
    "\n",
    "        - identifier-based filters...\n",
    "\n",
    "   - specify the output:\n",
    "\n",
    "       - // download as file?\n",
    "       - if file:\n",
    "\n",
    "           - // file path\n",
    "           - mime type?\n",
    "           - file extension?\n",
    "\n",
    "       - // data format - choose from:\n",
    "\n",
    "           - simple matrix\n",
    "           - CSV matrix\n",
    "           - tab-delimited matrix\n",
    "           - edge list?\n",
    "\n",
    "       - // output types:\n",
    "\n",
    "           - just network\n",
    "           - just attributes (one row per node, column per attribute).\n",
    "           - network with attributes as columns, so values stored per row.\n",
    "           - network with attributes as rows, so values stored per column.\n",
    "\n",
    "       - ? - include headers?\n",
    "       - ? - Network label...?\n",
    "\n",
    "- in test data base, make fixture of entities, relations, traits, etc., post-data load, for testing.  No need to include any Article_Data or anything, but need to specify exactly which tables are needed, and export all needed tables to a fixture.\n",
    "- create test JSON file that matches the criteria for \n",
    "- build out class to parse and hold the above JSON.\n",
    "- build logic to use contents of JSON to filter QuerySets of Entities and Relations.\n",
    "- then, build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "- test by comparing to output from the original tool, including derived statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relation Creation (start in `export_to_context.py`):**\n",
    "\n",
    "- FUTURE - abstract out the tests for an EntityContainer into their own parent test class that AbstractEntityContainers can use to re-use testing methods.  Will need a way to abstract out traits, identifiers, etc.  Not for now.\n",
    "- ? - make an \"Abstract_Relation_Container\" abstract method for code related to an instance of a given model resulting in a relation (Article_Data)?\n",
    "\n",
    "    - Might need ManyToMany back links, will have to see how we do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general TODO DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**general TODO DONE:**\n",
    "\n",
    "- // take the \"`create_article_entity()`\" function and put it in a class for loading sourcenet articles into  context\n",
    "\n",
    "    - `context_text/export/to_context_base/export_to_context.py` - class `ExportToContext`\n",
    "\n",
    "- // build unit test class for this loading class, and add one for creating a fake article, then making an entity out of it. Check entity, traits, and identifiers.\n",
    "- // Add Entity ID foreign key to Article, Person, Newspaper, Organization models.  Perhaps add it to a shared parent class? - context/shared/entity_models.py --> class Abstract_Entity_Container\n",
    "- add a unique_identifier_type column to Article model.  To set for NewsBank:\n",
    "\n",
    "        --SELECT COUNT( * ) FROM context_text_article;\n",
    "        --SELECT COUNT( * ) FROM context_text_article WHERE archive_source = 'NewsBank';\n",
    "        --SELECT * FROM context_text_article WHERE archive_source != 'NewsBank';\n",
    "        --UPDATE context_text_article SET unique_identifier_type = 'article_newsbank_id' WHERE archive_source = 'NewsBank';\n",
    "        --SELECT COUNT( * ) FROM context_text_article WHERE unique_identifier_type = 'permalink';\n",
    "        --SELECT COUNT( * ) FROM context_text_article WHERE unique_identifier_type = 'article_newsbank_id';\n",
    "\n",
    "    - need to update the code that loaded the NewsBank Articles so it sets this value.\n",
    "    - also, need to make \"Article\" unit tests for entity creation, rather than just having it in the export unit tests?\n",
    "\n",
    "- 2019.11.07 - // method to find entity - based on type and identifier (accept all the fields that make sense, including optional identifier type instance).\n",
    "\n",
    "    - // lookup_entities() - implemented, still need to write unit test.\n",
    "    - // implement unit test test_lookup_entities() in test_entity_model, pattern off of the Entity_Identifier unit test test_filter_identifiers().\n",
    "    - // update unit test test_get_entity_for_identifier() in test_entity_model to use all possible arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sourcenet-to-context TODO DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entity Creation:**\n",
    "\n",
    "- // Build and test basic article entity creation\n",
    "\n",
    "    - // includes building out entity helper methods and testing context entity code.\n",
    "    - // include adding reverse reference to Article's Entity to Article model.\n",
    "    - // include creating Newspaper entity for related newspaper?\n",
    "\n",
    "- // Build and test basic newspaper entity creation\n",
    "\n",
    "    - // ID type \"newspaper_sourcenet_id\" - add to both test and normal\n",
    "    - // ID type \"newspaper_newsbank_code\" - add to both test and normal\n",
    "    - // export new metadata fixture\n",
    "    - // integrate into article creation.\n",
    "\n",
    "- // Build and test basic person entity creation\n",
    "\n",
    "    - include adding reverse reference to Person's Entity to Person model.\n",
    "\n",
    "- // Build and test basic organization entity creation\n",
    "\n",
    "    - include adding reverse reference to Organization's Entity to Organization model.\n",
    "    - update newspaper entity creation to also create organization entity if newspaper.organization.has_entity() is False.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relation Creation (start in `export_to_context.py`)**\n",
    "\n",
    "All added 2019.11.25 unless noted otherwise:\n",
    "\n",
    "- // review the trait code and tests for entity (get, set, etc.), modify it and add it to relation, as well.  It will work exactly the same (see if we can abstract somehow).\n",
    "- // make methods `filter_relations` and `lookup_relations` with subset of above to serve Entity_Relation creation.\n",
    "- create unit test class for `Entity_Relation` based on Entity that tests:\n",
    "\n",
    "    - // trait methods\n",
    "    - instance methods:\n",
    "\n",
    "        - // `set_basic_traits_from_dict()`\n",
    "\n",
    "    - class methods:\n",
    "\n",
    "         - // `Entity_Relation.create_entity_relation()`\n",
    "\n",
    "             - test 1 - make one with type of \"quoted\", set FROM, TO, THROUGH and traits.\n",
    "             - test 2 - make one with same info, different traits, make sure it doesn't make a duplicate relation, and that trait values are updated.\n",
    "             - try other permutations?  No type, no through, no traits...\n",
    "\n",
    "         - // `filter_relations()`\n",
    "         - // `lookup_relations()`\n",
    "\n",
    "- Entity_Type and Entity_Relation_Type tests:\n",
    "\n",
    "    - method `get_type_for_slug()`\n",
    "\n",
    "- // work through entity creation first in `export_to_context.py`:\n",
    "\n",
    "    - // `create_entities()`\n",
    "    - // `create_newspaper_entities()`\n",
    "    - // `create_article_entities()`\n",
    "    - // add coder ID, coder username, and coder type to all relations based on the Article_Data from which they are derived.\n",
    "    - // create methods for getting lists of author, subject (including sources flag), and create test cases.\n",
    "    - // create method to generate relaton trait dictionary from article and article_Data passed in.\n",
    "    - // test cases for each of these in `test_export_to_context`.\n",
    "\n",
    "        - // `create_entity_container_entity()`\n",
    "        - // `create_article_entity()`\n",
    "        - // `create_person_entity()`\n",
    "        - // `@classmethod make_author_entity_list()`\n",
    "        - // `@classmethod make_relation_trait_dict()`\n",
    "        - // `@classmethod make_subject_entity_list()` (including only sources, and don't include sources in subjects).\n",
    "        - // `create_newspaper_relations()`\n",
    "        - // `create_article_relations()`\n",
    "        - // `create_relations()`\n",
    "        - // `process_articles()`\n",
    "\n",
    "    - // hook these in to `process_articles()`\n",
    "\n",
    "- // add traits to some of the relations created in `TestHelper.create_test_relations`.\n",
    "- // need to test what happens when you call the `update_entity()` method on each entity a second time.  Should not result in two separate entities.\n",
    "- 2019.12.04 - // add to unit test for `process_articles()` tests to make sure that tags are getting added to each article as they are processed.\n",
    "- 2019.12.04 - // create data from automated coding (just articles with coding by OpenCalais V.2) in actual database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
