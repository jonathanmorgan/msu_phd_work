{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li></ul></li><li><span><a href=\"#Tag-articles-to-be-coded\" data-toc-modified-id=\"Tag-articles-to-be-coded-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tag articles to be coded</a></span><ul class=\"toc-item\"><li><span><a href=\"#which-articles-need-to-be-tagged?\" data-toc-modified-id=\"which-articles-need-to-be-tagged?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>which articles need to be tagged?</a></span></li><li><span><a href=\"#tag-all-local-news\" data-toc-modified-id=\"tag-all-local-news-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>tag all local news</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grand-Rapids-Press-local-news\" data-toc-modified-id=\"Grand-Rapids-Press-local-news-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Grand Rapids Press local news</a></span></li><li><span><a href=\"#Detroit-News-local-news\" data-toc-modified-id=\"Detroit-News-local-news-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Detroit News local news</a></span></li></ul></li></ul></li><li><span><a href=\"#Code-Articles\" data-toc-modified-id=\"Code-Articles-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Code Articles</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T17:19:24.261084Z",
     "start_time": "2019-07-01T17:19:24.256325Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T18:06:42.736788Z",
     "start_time": "2019-07-01T18:06:42.729128Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from django.db.models import Avg, Max, Min\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T17:31:45.826995Z",
     "start_time": "2019-07-01T17:31:45.819463Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T17:31:48.771300Z",
     "start_time": "2019-07-01T17:31:46.711237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2019-07-01 17:31:48.768211\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T17:55:58.190099Z",
     "start_time": "2019-07-01T17:55:58.179482Z"
    }
   },
   "outputs": [],
   "source": [
    "# context_text imports\n",
    "from context_text.models import Article\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag articles to be coded\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Tag all locally implemented hard news articles in database, thenwork through using OpenCalais to code them all, starting with those proximal to the coding sample for methods paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which articles need to be tagged?\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "More precisely, find all articles that have Article_Data coded by the automated coder with type \"OpenCalais_REST_API_v2\" and tag the articles as \"coded-open_calais_v2\" or something like that.\n",
    "\n",
    "Then, for articles without that tag, use our criteria for local hard news to filter out and tag publications in the year before and after the month used to evaluate the automated coder, in both the Grand Rapids Press and the Detroit News, so I can look at longer time frames, then code all articles currently in database.\n",
    "\n",
    "Eventually, then, we'll code and examine before and after layoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T17:49:56.256853Z",
     "start_time": "2019-07-01T17:49:56.246189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-01 17:49:56.250169 - Loaded automated user: automated, id = 2\n"
     ]
    }
   ],
   "source": [
    "# look for publications that have article data:\n",
    "# - coded by automated coder\n",
    "# - with coder type of \"OpenCalais_REST_API_v2\"\n",
    "\n",
    "# get automated coder\n",
    "automated_coder_user = ArticleCoder.get_automated_coding_user()\n",
    "\n",
    "print( \"{} - Loaded automated user: {}, id = {}\".format( datetime.datetime.now(), automated_coder_user, automated_coder_user.id ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:28:34.630567Z",
     "start_time": "2019-07-01T19:28:34.602222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pub_date__max': datetime.date(2010, 11, 30), 'pub_date__min': datetime.date(2005, 1, 1)}\n"
     ]
    }
   ],
   "source": [
    "# try aggregates\n",
    "article_qs = Article.objects.all()\n",
    "pub_date_info = article_qs.aggregate( Max( 'pub_date' ), Min( 'pub_date' ) )\n",
    "print( pub_date_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T17:56:17.854100Z",
     "start_time": "2019-07-01T17:56:17.826648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 892 articles\n"
     ]
    }
   ],
   "source": [
    "# find articles with Article_Data created by the automated user.\n",
    "article_qs = Article.objects.filter( article_data__coder = automated_coder_user )\n",
    "article_qs = article_qs.filter( article_data__coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION )\n",
    "article_count = article_qs.count()\n",
    "print( \"Found {} articles\".format( article_count ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T18:52:49.295983Z",
     "start_time": "2019-07-01T18:52:49.229663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pub_date__max': datetime.date(2010, 7, 31), 'pub_date__min': datetime.date(2005, 1, 7)}\n",
      "- 2005-01-07 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-01-21 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-02-07 ( <class 'datetime.date'> ) count: 2\n",
      "- 2005-02-10 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-05-10 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-05-16 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-06-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-06-22 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-07-02 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-07-05 ( <class 'datetime.date'> ) count: 5\n",
      "- 2005-07-07 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-08-22 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-09-04 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-09-11 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-09-25 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-10-04 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-10-20 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-10-21 ( <class 'datetime.date'> ) count: 1\n",
      "- 2005-10-25 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-03-03 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-03-28 ( <class 'datetime.date'> ) count: 2\n",
      "- 2006-04-30 ( <class 'datetime.date'> ) count: 3\n",
      "- 2006-05-11 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-05-30 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-06-21 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-06-22 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-07-18 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-08-15 ( <class 'datetime.date'> ) count: 2\n",
      "- 2006-08-24 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-09-14 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-09-28 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-11-03 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-11-16 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-11-18 ( <class 'datetime.date'> ) count: 1\n",
      "- 2006-11-19 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-01-26 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-01-29 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-03-26 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-04-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-07-11 ( <class 'datetime.date'> ) count: 2\n",
      "- 2007-07-25 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-07-27 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-08-05 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-08-17 ( <class 'datetime.date'> ) count: 3\n",
      "- 2007-08-18 ( <class 'datetime.date'> ) count: 2\n",
      "- 2007-09-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-09-07 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-10-17 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-10-28 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-10-31 ( <class 'datetime.date'> ) count: 2\n",
      "- 2007-11-29 ( <class 'datetime.date'> ) count: 1\n",
      "- 2007-12-13 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-01-06 ( <class 'datetime.date'> ) count: 2\n",
      "- 2008-01-31 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-02-05 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-02-24 ( <class 'datetime.date'> ) count: 2\n",
      "- 2008-03-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-03-12 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-03-30 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-04-04 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-04-07 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-04-17 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-05-25 ( <class 'datetime.date'> ) count: 2\n",
      "- 2008-06-05 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-07-12 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-07-25 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-08-27 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-09-02 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-09-20 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-09-27 ( <class 'datetime.date'> ) count: 2\n",
      "- 2008-10-08 ( <class 'datetime.date'> ) count: 1\n",
      "- 2008-11-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-01-13 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-02-02 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-03-07 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-05-02 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-06-17 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-06-25 ( <class 'datetime.date'> ) count: 2\n",
      "- 2009-08-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-08-08 ( <class 'datetime.date'> ) count: 3\n",
      "- 2009-08-22 ( <class 'datetime.date'> ) count: 3\n",
      "- 2009-09-16 ( <class 'datetime.date'> ) count: 2\n",
      "- 2009-09-23 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-10-06 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-10-11 ( <class 'datetime.date'> ) count: 1\n",
      "- 2009-11-29 ( <class 'datetime.date'> ) count: 2\n",
      "- 2009-12-01 ( <class 'datetime.date'> ) count: 13\n",
      "- 2009-12-02 ( <class 'datetime.date'> ) count: 13\n",
      "- 2009-12-03 ( <class 'datetime.date'> ) count: 19\n",
      "- 2009-12-04 ( <class 'datetime.date'> ) count: 12\n",
      "- 2009-12-05 ( <class 'datetime.date'> ) count: 20\n",
      "- 2009-12-06 ( <class 'datetime.date'> ) count: 55\n",
      "- 2009-12-07 ( <class 'datetime.date'> ) count: 27\n",
      "- 2009-12-08 ( <class 'datetime.date'> ) count: 48\n",
      "- 2009-12-09 ( <class 'datetime.date'> ) count: 78\n",
      "- 2009-12-10 ( <class 'datetime.date'> ) count: 57\n",
      "- 2009-12-11 ( <class 'datetime.date'> ) count: 63\n",
      "- 2009-12-12 ( <class 'datetime.date'> ) count: 52\n",
      "- 2009-12-13 ( <class 'datetime.date'> ) count: 17\n",
      "- 2009-12-14 ( <class 'datetime.date'> ) count: 7\n",
      "- 2009-12-15 ( <class 'datetime.date'> ) count: 21\n",
      "- 2009-12-16 ( <class 'datetime.date'> ) count: 17\n",
      "- 2009-12-17 ( <class 'datetime.date'> ) count: 13\n",
      "- 2009-12-18 ( <class 'datetime.date'> ) count: 19\n",
      "- 2009-12-19 ( <class 'datetime.date'> ) count: 16\n",
      "- 2009-12-20 ( <class 'datetime.date'> ) count: 19\n",
      "- 2009-12-21 ( <class 'datetime.date'> ) count: 7\n",
      "- 2009-12-22 ( <class 'datetime.date'> ) count: 16\n",
      "- 2009-12-23 ( <class 'datetime.date'> ) count: 12\n",
      "- 2009-12-24 ( <class 'datetime.date'> ) count: 10\n",
      "- 2009-12-25 ( <class 'datetime.date'> ) count: 8\n",
      "- 2009-12-26 ( <class 'datetime.date'> ) count: 11\n",
      "- 2009-12-27 ( <class 'datetime.date'> ) count: 23\n",
      "- 2009-12-28 ( <class 'datetime.date'> ) count: 7\n",
      "- 2009-12-29 ( <class 'datetime.date'> ) count: 9\n",
      "- 2009-12-30 ( <class 'datetime.date'> ) count: 13\n",
      "- 2009-12-31 ( <class 'datetime.date'> ) count: 8\n",
      "- 2010-01-05 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-02-07 ( <class 'datetime.date'> ) count: 3\n",
      "- 2010-02-08 ( <class 'datetime.date'> ) count: 12\n",
      "- 2010-02-09 ( <class 'datetime.date'> ) count: 6\n",
      "- 2010-02-10 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-02-11 ( <class 'datetime.date'> ) count: 18\n",
      "- 2010-02-12 ( <class 'datetime.date'> ) count: 4\n",
      "- 2010-02-13 ( <class 'datetime.date'> ) count: 15\n",
      "- 2010-03-11 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-03-17 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-04-15 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-06-22 ( <class 'datetime.date'> ) count: 2\n",
      "- 2010-07-09 ( <class 'datetime.date'> ) count: 2\n",
      "- 2010-07-14 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-07-23 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-07-29 ( <class 'datetime.date'> ) count: 1\n",
      "- 2010-07-31 ( <class 'datetime.date'> ) count: 1\n"
     ]
    }
   ],
   "source": [
    "# profile these publications\n",
    "min_pub_date = None\n",
    "max_pub_date = None\n",
    "current_pub_date = None\n",
    "pub_date_count = None\n",
    "date_to_count_map = {}\n",
    "date_to_articles_map = {}\n",
    "pub_date_article_dict = None\n",
    "\n",
    "# try aggregates\n",
    "pub_date_info = article_qs.aggregate( Max( 'pub_date' ), Min( 'pub_date' ) )\n",
    "print( pub_date_info )\n",
    "\n",
    "# counts of pubs by date\n",
    "for current_article in article_qs:\n",
    "    \n",
    "    # get pub_date\n",
    "    current_pub_date = current_article.pub_date\n",
    "    current_article_id = current_article.id\n",
    "    \n",
    "    # get count, increment, and store.\n",
    "    pub_date_count = date_to_count_map.get( current_pub_date, 0 )\n",
    "    pub_date_count += 1\n",
    "    date_to_count_map[ current_pub_date ] = pub_date_count\n",
    "    \n",
    "    # also, store up ids and instances\n",
    "    \n",
    "    # get dict of article ids to article instances for date\n",
    "    pub_date_article_dict = date_to_articles_map.get( current_pub_date, {} )\n",
    "    \n",
    "    # article already there?\n",
    "    if ( current_article_id not in pub_date_article_dict ):\n",
    "        \n",
    "        # no - add it.\n",
    "        pub_date_article_dict[ current_article_id ] = current_article\n",
    "        \n",
    "    #-- END check to see if article already there.\n",
    "    \n",
    "    # put dict back.\n",
    "    date_to_articles_map[ current_pub_date ] = pub_date_article_dict\n",
    "    \n",
    "#-- END loop over articles. --#\n",
    "\n",
    "# output dates and counts.\n",
    "\n",
    "# get list of keys from map\n",
    "keys_list = list( six.viewkeys( date_to_count_map ) )\n",
    "keys_list.sort()\n",
    "for current_pub_date in keys_list:\n",
    "    \n",
    "    # get count\n",
    "    pub_date_count = date_to_count_map.get( current_pub_date, 0 )\n",
    "    print( \"- {} ( {} ) count: {}\".format( current_pub_date, type( current_pub_date ), pub_date_count ) )\n",
    "    \n",
    "#-- END loop over dates --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:23:40.319488Z",
     "start_time": "2019-07-01T19:23:40.290640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6065: <Article: 6065 - Jul 31, 2010, City and Region ( A6 ), UID: 1315C0760F2D0668 - Local ArtPeers registration opens ( Grand Rapids Press, The )>}\n",
      "<QuerySet [<Tag: prelim_reliability_test>, <Tag: prelim_reliability_combined>]>\n",
      "2180 - minnesota1 - no coder_type -- Article: 6065 - Jul 31, 2010, City and Region ( A6 ), UID: 1315C0760F2D0668 - Local ArtPeers registration opens ( Grand Rapids Press, The )\n",
      "2200 - minnesota2 - no coder_type -- Article: 6065 - Jul 31, 2010, City and Region ( A6 ), UID: 1315C0760F2D0668 - Local ArtPeers registration opens ( Grand Rapids Press, The )\n",
      "2281 - minnesota3 - no coder_type -- Article: 6065 - Jul 31, 2010, City and Region ( A6 ), UID: 1315C0760F2D0668 - Local ArtPeers registration opens ( Grand Rapids Press, The )\n",
      "2969 - automated ( ADCT: OpenCalais_REST_API_v2 )  -- Article: 6065 - Jul 31, 2010, City and Region ( A6 ), UID: 1315C0760F2D0668 - Local ArtPeers registration opens ( Grand Rapids Press, The )\n"
     ]
    }
   ],
   "source": [
    "# look at the 2010-07-31 date\n",
    "pub_date = datetime.datetime.strptime( \"2010-07-31\", \"%Y-%m-%d\" ).date()\n",
    "articles_for_date = date_to_articles_map.get( pub_date, {} )\n",
    "print( articles_for_date )\n",
    "\n",
    "# get the article and look at its tags.\n",
    "article_instance = articles_for_date.get( 6065 )\n",
    "print( article_instance.tags.all() )\n",
    "\n",
    "for article_data in article_instance.article_data_set.all():\n",
    "    \n",
    "    print( article_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tag all local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news by in-house implementor for Grand Rapids Press and Detroit News follow.  For each, tag all articles in database that match as \"local_hard_news\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Rapids Press local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Grand Rapids Press local hard news:\n",
    "\n",
    "- `context_text/examples/articles/articles-GRP-local_news.py`\n",
    "- local hard news sections (stored in `Article.GRP_NEWS_SECTION_NAME_LIST`):\n",
    "\n",
    "    - \"Business\"\n",
    "    - \"City and Region\"\n",
    "    - \"Front Page\"\n",
    "    - \"Lakeshore\"\n",
    "    - \"Religion\"\n",
    "    - \"Special\"\n",
    "    - \"State\"\n",
    "\n",
    "- in-house implementor (based on byline patterns, stored in `sourcenet.models.Article.Q_GRP_IN_HOUSE_AUTHOR`):\n",
    "\n",
    "    - Byline ends in \"/ THE GRAND RAPIDS PRESS\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *THE GRAND RAPIDS PRESS$'`\n",
    "\n",
    "    - Byline ends in \"/ PRESS * EDITOR\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *PRESS .* EDITOR$' )`\n",
    "\n",
    "    - Byline ends in \"/ GRAND RAPIDS PRESS * BUREAU\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *GRAND RAPIDS PRESS .* BUREAU$' )`\n",
    "\n",
    "    - Byline ends in \"/ SPECIAL TO THE PRESS\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *SPECIAL TO THE PRESS$' )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detroit News local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Detroit News local news:\n",
    "\n",
    "- `context_text/examples/articles/articles-TDN-local_news.py`\n",
    "- local hard news sections (stored in `from context_text.collectors.newsbank.newspapers.DTNB import DTNB` - `DTNB.NEWS_SECTION_NAME_LIST`):\n",
    "\n",
    "    - \"Business\"\n",
    "    - \"Metro\"\n",
    "    - \"Nation\" - because of auto industry stories\n",
    "\n",
    "- in-house implementor (based on byline patterns, stored in `DTNB.Q_IN_HOUSE_AUTHOR`):\n",
    "\n",
    "    - Byline ends in \"/ The Detroit News\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "    - Byline ends in \"Special to The Detroit News\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*special\\s*to\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "    - Byline ends in \"Detroit News * Bureau\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*detroit\\s*news\\s*.*\\s*bureau$' )`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables\n",
    "\n",
    "# declare variables - article filter parameters\n",
    "start_pub_date = None # should be datetime instance\n",
    "end_pub_date = None # should be datetime instance\n",
    "tag_in_list = []\n",
    "paper_id_in_list = []\n",
    "section_list = []\n",
    "article_id_in_list = []\n",
    "params = {}\n",
    "\n",
    "# declare variables - processing\n",
    "do_i_print_updates = True\n",
    "my_article_coding = None\n",
    "article_qs = None\n",
    "article_count = -1\n",
    "coding_status = \"\"\n",
    "limit_to = -1\n",
    "do_coding = False\n",
    "\n",
    "# declare variables - results\n",
    "success_count = -1\n",
    "success_list = None\n",
    "got_errors = False\n",
    "error_count = -1\n",
    "error_dictionary = None\n",
    "error_article_id = -1\n",
    "error_status_list = None\n",
    "error_status = \"\"\n",
    "error_status_counter = -1\n",
    "\n",
    "# first, get a list of articles to code.\n",
    "\n",
    "# ! Set param values.\n",
    "\n",
    "# ==> start and end dates\n",
    "#start_pub_date = \"2009-12-06\"\n",
    "#end_pub_date = \"2009-12-12\"\n",
    "\n",
    "# ==> tagged articles\n",
    "#tag_in_list = \"prelim_reliability\"\n",
    "#tag_in_list = \"prelim_network\"\n",
    "#tag_in_list = \"prelim_unit_test_007\"\n",
    "#tag_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tag_in_list = [ \"prelim_reliability_test\" ] # 60 articles - Grand Rapids only.\n",
    "#tag_in_list = [ \"prelim_reliability_combined\" ] # 87 articles, Grand Rapids and Detroit.\n",
    "#tag_in_list = [ \"prelim_training_001\" ]\n",
    "tag_in_list = [ \"grp_month\" ]\n",
    "\n",
    "# ==> IDs of newspapers to include.\n",
    "#paper_id_in_list = \"1\"\n",
    "\n",
    "# ==> names of sections to include.\n",
    "#section_list = \"Lakeshore,Front Page,City and Region,Business\"\n",
    "\n",
    "# ==> just limit to specific articles by ID.\n",
    "#article_id_in_list = [ 360962 ]\n",
    "#article_id_in_list = [ 28598 ]\n",
    "#article_id_in_list = [ 21653, 21756 ]\n",
    "#article_id_in_list = [ 90948 ]\n",
    "#article_id_in_list = [ 21627, 21609, 21579 ]\n",
    "#article_id_in_list = [ 48778 ]\n",
    "#article_id_in_list = [ 6065 ]\n",
    "#article_id_in_list = [ 221858 ]\n",
    "#article_id_in_list = [ 23804, 22630 ]\n",
    "article_id_in_list = [ 23804 ]\n",
    "\n",
    "# filter parameters\n",
    "params[ ArticleCoding.PARAM_START_DATE ] = start_pub_date\n",
    "params[ ArticleCoding.PARAM_END_DATE ] = end_pub_date\n",
    "params[ ArticleCoding.PARAM_TAG_LIST ] = tag_in_list\n",
    "params[ ArticleCoding.PARAM_PUBLICATION_LIST ] = paper_id_in_list\n",
    "params[ ArticleCoding.PARAM_SECTION_LIST ] = section_list\n",
    "params[ ArticleCoding.PARAM_ARTICLE_ID_LIST ] = article_id_in_list\n",
    "\n",
    "# set coder you want to use.\n",
    "\n",
    "# OpenCalais REST API v.2\n",
    "params[ ArticleCoding.PARAM_CODER_TYPE ] = ArticleCoding.ARTICLE_CODING_IMPL_OPEN_CALAIS_API_V2\n",
    "\n",
    "# get instance of ArticleCoding\n",
    "my_article_coding = ArticleCoding()\n",
    "my_article_coding.do_print_updates = do_i_print_updates\n",
    "\n",
    "# set params\n",
    "my_article_coding.store_parameters( params )\n",
    "\n",
    "# create query set - ArticleCoding does the filtering for you.\n",
    "article_qs = my_article_coding.create_article_query_set()\n",
    "\n",
    "# limit for an initial test?\n",
    "if ( ( limit_to is not None ) and ( isinstance( limit_to, int ) == True ) and ( limit_to > 0 ) ):\n",
    "\n",
    "    # yes.\n",
    "    article_qs = article_qs[ : limit_to ]\n",
    "\n",
    "#-- END check to see if limit --#\n",
    "\n",
    "# get article count\n",
    "article_count = article_qs.count()\n",
    "\n",
    "print( \"Query params:\" )\n",
    "print( params )\n",
    "print( \"Matching article count: \" + str( article_count ) )\n",
    "\n",
    "# Do coding?\n",
    "if ( do_coding == True ):\n",
    "\n",
    "    print( \"do_coding == True - it's on!\" )\n",
    "\n",
    "    # yes - make sure we have at least one article:\n",
    "    if ( article_count > 0 ):\n",
    "\n",
    "        # invoke the code_article_data( self, query_set_IN ) method.\n",
    "        coding_status = my_article_coding.code_article_data( article_qs )\n",
    "    \n",
    "        # output status\n",
    "        print( \"\\n\\n==============================\\n\\nCoding status: \\\"\" + coding_status + \"\\\"\" )\n",
    "        \n",
    "        # get success count\n",
    "        success_count = my_article_coding.get_success_count()\n",
    "        print( \"\\n\\n====> Count of articles successfully processed: \" + str( success_count ) )    \n",
    "        \n",
    "        # if successes, list out IDs.\n",
    "        if ( success_count > 0 ):\n",
    "        \n",
    "            # there were successes.\n",
    "            success_list = my_article_coding.get_success_list()\n",
    "            print( \"- list of successfully processed articles: \" + str( success_list ) )\n",
    "        \n",
    "        #-- END check to see if successes. --#\n",
    "        \n",
    "        # got errors?\n",
    "        got_errors = my_article_coding.has_errors()\n",
    "        if ( got_errors == True ):\n",
    "        \n",
    "            # get error dictionary\n",
    "            error_dictionary = my_article_coding.get_error_dictionary()\n",
    "            \n",
    "            # get error count\n",
    "            error_count = len( error_dictionary )\n",
    "            print( \"\\n\\n====> Count of articles with errors: \" + str( error_count ) )\n",
    "            \n",
    "            # loop...\n",
    "            for error_article_id, error_status_list in six.iteritems( error_dictionary ):\n",
    "            \n",
    "                # output errors for this article.\n",
    "                print( \"- errors for article ID \" + str( error_article_id ) + \":\" )\n",
    "                \n",
    "                # loop over status messages.\n",
    "                error_status_counter = 0\n",
    "                for error_status in error_status_list:\n",
    "                \n",
    "                    # increment status\n",
    "                    error_status_counter += 1\n",
    "\n",
    "                    # print status\n",
    "                    print( \"----> status #\" + str( error_status_counter ) + \": \" + error_status )\n",
    "                    \n",
    "                #-- END loop over status messages. --#\n",
    "            \n",
    "            #-- END loop over articles. --#\n",
    "   \n",
    "        #-- END check to see if errors --#\n",
    "    \n",
    "    #-- END check to see if article count. --#\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # output matching article count.\n",
    "    print( \"do_coding == False, so dry run\" )\n",
    "    \n",
    "#-- END check to see if we do_coding --#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
