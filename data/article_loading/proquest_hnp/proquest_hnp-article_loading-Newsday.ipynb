{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---logging\" data-toc-modified-id=\"Setup---logging-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - logging</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li><li><span><a href=\"#Setup---Initialize-LoggingHelper\" data-toc-modified-id=\"Setup---Initialize-LoggingHelper-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Setup - Initialize LoggingHelper</a></span></li></ul></li><li><span><a href=\"#Find-articles-to-be-loaded\" data-toc-modified-id=\"Find-articles-to-be-loaded-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Find articles to be loaded</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-setup---working-folder-paths\" data-toc-modified-id=\"Loading-setup---working-folder-paths-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Loading setup - working folder paths</a></span></li><li><span><a href=\"#Uncompress-files\" data-toc-modified-id=\"Uncompress-files-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Uncompress files</a></span></li><li><span><a href=\"#Work-with-uncompressed-files\" data-toc-modified-id=\"Work-with-uncompressed-files-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Work with uncompressed files</a></span></li><li><span><a href=\"#load-a-file-into-memory.\" data-toc-modified-id=\"load-a-file-into-memory.-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>load a file into memory.</a></span></li></ul></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>TODO</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This is a notebook that expands on the OpenCalais code in the file `article_coding.py`, also in this folder.  It includes more sections on selecting publications you want to submit to OpenCalais as an example.  It is intended to be copied and re-used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:44:53.493847Z",
     "start_time": "2019-08-07T02:44:53.488073Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:44:54.465823Z",
     "start_time": "2019-08-07T02:44:54.451053Z"
    }
   },
   "outputs": [],
   "source": [
    "# python packages\n",
    "import datetime\n",
    "import glob\n",
    "import logging\n",
    "import lxml\n",
    "import os\n",
    "import six\n",
    "import xml\n",
    "import xmltodict\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:44:55.682349Z",
     "start_time": "2019-08-07T02:44:55.675918Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = '/home/jonathanmorgan/logs/django-research-data_load-Newsday.log.txt',\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:44:59.890066Z",
     "start_time": "2019-08-07T02:44:59.873516Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:45:02.348510Z",
     "start_time": "2019-08-07T02:45:00.953490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2019-08-07 02:45:02.344557\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:45:02.563901Z",
     "start_time": "2019-08-07T02:45:02.354009Z"
    }
   },
   "outputs": [],
   "source": [
    "# context_text imports\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Subject\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize LoggingHelper\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Create a LoggingHelper instance to use to log debug and also print at the same time.\n",
    "\n",
    "Preconditions: Must be run after Django is initialized, since `python_utilities` is in the django path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:45:15.892494Z",
     "start_time": "2019-08-07T02:45:15.869519Z"
    }
   },
   "outputs": [],
   "source": [
    "# python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# init\n",
    "my_logging_helper = LoggingHelper()\n",
    "my_logging_helper.set_logger_name( \"proquest_hnp-article-loading-Newsday\" )\n",
    "log_message = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find articles to be loaded\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Specify which folder of XML files should be loaded into system, then process all files within the folder.\n",
    "\n",
    "The compressed archives from proquest_hnp just contain publication XML files, no containing folder.\n",
    "\n",
    "To process:\n",
    "\n",
    "- **uncompresed paper folder ( `<paper_folder>` )** - make a folder in `/mnt/hgfs/projects/phd/proquest_hnp/uncompressed` for the paper whose data you are working with, named the same as the paper's folder in `/mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data`.\n",
    "\n",
    "    - for example, for the Boston Globe, name it \"`BostonGlobe`\".\n",
    "\n",
    "- **uncompressed archive folder ( `<archive_folder>` )** - inside a given paper's folder in uncompressed, for each archive file, create a folder named the same as the archive file, but with no \".zip\" at the end.\n",
    "\n",
    "    - For example, for the file \"`BG_20171002210239_00001.zip`\", make a folder named \"`BG_20171002210239_00001`\".\n",
    "    - path should be \"`<paper_folder>/<archive_name_no_zip>`.\n",
    "\n",
    "- unzip the archive into this folder:\n",
    "\n",
    "        unzip <path_to_zip> -d <archive_folder>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading setup - working folder paths\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "What data are we looking at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:45:20.275260Z",
     "start_time": "2019-08-07T02:45:20.263086Z"
    }
   },
   "outputs": [],
   "source": [
    "# paper identifier\n",
    "paper_identifier = \"Newsday\"\n",
    "archive_identifier = None\n",
    "\n",
    "# source\n",
    "source_paper_folder = \"/mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data\"\n",
    "source_paper_path = \"{}/{}\".format( source_paper_folder, paper_identifier )\n",
    "source_archive_file = \"{}.zip\".format( archive_identifier )\n",
    "source_archive_path = \"{}/{}\".format( source_paper_path, source_archive_file )\n",
    "\n",
    "# uncompressed\n",
    "uncompressed_paper_folder = \"/mnt/hgfs/projects/phd/proquest_hnp/uncompressed\"\n",
    "uncompressed_paper_path = \"{}/{}\".format( uncompressed_paper_folder, paper_identifier )\n",
    "\n",
    "# make sure an identifier is set before you make a path here.\n",
    "if ( ( archive_identifier is not None ) and ( archive_identifier != \"\" ) ):\n",
    "    \n",
    "    # identifier is set.\n",
    "    uncompressed_archive_path = \"{}/{}\".format( uncompressed_paper_path, archive_identifier )\n",
    "\n",
    "#-- END check to see if archive_identifier present. --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncompress files\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "See if the uncompressed paper folder exists.  If not, set flag and create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T02:45:24.577770Z",
     "start_time": "2019-08-07T02:45:24.546648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED - Uncompressed paper folder /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "did_uncomp_paper_folder_exist = False\n",
    "\n",
    "# check if uncompressed paper folder exists.\n",
    "if not os.path.exists( uncompressed_paper_path ):\n",
    "    \n",
    "    # no.  Make it.\n",
    "    os.makedirs( uncompressed_paper_path )\n",
    "    did_uncomp_paper_folder_exist = False\n",
    "    log_message = \"CREATED - Uncompressed paper folder {}\".format( uncompressed_paper_path )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # yes.  Set flag.\n",
    "    did_uncomp_paper_folder_exist = True\n",
    "    log_message = \"EXISTS - Uncompressed paper folder {}\".format( uncompressed_paper_path )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "    \n",
    "#-- END check to see if paper folder exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each *.zip file in the paper's source folder:\n",
    "\n",
    "- parse file name from path returned by glob.\n",
    "- parse the part before \".zip\" from the file name.  This is referred to subsequently as the \"archive identifier\".\n",
    "- check if folder named the same as the \"archive identifier\" is present.\n",
    "\n",
    "    - If no:\n",
    "    \n",
    "        - create it.\n",
    "        - then, uncompress the archive into it.\n",
    "        \n",
    "    - If yes:\n",
    "    \n",
    "        - output a message.  Don't want to uncompress if it was already uncompressed once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T02:52:59.372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> zip file count: 194\n",
      "----> processing file 1 of 194\n",
      "==> path: /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220113_00001.zip\n",
      "==> file: Newsday_20171006220113_00001.zip\n",
      "==> ID: Newsday_20171006220113_00001\n",
      "==> TO: /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220113_00001\n",
      "CREATED - Uncompressed archive folder /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220113_00001\n",
      "==> extract started at 2019-08-07 02:52:59.761334\n",
      "EXTRACTED - /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220113_00001.zip\n",
      "TO uncompressed archive folder - /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220113_00001\n",
      "==> extract completed at 2019-08-07 02:53:58.689399\n",
      "==> time elapsed: 0:00:58.928065\n",
      "------------------------------\n",
      "----> processing file 2 of 194\n",
      "==> path: /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220215_00002.zip\n",
      "==> file: Newsday_20171006220215_00002.zip\n",
      "==> ID: Newsday_20171006220215_00002\n",
      "==> TO: /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220215_00002\n",
      "CREATED - Uncompressed archive folder /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220215_00002\n",
      "==> extract started at 2019-08-07 02:53:59.085531\n",
      "EXTRACTED - /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220215_00002.zip\n",
      "TO uncompressed archive folder - /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220215_00002\n",
      "==> extract completed at 2019-08-07 02:54:57.615758\n",
      "==> time elapsed: 0:00:58.530227\n",
      "------------------------------\n",
      "----> processing file 3 of 194\n",
      "==> path: /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220218_00003.zip\n",
      "==> file: Newsday_20171006220218_00003.zip\n",
      "==> ID: Newsday_20171006220218_00003\n",
      "==> TO: /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220218_00003\n",
      "CREATED - Uncompressed archive folder /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220218_00003\n",
      "==> extract started at 2019-08-07 02:54:58.014217\n",
      "EXTRACTED - /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220218_00003.zip\n",
      "TO uncompressed archive folder - /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220218_00003\n",
      "==> extract completed at 2019-08-07 02:55:54.334288\n",
      "==> time elapsed: 0:00:56.320071\n",
      "------------------------------\n",
      "----> processing file 4 of 194\n",
      "==> path: /mnt/hgfs/projects/phd/proquest_hnp/proquest_hnp/data/Newsday/Newsday_20171006220219_00004.zip\n",
      "==> file: Newsday_20171006220219_00004.zip\n",
      "==> ID: Newsday_20171006220219_00004\n",
      "==> TO: /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220219_00004\n",
      "CREATED - Uncompressed archive folder /mnt/hgfs/projects/phd/proquest_hnp/uncompressed/Newsday/Newsday_20171006220219_00004\n",
      "==> extract started at 2019-08-07 02:55:54.669099\n"
     ]
    }
   ],
   "source": [
    "# declare variables - papers\n",
    "did_uncomp_paper_folder_exist = None\n",
    "\n",
    "# declare variables archive (.zip) files.\n",
    "zip_file_list = None\n",
    "zip_file_path = None\n",
    "zip_file_path_parts_list = None\n",
    "zip_file_name = None\n",
    "zip_file_name_parts_list = None\n",
    "archive_identifier = None\n",
    "uc_archive_folder_path = None\n",
    "zip_file = None\n",
    "\n",
    "# declare variables - auditing (uc = uncompressed)\n",
    "archive_file_counter = None\n",
    "did_uc_archive_folder_exist = None\n",
    "uc_folder_exists_counter = None\n",
    "start_dt = None\n",
    "end_dt = None\n",
    "time_delta = None\n",
    "\n",
    "# use glob to get list of zip files in paper source folder.\n",
    "zip_file_list = glob.glob( \"{}/*.zip\".format( source_paper_path ) )\n",
    "zip_file_count = len( zip_file_list )\n",
    "\n",
    "log_message = \"==> zip file count: {}\".format( zip_file_count )\n",
    "my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "\n",
    "# loop over zip files.\n",
    "archive_file_counter = 0\n",
    "did_uc_archive_folder_exist = False\n",
    "uc_folder_exists_counter = 0\n",
    "for zip_file_path in zip_file_list:\n",
    "    \n",
    "    # increment counter\n",
    "    archive_file_counter += 1\n",
    "    \n",
    "    log_message = \"----> processing file {} of {}\".format( archive_file_counter, zip_file_count )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "    \n",
    "    # get file name\n",
    "    \n",
    "    # split path into parts on path separator.\n",
    "    zip_file_path_parts_list = zip_file_path.split( \"/\" )\n",
    "\n",
    "    # file name is the last thing in the list.\n",
    "    zip_file_name = zip_file_path_parts_list[ -1 ]\n",
    "\n",
    "    # archive_identifier is name with \".zip\" removed from end.\n",
    "    zip_file_name_parts_list = zip_file_name.split( \".zip\" )\n",
    "    archive_identifier = zip_file_name_parts_list[ 0 ]\n",
    "    \n",
    "    # for now, log and print the things we've just created.\n",
    "    log_message = \"==> path: {}\".format( zip_file_path )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "    log_message = \"==> file: {}\".format( zip_file_name )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "    log_message = \"==> ID: {}\".format( archive_identifier )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "\n",
    "    # check if uncompressed archive folder exists.\n",
    "    uc_archive_folder_path = \"{}/{}\".format( uncompressed_paper_path, archive_identifier )\n",
    "\n",
    "    log_message = \"==> TO: {}\".format( uc_archive_folder_path )\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "\n",
    "    # check if the uncompressed archive folder exists.\n",
    "    did_uc_archive_folder_exist = os.path.exists( uc_archive_folder_path )\n",
    "    if did_uc_archive_folder_exist == False:\n",
    "\n",
    "        # no.  Make it.\n",
    "        os.makedirs( uc_archive_folder_path )\n",
    "        log_message = \"CREATED - Uncompressed archive folder {}\".format( uc_archive_folder_path )\n",
    "        my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "        \n",
    "        # and uncompress archive to it.\n",
    "        with zipfile.ZipFile( zip_file_path, 'r' ) as zip_file:\n",
    "\n",
    "            # starting extract.\n",
    "            start_dt = datetime.datetime.now()\n",
    "            log_message = \"==> extract started at {}\".format( start_dt )\n",
    "            my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "            \n",
    "            # unzip to uncompressed archive folder path.\n",
    "            zip_file.extractall( uc_archive_folder_path )\n",
    "            \n",
    "            log_message = \"EXTRACTED - {}\".format( zip_file_path )\n",
    "            my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "\n",
    "            log_message = \"TO uncompressed archive folder - {}\".format( uc_archive_folder_path )\n",
    "            my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "            \n",
    "            # complete\n",
    "            end_dt = datetime.datetime.now()\n",
    "            \n",
    "            log_message = \"==> extract completed at {}\".format( end_dt )\n",
    "            my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "            \n",
    "            log_message = \"==> time elapsed: {}\".format( end_dt - start_dt )\n",
    "            my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "            \n",
    "        #-- END with ZipFile --#\n",
    "\n",
    "    else:\n",
    "\n",
    "        # yes.  Set flag.\n",
    "        uc_folder_exists_counter += 1\n",
    "        log_message = \"EXISTS, so moving on - Uncompressed archive folder {}\".format( uncompressed_archive_path )\n",
    "        my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "\n",
    "    #-- END check to see if archive folder exists. --#\n",
    "\n",
    "    log_message = \"------------------------------\"\n",
    "    my_logging_helper.output_debug_message( log_message, do_print_IN = True )\n",
    "\n",
    "#-- END loop over zip files. --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with uncompressed files\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Change working directories to the uncompressed paper path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:50:23.122899Z",
     "start_time": "2019-08-05T17:50:23.079535Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd $uncompressed_paper_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:50:47.438640Z",
     "start_time": "2019-08-05T17:50:43.331622Z"
    }
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load a file into memory.\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Load one of the files into memory and see what we can do with it.  Beautiful Soup?\n",
    "\n",
    "Looks like the root element is \"Record\", then the high-level type of the article is \"ObjectType\".\n",
    "\n",
    "ObjectType values:\n",
    "\n",
    "- Advertisement\n",
    "- ...\n",
    "\n",
    "Good options for XML parser:\n",
    "\n",
    "- `lxml.etree` - [https://stackoverflow.com/questions/12290091/reading-xml-file-and-fetching-its-attributes-value-in-python](https://stackoverflow.com/questions/12290091/reading-xml-file-and-fetching-its-attributes-value-in-python)\n",
    "- `xmltodict` - [https://docs.python-guide.org/scenarios/xml/](https://docs.python-guide.org/scenarios/xml/)\n",
    "- `beautifulsoup` using `lxml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:59:30.240631Z",
     "start_time": "2019-08-05T18:59:11.488862Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop over files in the current archive folder path.\n",
    "\n",
    "# declare variables\n",
    "xml_file_list = None\n",
    "xml_file_path = None\n",
    "xml_file = None\n",
    "xml_dict = None\n",
    "xml_file_counter = None\n",
    "object_type_to_count_map = None\n",
    "object_type_count = None\n",
    "record_node = None\n",
    "object_type_node = None\n",
    "object_type_list = None\n",
    "object_type = None\n",
    "\n",
    "# declare variables - auditing\n",
    "xml_file_counter = None\n",
    "no_record_counter = None\n",
    "no_object_type_counter = None\n",
    "no_object_type_text_counter = None\n",
    "\n",
    "# init\n",
    "object_type_to_count_map = {}\n",
    "\n",
    "# get file list.\n",
    "xml_file_list = glob.glob( \"{}/*.xml\".format( uc_archive_folder_path ) )\n",
    "\n",
    "# loop\n",
    "xml_file_counter = 0\n",
    "no_record_counter = 0\n",
    "no_object_type_counter = 0\n",
    "no_object_type_text_counter = 0\n",
    "for xml_file_path in xml_file_list:\n",
    "    \n",
    "    xml_file_counter += 1\n",
    "    \n",
    "    # try to parse the file\n",
    "    with open( xml_file_path ) as xml_file:\n",
    "    \n",
    "        # parse XML\n",
    "        xml_dict = xmltodict.parse( xml_file.read() )\n",
    "        \n",
    "        # get root.Record.ObjectType value\n",
    "        record_node = xml_dict.get( \"Record\", None )\n",
    "        \n",
    "        if ( record_node is not None ):\n",
    "            \n",
    "            # get object type (looks like xmltodict stores\n",
    "            #     elements with no attributes and no child\n",
    "            #     elements just as a string contents mapped\n",
    "            #     to name in parent, no dictionary)\n",
    "            #\n",
    "            # so for:\n",
    "            # <Record>\n",
    "            #     ...\n",
    "            #     <ObjectType>Advertisement</ObjectType>\n",
    "            #     ...\n",
    "            # </Record>\n",
    "            #\n",
    "            # to get value:\n",
    "            #     record_node = xml_dict.get( \"Record\", None )\n",
    "            #     object_type_list = record_node.get( \"ObjectType\", None )\n",
    "            #     object_type = \"|\".join( object_type_list )\n",
    "            #\n",
    "            # NOT:\n",
    "            #     record_node = xml_dict.get( \"Record\", None )\n",
    "            #     object_type_node = record_node.get( \"ObjectType\", None )\n",
    "            #     object_type = object_type_node.get( \"#text\", None )\n",
    "            #\n",
    "            # Doc that led me astray: https://docs.python-guide.org/scenarios/xml/\n",
    "            object_type_list = record_node.get( \"ObjectType\", None )\n",
    "            object_type = \"|\".join( object_type_list )\n",
    "\n",
    "            # got a type?\n",
    "            if ( ( object_type is not None ) and ( object_type != \"\" ) ):\n",
    "\n",
    "                # we do.  Increment count.\n",
    "                object_type_count = object_type_to_count_map.get( object_type, 0 )\n",
    "                object_type_count += 1\n",
    "                object_type_to_count_map[ object_type ] = object_type_count\n",
    "\n",
    "            else:\n",
    "\n",
    "                # object type is None\n",
    "                no_object_type_text_counter += 1\n",
    "\n",
    "            #-- END check for type value --#\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # increment counter\n",
    "            no_record_counter += 1\n",
    "            \n",
    "        #-- END check if we found a \"Record\" node in root --#\n",
    "\n",
    "    #-- END with open( xml_file_path )...: --#\n",
    "    \n",
    "#-- END loop over XML files --#\n",
    "\n",
    "print( \"XML file count: {}\".format( len( xml_file_list ) ) )\n",
    "print( \"Counters:\" )\n",
    "print( \"- Processed {} files\".format( xml_file_counter ) )\n",
    "print( \"- No Record: {}\".format( no_record_counter ) )\n",
    "print( \"- No ObjectType: {}\".format( no_object_type_counter ) )\n",
    "print( \"- No ObjectType value: {}\".format( no_object_type_text_counter ) )\n",
    "print( \"\\nObjectType values and occurrence counts:\")\n",
    "for object_type, object_type_count in six.iteritems( object_type_to_count_map ):\n",
    "    \n",
    "    # print type and count\n",
    "    print( \"- {}: {}\".format( object_type, object_type_count ) )\n",
    "    \n",
    "#-- END loop over object types. --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- create bash script to uncompress all files in a folder from data to uncompressed, when passed paper and archive identifiers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
