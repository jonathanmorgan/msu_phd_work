{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R - grp_month - sna-author_info - full_month**\n",
    "\n",
    "_2017.12.07 - work log - prelim - R - grp month_\n",
    "\n",
    "From `sna-author_info.r`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup----working-directories\" data-toc-modified-id=\"Setup----working-directories-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup -  working directories</a></span></li><li><span><a href=\"#Setup---load-workspace\" data-toc-modified-id=\"Setup---load-workspace-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Setup - load workspace</a></span></li><li><span><a href=\"#Setup---put-data-in-expected-variables\" data-toc-modified-id=\"Setup---put-data-in-expected-variables-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup - put data in expected variables</a></span></li></ul></li><li><span><a href=\"#Calculate-Author-Info.\" data-toc-modified-id=\"Calculate-Author-Info.-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Calculate Author Info.</a></span></li><li><span><a href=\"#Save-workspace-image\" data-toc-modified-id=\"Save-workspace-image-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Save workspace image</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup -  working directories\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Store important directories and file names in variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:05:58.153359Z",
     "start_time": "2018-04-17T22:05:58.004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods/network_analysis/author_info'"
      ],
      "text/latex": [
       "'/home/jonathanmorgan/work/sourcenet/django/research/work/msu\\_phd\\_work/methods/network\\_analysis/author\\_info'"
      ],
      "text/markdown": [
       "'/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods/network_analysis/author_info'"
      ],
      "text/plain": [
       "[1] \"/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods/network_analysis/author_info\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:05:59.315392Z",
     "start_time": "2018-04-17T22:05:59.314Z"
    }
   },
   "outputs": [],
   "source": [
    "# code files (in particular SNA function library, modest though it may be)\n",
    "code_directory <- \"/home/jonathanmorgan/work/sourcenet/django/research/sourcenet_analysis/R/sna\"\n",
    "sna_function_file_path <- paste( code_directory, \"/\", 'functions-sna.r', sep = \"\" )\n",
    "\n",
    "# home directory\n",
    "home_directory <- getwd()\n",
    "home_directory <- \"/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods\"\n",
    "\n",
    "# data directories\n",
    "data_directory <- paste( home_directory, \"/data\", sep = \"\" )\n",
    "workspace_file_name <- \"statnet-grp_month.RData\"\n",
    "workspace_file_path <- paste( data_directory, \"/\", workspace_file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:06:02.089455Z",
     "start_time": "2018-04-17T22:06:02.118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods/data'"
      ],
      "text/latex": [
       "'/home/jonathanmorgan/work/sourcenet/django/research/work/msu\\_phd\\_work/methods/data'"
      ],
      "text/markdown": [
       "'/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods/data'"
      ],
      "text/plain": [
       "[1] \"/home/jonathanmorgan/work/sourcenet/django/research/work/msu_phd_work/methods/data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set working directory to data directory for now.\n",
    "setwd( data_directory )\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - load workspace\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In the original file, it assumed you'd just source it after running other stuff.  Here, we have done that other stuff in another notebook, now we need to reload the workspace in which it was done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:06:04.944498Z",
     "start_time": "2018-04-17T22:06:03.858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading workspace : statnet-grp_month.RData\n"
     ]
    }
   ],
   "source": [
    "# assumes that you've already set working directory above to the\n",
    "#     working directory.\n",
    "setwd( data_directory )\n",
    "message( paste( \"Loading workspace : \", workspace_file_name, sep = \"\" ) )\n",
    "load( workspace_file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:08:05.868134Z",
     "start_time": "2018-04-17T22:08:05.904Z"
    }
   },
   "outputs": [],
   "source": [
    "# output workspace\n",
    "output_workspace_file_name <- workspace_file_name\n",
    "output_workspace_file_path <- paste( data_directory, \"/\", output_workspace_file_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - put data in expected variables\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Load original network data dataframes into humanNetworkDataDF and automatedNetworkDataDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:08:12.763429Z",
     "start_time": "2018-04-17T22:08:12.798Z"
    }
   },
   "outputs": [],
   "source": [
    "# in statsnet files, orginal automated data was loaded into gmAutomatedDataDF\n",
    "automatedNetworkDataDF <- gmAutomatedDataDF\n",
    "\n",
    "# original human data was loaded into gmHumanDataDF\n",
    "humanNetworkDataDF <- gmHumanDataDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Author Info.\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The original file on which this is based is: `sourcenet/R/sna/sna-author_info.r`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- `humanNetworkDataDF` is original data DataFrame (`gmHumanDataDF`, etc.).\n",
    "- `automatedNetworkDataDF` is original data DataFrame (`gmAutomatedDataDF`, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:08:15.148386Z",
     "start_time": "2018-04-17T22:08:14.972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = sharedCount ~ sourceCount + articleCount, data = humanAuthorsDF)\n",
       "\n",
       "Coefficients:\n",
       " (Intercept)   sourceCount  articleCount  \n",
       "    -0.54250       0.24345       0.02411  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = sharedCount ~ sourceCount + articleCount, data = automatedAuthorsDF)\n",
       "\n",
       "Coefficients:\n",
       " (Intercept)   sourceCount  articleCount  \n",
       "    -0.42119       0.22519       0.03037  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For this to work, you'll need to have run either of the following, including\n",
    "#    all of the prerequisite files listed in each file:\n",
    "#    - sourcenet/R/igraph/sna-igraph-network_stats.r\n",
    "#    - sourcenet/R/statnet/sna-statnet-network_stats.r\n",
    "# Also assumes that you haven't re-ordered the <type>NetworkData data frames.\n",
    "\n",
    "#==============================================================================#\n",
    "# information for all authors - source_type = 2 (reporter) or 4 (both source and reporter)\n",
    "#==============================================================================#\n",
    "\n",
    "# source_type = 2 (reporter) or 4 (both source and reporter)\n",
    "\n",
    "# human - all authors\n",
    "humanAuthorsNetworkData <- humanNetworkDataDF[ humanNetworkDataDF$person_type == 2 | humanNetworkDataDF$person_type == 4, ]\n",
    "humanAuthorsCount <- nrow( humanAuthorsNetworkData )\n",
    "humanAuthorsMeanDegree <- mean( humanAuthorsNetworkData$degree )\n",
    "humanAuthorsMaxDegree <- max( humanAuthorsNetworkData$degree )\n",
    "humanAuthorsMeanTieWeightGE0 <- mean( humanAuthorsNetworkData$meanTieWeightGE0 )\n",
    "humanAuthorsMeanTieWeightGE1 <- mean( humanAuthorsNetworkData$meanTieWeightGE1 )\n",
    "humanAuthorsMaxTieWeight <- max( humanAuthorsNetworkData$maxTieWeight )\n",
    "\n",
    "# automated - all authors\n",
    "automatedAuthorsNetworkData <- automatedNetworkDataDF[ automatedNetworkDataDF$person_type == 2 | automatedNetworkDataDF$person_type == 4, ]\n",
    "automatedAuthorsCount <- nrow( automatedAuthorsNetworkData )\n",
    "automatedAuthorsMeanDegree <- mean( automatedAuthorsNetworkData$degree )\n",
    "automatedAuthorsMaxDegree <- max( automatedAuthorsNetworkData$degree )\n",
    "automatedAuthorsMeanTieWeightGE0 <- mean( automatedAuthorsNetworkData$meanTieWeightGE0 )\n",
    "automatedAuthorsMeanTieWeightGE1 <- mean( automatedAuthorsNetworkData$meanTieWeightGE1 )\n",
    "automatedAuthorsMaxTieWeight <- max( automatedAuthorsNetworkData$maxTieWeight )\n",
    "\n",
    "#==============================================================================#\n",
    "# Generate information on individual reporters who have shared sources (subset\n",
    "#    of all authors).\n",
    "#==============================================================================#\n",
    "\n",
    "# human - subsetting based on position of authors who had shared sources.\n",
    "#humanAuthorsSharedNetworkData <- humanNetworkDataDF[ c( 3, 6, 9, 11, 12, 13, 14, 16, 21, 43, 44, 63, 169, 310 ), ]\n",
    "\n",
    "# subsetting based on person IDs.\n",
    "humanAuthorsSharedIDs <- c( 387, 2310, 394, 13, 3, 46, 23, 29, 30, 36, 425, 302, 178, 437, 1082, 443, 377, 66, 69, 161, 73, 74, 460, 591, 336, 84, 598, 599, 217, 223, 937, 1655, 332, 505 )\n",
    "humanAuthorsSharedNetworkData <- humanNetworkDataDF[ humanNetworkDataDF$person_id %in% humanAuthorsSharedIDs , ]\n",
    "\n",
    "# human - make data\n",
    "humanAuthorsSharedCount <- nrow( humanAuthorsSharedNetworkData )\n",
    "humanAuthorsSharedMeanDegree <- mean( humanAuthorsSharedNetworkData$degree )\n",
    "humanAuthorsSharedMaxDegree <- max( humanAuthorsSharedNetworkData$degree )\n",
    "humanAuthorsSharedMeanTieWeightGE0 <- mean( humanAuthorsSharedNetworkData$meanTieWeightGE0 )\n",
    "humanAuthorsSharedMeanTieWeightGE1 <- mean( humanAuthorsSharedNetworkData$meanTieWeightGE1 )\n",
    "humanAuthorsSharedMaxTieWeight <- max( humanAuthorsSharedNetworkData$maxTieWeight )\n",
    "\n",
    "# automated - subsetting based on position of authors who had shared sources.\n",
    "#automatedAuthorsSharedNetworkData <- automatedNetworkDataDF[ c( 3, 6, 9, 11, 12, 13, 16, 21, 44, 63, 169, 310 ), ]\n",
    "\n",
    "# subsetting based on person IDs.\n",
    "automatedAuthorsSharedIDs <- c( 387, 2310, 394, 13, 3, 46, 23, 30, 36, 425, 2614, 302, 178, 437, 1082, 443, 377, 66, 69, 161, 73, 74, 460, 591, 336, 84, 598, 599, 217, 223, 1655, 332, 505 )\n",
    "automatedAuthorsSharedNetworkData <- automatedNetworkDataDF[ automatedNetworkDataDF$person_id %in% automatedAuthorsSharedIDs , ]\n",
    "\n",
    "# automated - make data\n",
    "automatedAuthorsSharedCount <- nrow( automatedAuthorsSharedNetworkData )\n",
    "automatedAuthorsSharedMeanDegree <- mean( automatedAuthorsSharedNetworkData$degree )\n",
    "automatedAuthorsSharedMaxDegree <- max( automatedAuthorsSharedNetworkData$degree )\n",
    "automatedAuthorsSharedMeanTieWeightGE0 <- mean( automatedAuthorsSharedNetworkData$meanTieWeightGE0 )\n",
    "automatedAuthorsSharedMeanTieWeightGE1 <- mean( automatedAuthorsSharedNetworkData$meanTieWeightGE1 )\n",
    "automatedAuthorsSharedMaxTieWeight <- max( automatedAuthorsSharedNetworkData$maxTieWeight )\n",
    "\n",
    "#==============================================================================#\n",
    "# Do some regression to see if article or source count predict source sharing.\n",
    "#==============================================================================#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# first, set up data frames (from results of running python script:\n",
    "#    sourcenet/examples/analysis/analysis-person_info.py)\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "# human coder (index 1), all authors.\n",
    "humanIdVector <- c( 387, 2310, 2567, 394, 652, 13, 654, 3, 46, 23, 2004, 29, 30, 417, 36, 425, 2614, 302, 178, 437, 566, 1082, 443, 377, 66, 69, 161, 73, 74, 460, 482, 591, 336, 84, 598, 599, 217, 223, 736, 2018, 743, 937, 1782, 1655, 332, 505, 703, 637 )\n",
    "humanSourceCountsVector <- c( 18, 2, 0, 33, 9, 36, 3, 27, 57, 31, 4, 50, 28, 4, 31, 30, 5, 31, 41, 45, 4, 13, 43, 36, 92, 43, 37, 30, 46, 3, 1, 76, 9, 64, 21, 50, 46, 18, 2, 5, 2, 7, 4, 6, 7, 18, 2, 13 )\n",
    "humanSharedCountsVector <- c( 7, 2, 0, 2, 0, 1, 0, 9, 22, 12, 0, 2, 2, 0, 9, 2, 0, 3, 6, 13, 0, 5, 9, 10, 37, 19, 12, 10, 5, 1, 0, 6, 2, 19, 5, 4, 13, 9, 0, 0, 0, 7, 0, 6, 1, 1, 0, 0 )\n",
    "humanArticleCountsVector <- c( 7, 1, 1, 8, 5, 17, 1, 13, 21, 15, 2, 18, 13, 4, 11, 10, 1, 12, 13, 15, 1, 8, 16, 17, 30, 15, 14, 12, 19, 4, 1, 25, 4, 27, 9, 17, 18, 6, 1, 1, 1, 1, 4, 1, 4, 8, 2, 4 )\n",
    "humanAuthorsDF <- data.frame( humanIdVector, humanSourceCountsVector, humanSharedCountsVector, humanArticleCountsVector )\n",
    "names( humanAuthorsDF ) <- c( \"authorID\", \"sourceCount\", \"sharedCount\", \"articleCount\" )\n",
    "\n",
    "# human coder, only authors with shared sources.\n",
    "humanSharedIdVector <- c( 387, 2310, 394, 13, 3, 46, 23, 29, 30, 36, 425, 302, 178, 437, 1082, 443, 377, 66, 69, 161, 73, 74, 460, 591, 336, 84, 598, 599, 217, 223, 937, 1655, 332, 505 )\n",
    "humanSharedSourceCountsVector <- c( 18, 2, 33, 36, 27, 57, 31, 50, 28, 31, 30, 31, 41, 45, 13, 43, 36, 92, 43, 37, 30, 46, 3, 76, 9, 64, 21, 50, 46, 18, 7, 6, 7, 18 )\n",
    "humanSharedSharedCountsVector <- c( 7, 2, 2, 1, 9, 22, 12, 2, 2, 9, 2, 3, 6, 13, 5, 9, 10, 37, 19, 12, 10, 5, 1, 6, 2, 19, 5, 4, 13, 9, 7, 6, 1, 1 )\n",
    "humanSharedArticleCountsVector <- c( 7, 1, 8, 17, 13, 21, 15, 18, 13, 11, 10, 12, 13, 15, 8, 16, 17, 30, 15, 14, 12, 19, 4, 25, 4, 27, 9, 17, 18, 6, 1, 1, 4, 8 )\n",
    "humanSharedDF <- data.frame( humanSharedIdVector, humanSharedSourceCountsVector, humanSharedSharedCountsVector, humanSharedArticleCountsVector )\n",
    "names( humanSharedDF ) <- c( \"authorID\", \"sourceCount\", \"sharedCount\", \"articleCount\" )\n",
    "\n",
    "# computer coder, all authors.\n",
    "automatedIdVector <- c( 387, 2310, 2567, 394, 652, 13, 654, 3, 46, 23, 2004, 29, 30, 417, 36, 425, 2614, 302, 178, 437, 566, 1082, 443, 377, 66, 69, 161, 73, 74, 460, 482, 591, 336, 84, 598, 599, 217, 223, 736, 2018, 743, 1782, 1655, 332, 505, 703, 637 )\n",
    "automatedSourceCountsVector <- c( 18, 2, 0, 27, 8, 39, 2, 29, 46, 33, 4, 50, 26, 4, 28, 31, 6, 31, 42, 49, 2, 15, 43, 34, 88, 45, 34, 28, 46, 4, 1, 72, 9, 69, 22, 46, 43, 13, 2, 5, 2, 4, 6, 7, 14, 2, 10 )\n",
    "automatedSharedCountsVector <- c( 7, 2, 0, 2, 0, 1, 0, 12, 13, 11, 0, 0, 2, 0, 7, 3, 1, 4, 8, 10, 0, 7, 8, 9, 35, 19, 11, 10, 4, 1, 0, 6, 1, 20, 7, 3, 11, 8, 0, 0, 0, 0, 6, 1, 1, 0, 0 )\n",
    "automatedArticleCountsVector <- c( 7, 1, 1, 8, 5, 17, 1, 13, 20, 15, 2, 18, 13, 4, 11, 10, 1, 12, 13, 15, 1, 8, 16, 17, 30, 15, 14, 12, 19, 4, 1, 25, 4, 27, 9, 17, 18, 6, 1, 1, 1, 4, 1, 4, 8, 2, 4 )\n",
    "automatedAuthorsDF <- data.frame( automatedIdVector, automatedSourceCountsVector, automatedSharedCountsVector, automatedArticleCountsVector )\n",
    "names( automatedAuthorsDF ) <- c( \"authorID\", \"sourceCount\", \"sharedCount\", \"articleCount\" )\n",
    "\n",
    "# computer coder, only authors with shared sources.\n",
    "automatedSharedIdVector <- c( 387, 2310, 394, 13, 3, 46, 23, 30, 36, 425, 2614, 302, 178, 437, 1082, 443, 377, 66, 69, 161, 73, 74, 460, 591, 336, 84, 598, 599, 217, 223, 1655, 332, 505 )\n",
    "automatedSharedSourceCountsVector <- c( 18, 2, 27, 39, 29, 46, 33, 26, 28, 31, 6, 31, 42, 49, 15, 43, 34, 88, 45, 34, 28, 46, 4, 72, 9, 69, 22, 46, 43, 13, 6, 7, 14 )\n",
    "automatedSharedSharedCountsVector <- c( 7, 2, 2, 1, 12, 13, 11, 2, 7, 3, 1, 4, 8, 10, 7, 8, 9, 35, 19, 11, 10, 4, 1, 6, 1, 20, 7, 3, 11, 8, 6, 1, 1 )\n",
    "automatedSharedArticleCountsVector <- c( 7, 1, 8, 17, 13, 20, 15, 13, 11, 10, 1, 12, 13, 15, 8, 16, 17, 30, 15, 14, 12, 19, 4, 25, 4, 27, 9, 17, 18, 6, 1, 4, 8 )\n",
    "automatedSharedDF <- data.frame( automatedSharedIdVector, automatedSharedSourceCountsVector, automatedSharedSharedCountsVector, automatedSharedArticleCountsVector )\n",
    "names( automatedSharedDF ) <- c( \"authorID\", \"sourceCount\", \"sharedCount\", \"articleCount\" )\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# regression\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "# all human-coded authors:\n",
    "humanLmResults <- lm( sharedCount ~ sourceCount + articleCount, data = humanAuthorsDF )\n",
    "humanLmResults\n",
    "\n",
    "# all computer-coded authors:\n",
    "automatedLmResults <- lm( sharedCount ~ sourceCount + articleCount, data = automatedAuthorsDF )\n",
    "automatedLmResults\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# means of counts from python file\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "# Article Count\n",
    "humanAuthorsMeanArticleCount <- mean( humanAuthorsDF$articleCount )\n",
    "humanAuthorsSharedMeanArticleCount <- mean( humanSharedDF$articleCount )\n",
    "automatedAuthorsMeanArticleCount <- mean( automatedAuthorsDF$articleCount )\n",
    "automatedAuthorsSharedMeanArticleCount <- mean( automatedSharedDF$articleCount )\n",
    "\n",
    "# Source Count\n",
    "humanAuthorsMeanSourceCount <- mean( humanAuthorsDF$sourceCount )\n",
    "humanAuthorsSharedMeanSourceCount <- mean( humanSharedDF$sourceCount )\n",
    "automatedAuthorsMeanSourceCount <- mean( automatedAuthorsDF$sourceCount )\n",
    "automatedAuthorsSharedMeanSourceCount <- mean( automatedSharedDF$sourceCount )\n",
    "\n",
    "# Shared Count\n",
    "humanAuthorsMeanSharedCount <- mean( humanAuthorsDF$sharedCount )\n",
    "humanAuthorsSharedMeanSharedCount <- mean( humanSharedDF$sharedCount )\n",
    "automatedAuthorsMeanSharedCount <- mean( automatedAuthorsDF$sharedCount )\n",
    "automatedAuthorsSharedMeanSharedCount <- mean( automatedSharedDF$sharedCount )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:08:16.703986Z",
     "start_time": "2018-04-17T22:08:16.502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "====> HUMAN - all authors\n",
      "human author count = 48\n",
      "human author mean degree = 25.3958333333333\n",
      "human author max degree = 99\n",
      "human author mean tie weight GE0 = 0.0238860325621251\n",
      "human author mean tie weight GE1 = 1.06601763268533\n",
      "human author max tie weight = 8\n",
      "human author mean article count = 9.54166666666667\n",
      "human author mean source count = 24.6458333333333\n",
      "human author mean shared count = 5.6875\n",
      "\n",
      "\n",
      "====> HUMAN - authors with shared sources\n",
      "human shared count = 34\n",
      "human shared mean degree = 34.1470588235294\n",
      "human shared max degree = 99\n",
      "human shared mean tie weight GE0 = 0.0322092847421745\n",
      "human shared mean tie weight GE1 = 1.10463927228779\n",
      "human shared max tie weight = 8\n",
      "human shared mean article count = 12.6176470588235\n",
      "human shared mean source count = 33.0882352941176\n",
      "human shared mean shared count = 8.02941176470588\n",
      "regression results:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = sharedCount ~ sourceCount + articleCount, data = humanAuthorsDF)\n",
      "\n",
      "Coefficients:\n",
      " (Intercept)   sourceCount  articleCount  \n",
      "    -0.54250       0.24345       0.02411  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====> AUTOMATED - all authors\n",
      "automated author count = 47\n",
      "automated author mean degree = 24.7872340425532\n",
      "automated author max degree = 93\n",
      "automated author mean tie weight GE0 = 0.0230997830407118\n",
      "automated author mean tie weight GE1 = 1.06408773176287\n",
      "automated author max tie weight = 8\n",
      "automated author mean article count = 9.70212765957447\n",
      "automated author mean source count = 24.2765957446809\n",
      "automated author mean shared count = 5.34042553191489\n",
      "\n",
      "\n",
      "====> AUTOMATED - authors with shared sources\n",
      "automated shared count = 33\n",
      "automated shared mean degree = 32.3939393939394\n",
      "automated shared max degree = 93\n",
      "automated shared mean tie weight GE0 = 0.0301472306613695\n",
      "automated shared mean tie weight GE1 = 1.0977916179653\n",
      "automated shared max tie weight = 8\n",
      "automated shared mean article count = 12.4242424242424\n",
      "automated shared mean source count = 31.6666666666667\n",
      "automated shared mean shared count = 7.60606060606061\n",
      "regression results:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = sharedCount ~ sourceCount + articleCount, data = automatedAuthorsDF)\n",
      "\n",
      "Coefficients:\n",
      " (Intercept)   sourceCount  articleCount  \n",
      "    -0.42119       0.22519       0.03037  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# output\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "message( \"====> HUMAN - all authors\" )\n",
    "message( paste( \"human author count = \", humanAuthorsCount, sep = \"\" ) )\n",
    "message( paste( \"human author mean degree = \", humanAuthorsMeanDegree, sep = \"\" ) )\n",
    "message( paste( \"human author max degree = \", humanAuthorsMaxDegree, sep = \"\" ) )\n",
    "message( paste( \"human author mean tie weight GE0 = \", humanAuthorsMeanTieWeightGE0, sep = \"\" ) )\n",
    "message( paste( \"human author mean tie weight GE1 = \", humanAuthorsMeanTieWeightGE1, sep = \"\" ) )\n",
    "message( paste( \"human author max tie weight = \", humanAuthorsMaxTieWeight, sep = \"\" ) )\n",
    "message( paste( \"human author mean article count = \", humanAuthorsMeanArticleCount, sep = \"\" ) )\n",
    "message( paste( \"human author mean source count = \", humanAuthorsMeanSourceCount, sep = \"\" ) )\n",
    "message( paste( \"human author mean shared count = \", humanAuthorsMeanSharedCount, sep = \"\" ) )\n",
    "message( \"\" )\n",
    "message( \"\" )\n",
    "\n",
    "message( \"====> HUMAN - authors with shared sources\" )\n",
    "message( paste( \"human shared count = \", humanAuthorsSharedCount, sep = \"\" ) )\n",
    "message( paste( \"human shared mean degree = \", humanAuthorsSharedMeanDegree, sep = \"\" ) )\n",
    "message( paste( \"human shared max degree = \", humanAuthorsSharedMaxDegree, sep = \"\" ) )\n",
    "message( paste( \"human shared mean tie weight GE0 = \", humanAuthorsSharedMeanTieWeightGE0, sep = \"\" ) )\n",
    "message( paste( \"human shared mean tie weight GE1 = \", humanAuthorsSharedMeanTieWeightGE1, sep = \"\" ) )\n",
    "message( paste( \"human shared max tie weight = \", humanAuthorsSharedMaxTieWeight, sep = \"\" ) )\n",
    "message( paste( \"human shared mean article count = \", humanAuthorsSharedMeanArticleCount, sep = \"\" ) )\n",
    "message( paste( \"human shared mean source count = \", humanAuthorsSharedMeanSourceCount, sep = \"\" ) )\n",
    "message( paste( \"human shared mean shared count = \", humanAuthorsSharedMeanSharedCount, sep = \"\" ) )\n",
    "message( \"regression results:\" )\n",
    "print( humanLmResults )\n",
    "message( \"\" )\n",
    "message( \"\" )\n",
    "\n",
    "message( \"====> AUTOMATED - all authors\" )\n",
    "message( paste( \"automated author count = \", automatedAuthorsCount, sep = \"\" ) )\n",
    "message( paste( \"automated author mean degree = \", automatedAuthorsMeanDegree, sep = \"\" ) )\n",
    "message( paste( \"automated author max degree = \", automatedAuthorsMaxDegree, sep = \"\" ) )\n",
    "message( paste( \"automated author mean tie weight GE0 = \", automatedAuthorsMeanTieWeightGE0, sep = \"\" ) )\n",
    "message( paste( \"automated author mean tie weight GE1 = \", automatedAuthorsMeanTieWeightGE1, sep = \"\" ) )\n",
    "message( paste( \"automated author max tie weight = \", automatedAuthorsMaxTieWeight, sep = \"\" ) )\n",
    "message( paste( \"automated author mean article count = \", automatedAuthorsMeanArticleCount, sep = \"\" ) )\n",
    "message( paste( \"automated author mean source count = \", automatedAuthorsMeanSourceCount, sep = \"\" ) )\n",
    "message( paste( \"automated author mean shared count = \", automatedAuthorsMeanSharedCount, sep = \"\" ) )\n",
    "message( \"\" )\n",
    "message( \"\" )\n",
    "\n",
    "message( \"====> AUTOMATED - authors with shared sources\" )\n",
    "message( paste( \"automated shared count = \", automatedAuthorsSharedCount, sep = \"\" ) )\n",
    "message( paste( \"automated shared mean degree = \", automatedAuthorsSharedMeanDegree, sep = \"\" ) )\n",
    "message( paste( \"automated shared max degree = \", automatedAuthorsSharedMaxDegree, sep = \"\" ) )\n",
    "message( paste( \"automated shared mean tie weight GE0 = \", automatedAuthorsSharedMeanTieWeightGE0, sep = \"\" ) )\n",
    "message( paste( \"automated shared mean tie weight GE1 = \", automatedAuthorsSharedMeanTieWeightGE1, sep = \"\" ) )\n",
    "message( paste( \"automated shared max tie weight = \", automatedAuthorsSharedMaxTieWeight, sep = \"\" ) )\n",
    "message( paste( \"automated shared mean article count = \", automatedAuthorsSharedMeanArticleCount, sep = \"\" ) )\n",
    "message( paste( \"automated shared mean source count = \", automatedAuthorsSharedMeanSourceCount, sep = \"\" ) )\n",
    "message( paste( \"automated shared mean shared count = \", automatedAuthorsSharedMeanSharedCount, sep = \"\" ) )\n",
    "message( \"regression results:\" )\n",
    "print( automatedLmResults )\n",
    "message( \"\" )\n",
    "message( \"\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save workspace image\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Save all the information in the current image, in case we need/want it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T22:08:20.001425Z",
     "start_time": "2018-04-17T22:08:18.592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output workspace to: statnet-grp_month.RData\n"
     ]
    }
   ],
   "source": [
    "# help( save.image )\n",
    "message( paste( \"Output workspace to: \", output_workspace_file_name, sep = \"\" ) )\n",
    "save.image( file = output_workspace_file_name )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
