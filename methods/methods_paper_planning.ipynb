{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**methods paper planning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li></ul></li><li><span><a href=\"#Analysis-steps\" data-toc-modified-id=\"Analysis-steps-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analysis steps</a></span></li><li><span><a href=\"#Reliability\" data-toc-modified-id=\"Reliability-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Reliability</a></span><ul class=\"toc-item\"><li><span><a href=\"#Coding-protocol-testing\" data-toc-modified-id=\"Coding-protocol-testing-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Coding protocol testing</a></span></li><li><span><a href=\"#Reliability-Data\" data-toc-modified-id=\"Reliability-Data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Reliability Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#prelim_month-reliability-sample-size\" data-toc-modified-id=\"prelim_month-reliability-sample-size-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>prelim_month reliability sample size</a></span></li><li><span><a href=\"#original-design-reliability-sample-size\" data-toc-modified-id=\"original-design-reliability-sample-size-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>original design reliability sample size</a></span></li></ul></li><li><span><a href=\"#Reliability-Analysis\" data-toc-modified-id=\"Reliability-Analysis-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Reliability Analysis</a></span></li><li><span><a href=\"#prelim_reliability_combined_human_final-results\" data-toc-modified-id=\"prelim_reliability_combined_human_final-results-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>prelim_reliability_combined_human_final results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Author-reliability\" data-toc-modified-id=\"Author-reliability-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Author reliability</a></span></li><li><span><a href=\"#Subject-reliability\" data-toc-modified-id=\"Subject-reliability-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Subject reliability</a></span></li></ul></li><li><span><a href=\"#prelim_reliability_combined_human-results\" data-toc-modified-id=\"prelim_reliability_combined_human-results-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>prelim_reliability_combined_human results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Author-reliability\" data-toc-modified-id=\"Author-reliability-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Author reliability</a></span></li><li><span><a href=\"#Subject-reliability\" data-toc-modified-id=\"Subject-reliability-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Subject reliability</a></span></li></ul></li></ul></li><li><span><a href=\"#Additional-analysis\" data-toc-modified-id=\"Additional-analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Additional analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#prelim_month-vs.-prelim_month_human\" data-toc-modified-id=\"prelim_month-vs.-prelim_month_human-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><code>prelim_month</code> vs. <code>prelim_month_human</code></a></span></li><li><span><a href=\"#Human-Precision-and-Recall---prelim_month_human\" data-toc-modified-id=\"Human-Precision-and-Recall---prelim_month_human-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Human Precision and Recall - <code>prelim_month_human</code></a></span></li><li><span><a href=\"#Calculate-reliability-numbers-for-prelim_month...\" data-toc-modified-id=\"Calculate-reliability-numbers-for-prelim_month...-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Calculate reliability numbers for <code>prelim_month</code>...</a></span></li><li><span><a href=\"#...-and-calculate-reliability-numbers-for-prelim_month_human\" data-toc-modified-id=\"...-and-calculate-reliability-numbers-for-prelim_month_human-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>... and calculate reliability numbers for <code>prelim_month_human</code></a></span></li><li><span><a href=\"#Network-Analysis\" data-toc-modified-id=\"Network-Analysis-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Network Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notes\" data-toc-modified-id=\"Notes-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Notes</a></span></li><li><span><a href=\"#network-analysis-TODO\" data-toc-modified-id=\"network-analysis-TODO-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>network analysis TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#network-analysis-TODO---DEFERRED\" data-toc-modified-id=\"network-analysis-TODO---DEFERRED-4.5.2.1\"><span class=\"toc-item-num\">4.5.2.1&nbsp;&nbsp;</span>network analysis TODO - DEFERRED</a></span></li><li><span><a href=\"#network-analysis-TODO---DONE\" data-toc-modified-id=\"network-analysis-TODO---DONE-4.5.2.2\"><span class=\"toc-item-num\">4.5.2.2&nbsp;&nbsp;</span>network analysis TODO - DONE</a></span></li></ul></li></ul></li><li><span><a href=\"#Combine-results-into-spreadsheet\" data-toc-modified-id=\"Combine-results-into-spreadsheet-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Combine results into spreadsheet</a></span></li></ul></li><li><span><a href=\"#Preparation-for-automated-assessment\" data-toc-modified-id=\"Preparation-for-automated-assessment-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preparation for automated assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Single-name-removal\" data-toc-modified-id=\"Single-name-removal-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Single name removal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notes\" data-toc-modified-id=\"Notes-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Notes</a></span></li><li><span><a href=\"#Error-detail\" data-toc-modified-id=\"Error-detail-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Error detail</a></span></li></ul></li><li><span><a href=\"#Evaluating-disagreements\" data-toc-modified-id=\"Evaluating-disagreements-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Evaluating disagreements</a></span></li></ul></li><li><span><a href=\"#Paper-Edits\" data-toc-modified-id=\"Paper-Edits-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Paper Edits</a></span></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>TODO</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T03:42:55.221143Z",
     "start_time": "2018-08-16T03:42:55.215308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported at 2018-08-16 03:42:55.217351\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import six\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon sourcenet\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"sourcenet (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T03:42:58.935422Z",
     "start_time": "2018-08-16T03:42:58.922731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/msu_phd_work/methods'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T03:43:03.105326Z",
     "start_time": "2018-08-16T03:43:02.329123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathanmorgan/.virtualenvs/research/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "/home/jonathanmorgan/.virtualenvs/research/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2018-08-16 03:43:03.103065\n"
     ]
    }
   ],
   "source": [
    "%run django_init.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T03:43:06.460871Z",
     "start_time": "2018-08-16T03:43:06.456879Z"
    }
   },
   "outputs": [],
   "source": [
    "# django imports\n",
    "from sourcenet_analysis.models import Reliability_Names_Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis steps\n",
    "\n",
    "In the methods folder, here is the order the code was run for analysis:\n",
    "\n",
    "- 1) `data_creation` (results in `data` folder)\n",
    "- 2) `evaluate_disagreements` - correct human coding when they are wrong in a disagreement, to create \"ground truth\".\n",
    "- 3) `precision_recall`\n",
    "- 4) `reliability`\n",
    "- 5) `network_analysis`\n",
    "- 6) `results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- Characterize data used in reliability test (# articles, from both Detroit News and Grand Rapids Press, etc.).\n",
    "- describe reliability results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding protocol testing\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Outline in voodoopad - \"`Dropbox/academia/MSU/program_stuff/voodoopad/phd.vpdoc`\", note \"Prelim - Notes\".\n",
    "\n",
    "Trained on 7 samples of 10 articles each. For each training set, users coded, I reviewed coding and updated protocol, then we reviewed problems and changes to protocol.  After 7 sets, did formal reliability test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability Data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Article traits:\n",
    "\n",
    "- 87 total local news articles implemented by a staff writer (either full-time or contractor), published in a local news section (outline criteria for GRP and TDN), and across two different papers, to just confirm that sourcing is standard across publications.\n",
    "- Sample size:\n",
    "\n",
    "    - minimum required sample size was 47 articles (46.79)\n",
    "    - Equation: $$n = \\frac {(N-1)(SE)^2 + PQN}{(N-1)(SE)^2 + PQ}$$\n",
    "    \n",
    "        - WHERE:\n",
    "        \n",
    "            - N = total number of items to be coded\n",
    "            - SE = standard error at desired confidence level ( $$SE = \\frac{confidence interval}{Z-score}$$\n",
    "            - P = population level of agreement\n",
    "            - Q = 1 - P\n",
    "    \n",
    "    - from:\n",
    "\n",
    "        - Lacy, S., and D. Riffe. “Sampling Error and Selecting Intercoder Reliability Samples for Nominal Content Categories.” JOURNALISM AND MASS COMMUNICATION QUARTERLY, no. 4 (Winter 1996): 963. https://doi.org/10.1177/107769909607300414.\n",
    "        - Riffe, Daniel, Stephen Lacy, and Frederick G. Fico. Analyzing Media Messages: Using Quantitative Content Analysis in Research, Second Edition. 2nd ed. LEA Communications Series. Mahwah, New Jersey: Lawrence Erlbaum Associates, Inc., 2005.\n",
    "\n",
    "- Articles in the reliability test sample:\n",
    "\n",
    "    - need a minimum of 47 articles given math above (calculated in detail below).  Ended up including 87 articles in reliability sample to make sure we would be OK if we needed to code many more by hand if automated coder was no good. \n",
    "    - 27 articles from the Detroit News (tags \"minnesota1-20160409\", \"minnesota2-20160409\", and \"minnesota3-20160409\" each reference these same 27 articles)\n",
    "    - 60 Grand Rapids Press articles are tagged \"prelim_reliability_test\".\n",
    "    \n",
    "- number of people detected?\n",
    "- anything else?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$n = \\frac {(N-1)(SE)^2 + PQN}{(N-1)(SE)^2 + PQ}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prelim_month reliability sample size\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T03:24:50.357838Z",
     "start_time": "2018-08-17T03:24:50.351963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_month reliability minimum sample size: 46.78486279032644\n"
     ]
    }
   ],
   "source": [
    "# ==> prelim_month\n",
    "\n",
    "# init variables\n",
    "n = 441\n",
    "p = 0.95\n",
    "ci = 0.05\n",
    "z = 1.64\n",
    "se = ci / z\n",
    "q = 1 - p\n",
    "sample_size = None\n",
    "\n",
    "# calculate sample_size\n",
    "n_minus_1 = n - 1\n",
    "se_squared = se ** 2\n",
    "p_times_q = p * q\n",
    "n_minus_1_times_se_squared = n_minus_1 * se_squared\n",
    "numerator = n_minus_1_times_se_squared + ( p_times_q * n )\n",
    "denominator = n_minus_1_times_se_squared + p_times_q\n",
    "sample_size = numerator / denominator\n",
    "\n",
    "print( \"prelim_month reliability minimum sample size: {}\".format( sample_size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for \"`grp_month`\":\n",
    "\n",
    "    - P = 95% agreement in the population\n",
    "    - seeking a 95% confidence level (confidence interval p = 0.05)\n",
    "    - Z-Score for p = 0.05: 1.64\n",
    "    - N = content universe = 1 month of local news articles by staff writers in Grand Rapids Press = 441 articles.\n",
    "    - SE = 0.05 / 1.64 = 0.0304878\n",
    "    - so:\n",
    "\n",
    "$$n = \\frac {(441-1)(0.0304878)^2 + (0.95 * 0.05 * 441)}{(441-1)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(440)(0.0304878)^2 + (0.95 * 0.05 * 441)}{(440)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(440)(0.0009295059) + (0.95 * 0.05 * 441)}{(440)(0.0009295059) + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4089826 + (0.95 * 0.05 * 441)}{0.4089826 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4089826 + (0.0475 * 441)}{0.4089826 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {0.4089826 + 20.9475}{0.4089826 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {21.35648}{0.4564826}$$\n",
    "\n",
    "$$n = 46.78487$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T03:33:09.168976Z",
     "start_time": "2018-08-17T03:33:09.162915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_month reliability minimum sample size: 52.10239738854489\n"
     ]
    }
   ],
   "source": [
    "# ==> prelim_month\n",
    "\n",
    "# init variables\n",
    "n = 1000000000\n",
    "p = 0.95\n",
    "ci = 0.05\n",
    "z = 1.64\n",
    "se = ci / z\n",
    "q = 1 - p\n",
    "sample_size = None\n",
    "\n",
    "# calculate sample_size\n",
    "n_minus_1 = n - 1\n",
    "se_squared = se ** 2\n",
    "p_times_q = p * q\n",
    "n_minus_1_times_se_squared = n_minus_1 * se_squared\n",
    "numerator = n_minus_1_times_se_squared + ( p_times_q * n )\n",
    "denominator = n_minus_1_times_se_squared + p_times_q\n",
    "sample_size = numerator / denominator\n",
    "\n",
    "print( \"prelim_month reliability minimum sample size: {}\".format( sample_size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original design reliability sample size\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T03:24:32.060576Z",
     "start_time": "2018-08-17T03:24:32.054487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sample reliability minimum sample size: 46.9929438797392\n"
     ]
    }
   ],
   "source": [
    "# ==> original sample\n",
    "\n",
    "# init variables\n",
    "n = 461\n",
    "p = 0.95\n",
    "ci = 0.05\n",
    "z = 1.64\n",
    "se = ci / z\n",
    "q = 1 - p\n",
    "sample_size = None\n",
    "\n",
    "# calculate sample_size\n",
    "n_minus_1 = n - 1\n",
    "se_squared = se ** 2\n",
    "p_times_q = p * q\n",
    "n_minus_1_times_se_squared = n_minus_1 * se_squared\n",
    "numerator = n_minus_1_times_se_squared + ( p_times_q * n )\n",
    "denominator = n_minus_1_times_se_squared + p_times_q\n",
    "sample_size = numerator / denominator\n",
    "\n",
    "print( \"original sample reliability minimum sample size: {}\".format( sample_size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for original sample:\n",
    "\n",
    "    - P = 95% agreement in the population\n",
    "    - seeking a 95% confidence level (confidence interval p = 0.05)\n",
    "    - Z-Score for p = 0.05: 1.64\n",
    "    - N = content universe = 2 weeks of local news articles by staff writers in each of the Grand Rapids Press and Detroit News = 461 articles.\n",
    "    - SE = 0.05 / 1.64 = 0.0304878\n",
    "    - so:\n",
    "\n",
    "$$n = \\frac {(461-1)(0.0304878)^2 + (0.95 * 0.05 * 461)}{(461-1)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(460)(0.0304878)^2 + (0.95 * 0.05 * 461)}{(460)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(460)(0.0009295059) + (0.95 * 0.05 * 461)}{(460)(0.0009295059) + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4275727 + (0.95 * 0.05 * 461)}{0.4275727 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4275727 + (0.0475 * 461)}{0.4275727 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {0.4275727 + 21.8975}{0.4275727 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {22.32507}{0.4750727}$$\n",
    "\n",
    "$$n = 46.99295$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T03:43:09.459252Z",
     "start_time": "2018-08-16T03:43:09.455155Z"
    }
   },
   "outputs": [],
   "source": [
    "from sourcenet.models import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T03:45:16.135849Z",
     "start_time": "2018-08-16T03:45:16.129621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_reliability_test count = 60\n"
     ]
    }
   ],
   "source": [
    "# how many articles in \"prelim_reliability_test\"?\n",
    "article_qs = Article.objects.filter( tags__name__in = [ \"prelim_reliability_test\" ] )\n",
    "reliability_sample_count = article_qs.count()\n",
    "\n",
    "print( \"prelim_reliability_test count = {}\".format( reliability_sample_count ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability Analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Path to Dropbox folder that holds PDF and Excel file output of reliability numbers:\n",
    "\n",
    "- Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data\n",
    "\n",
    "To view results: [https://research.local/research/sourcenet/analysis/reliability/names/results/view](https://research.local/research/sourcenet/analysis/reliability/names/results/view)\n",
    "\n",
    "The human-only results (the ones I will write about) are results with labels:\n",
    "\n",
    "- \"`prelim_reliability_combined_human_final`\"\n",
    "\n",
    "    - this is latest code, regenerated recently.  Is identical to the results from the old code (numbers from 2016.08.27):\n",
    "    \n",
    "        - `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/2016.08.27-reliability-prelim_reliability_combined_human.pdf`\n",
    "        - `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/2016.08.27-reliability-prelim_reliability_combined_human.xlsx`\n",
    "\n",
    "- and \"`prelim_reliability_combined_human`\"\n",
    "\n",
    "    - this is old code results stored in the database.\n",
    "    - compare to \"final\" calculated with rewritten code - numbers should be identical.\n",
    "    - results in database for \"`prelim_reliability_combined_human`\", shown below, are not identical - but,  the results stored in Dropbox (see above) are identical to those for \"`prelim_reliability_combined_human_final`\".  Very strange.\n",
    "    \n",
    "Since they match original numbers, and since they are lower, I'll just use \"`prelim_reliability_combined_human_final`\".\n",
    "\n",
    "Code to actually calculate reliability numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start to support python 3:\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "\n",
    "#==============================================================================#\n",
    "# ! imports\n",
    "#==============================================================================#\n",
    "\n",
    "# grouped by functional area, then alphabetical order by package, then\n",
    "#     alphabetical order by name of thing being imported.\n",
    "\n",
    "# sourcenet_analysis imports\n",
    "from sourcenet_analysis.reliability.reliability_names_analyzer import ReliabilityNamesAnalyzer\n",
    "\n",
    "#==============================================================================#\n",
    "# ! logic\n",
    "#==============================================================================#\n",
    "\n",
    "# declare variables\n",
    "my_analysis_instance = None\n",
    "label = \"\"\n",
    "indices_to_process = -1\n",
    "result_status = \"\"\n",
    "\n",
    "# make reliability instance\n",
    "my_analysis_instance = ReliabilityNamesAnalyzer()\n",
    "\n",
    "# database connection information - 2 options...  Enter it here:\n",
    "#my_analysis_instance.db_username = \"\"\n",
    "#my_analysis_instance.db_password = \"\"\n",
    "#my_analysis_instance.db_host = \"localhost\"\n",
    "#my_analysis_instance.db_name = \"sourcenet\"\n",
    "\n",
    "# Or set up the following properties in Django_Config, inside the django admins.\n",
    "#     All have application of: \"sourcenet-db-admin\":\n",
    "#     - db_username\n",
    "#     - db_password\n",
    "#     - db_host\n",
    "#     - db_port\n",
    "#     - db_name\n",
    "\n",
    "# run the analyze method, see what happens.\n",
    "#label = \"prelim_reliability_test\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_combined_human\"\n",
    "#indices_to_process = 3\n",
    "#label = \"name_data_test_combined_human\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_combined_human_final\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_combined_all\"\n",
    "#indices_to_process = 4\n",
    "#label = \"prelim_reliability_combined_all_final\"\n",
    "#indices_to_process = 4\n",
    "#label = \"prelim_reliability_test_human\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_test_all\"\n",
    "#indices_to_process = 4\n",
    "label = \"prelim_month\"\n",
    "indices_to_process = 2\n",
    "result_status = my_analysis_instance.analyze_reliability_names( label, indices_to_process )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prelim_reliability_combined_human_final results\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Results:\n",
    "\n",
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "\n",
    "    <h3>Author reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "        </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human_final</td>\n",
    "                <td>10</td>\n",
    "                <td>1</td>\n",
    "                <td>2</td>\n",
    "                <td></td>\n",
    "                <td></td>\n",
    "                <td>98</td>\n",
    "                <td>0.9795918367</td>\n",
    "                <td>-0.0051546392</td>\n",
    "                <td>0.9727891156</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9795918367</td>\n",
    "                <td>0.9791722296</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96</td>\n",
    "                <td>0.9795918367</td>\n",
    "                <td>-0.0051546392</td>\n",
    "                <td>0.9782312925</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human_final</td>\n",
    "                <td>11</td>\n",
    "                <td>1</td>\n",
    "                <td>3</td>\n",
    "                <td></td>\n",
    "                <td>10</td>\n",
    "                <td>98</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9863945578</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.9895861148</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9891156463</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human_final</td>\n",
    "                <td>12</td>\n",
    "                <td>2</td>\n",
    "                <td>3</td>\n",
    "                <td></td>\n",
    "                <td>10</td>\n",
    "                <td>98</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9863945578</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.9895816637</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9891156463</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td><strong>Averages:</strong></td>\n",
    "                <td></td> <!-- results_instance.id -->\n",
    "                <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder1.id -->\n",
    "                <td></td> <!-- results_instance.coder2.id -->\n",
    "                <td>98</td>\n",
    "                <td>0.9863945578333333333333333333</td>\n",
    "                <td>-0.001718213066666666666666666667</td>\n",
    "                <td>0.9818594104</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9863945578333333333333333333</td>\n",
    "                <td>0.9861133360333333333333333333</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96.66666666666666666666666667</td>\n",
    "                <td>0.9863945578333333333333333333</td>\n",
    "                <td>-0.001718213066666666666666666667</td>\n",
    "                <td>0.9854875283666666666666666667</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96.66666666666666666666666667</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "    </table>\n",
    "\n",
    "    <hr />\n",
    "\n",
    "    <h3>Subject reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "            <th>1st graf %</th>\n",
    "            <th>1st graf A</th>\n",
    "            <th>1st index %</th>\n",
    "            <th>1st index A</th>\n",
    "            <th>org hash %</th>\n",
    "            <th>org hash A</th>\n",
    "\n",
    "        </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human_final</td>\n",
    "                <td>10</td>\n",
    "                <td>1</td>\n",
    "                <td>2</td>\n",
    "                <td></td>\n",
    "                <td></td>\n",
    "                <td>399</td>\n",
    "                <td>0.9122807018</td>\n",
    "                <td>0.1407669798</td>\n",
    "                <td>0.8830409357</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9122807018</td>\n",
    "                <td>0.9118944818</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>360</td>\n",
    "                <td>0.8922305764</td>\n",
    "                <td>0.7955934892</td>\n",
    "                <td>0.8850459482</td>\n",
    "                <td>0.9777777778</td>\n",
    "                <td>0.9523699116</td>\n",
    "                <td>0.9750000000</td>\n",
    "                <td>360</td>\n",
    "                <td>0.5363408521</td>\n",
    "                <td>0.9573273382</td>\n",
    "                <td>0.5087719298</td>\n",
    "                <td>0.9101064582</td>\n",
    "                <td>0.5839598997</td>\n",
    "                <td>0.5626481371</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human_final</td>\n",
    "                <td>11</td>\n",
    "                <td>1</td>\n",
    "                <td>3</td>\n",
    "                <td></td>\n",
    "                <td>10</td>\n",
    "                <td>399</td>\n",
    "                <td>0.8972431078</td>\n",
    "                <td>0.2505447123</td>\n",
    "                <td>0.8629908104</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.8972431078</td>\n",
    "                <td>0.8965318523</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>349</td>\n",
    "                <td>0.8746867168</td>\n",
    "                <td>0.7694145966</td>\n",
    "                <td>0.8663324979</td>\n",
    "                <td>0.9742120344</td>\n",
    "                <td>0.9446517907</td>\n",
    "                <td>0.9709885387</td>\n",
    "                <td>349</td>\n",
    "                <td>0.4962406015</td>\n",
    "                <td>0.9117737368</td>\n",
    "                <td>0.4736842105</td>\n",
    "                <td>0.8747093023</td>\n",
    "                <td>0.5664160401</td>\n",
    "                <td>0.5380809123</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human_final</td>\n",
    "                <td>12</td>\n",
    "                <td>2</td>\n",
    "                <td>3</td>\n",
    "                <td></td>\n",
    "                <td>10</td>\n",
    "                <td>399</td>\n",
    "                <td>0.9147869674</td>\n",
    "                <td>0.1062664908</td>\n",
    "                <td>0.8863826232</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9147869674</td>\n",
    "                <td>0.9144471807</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>362</td>\n",
    "                <td>0.8972431078</td>\n",
    "                <td>0.8055310893</td>\n",
    "                <td>0.8903926483</td>\n",
    "                <td>0.9806629834</td>\n",
    "                <td>0.9591258208</td>\n",
    "                <td>0.9782458564</td>\n",
    "                <td>362</td>\n",
    "                <td>0.5037593985</td>\n",
    "                <td>0.9086158161</td>\n",
    "                <td>0.4812030075</td>\n",
    "                <td>0.8724327241</td>\n",
    "                <td>0.5664160401</td>\n",
    "                <td>0.5514299936</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td><strong>Averages:</strong></td>\n",
    "                <td></td> <!-- results_instance.id -->\n",
    "                <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder1.id -->\n",
    "                <td></td> <!-- results_instance.coder2.id -->\n",
    "                <td>399</td>\n",
    "                <td>0.9081035923333333333333333333</td>\n",
    "                <td>0.1658593943</td>\n",
    "                <td>0.8774714564333333333333333333</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9081035923333333333333333333</td>\n",
    "                <td>0.9076245049333333333333333333</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>357</td>\n",
    "                <td>0.8880534670</td>\n",
    "                <td>0.7901797250333333333333333333</td>\n",
    "                <td>0.8805903648</td>\n",
    "                <td>0.9775509318666666666666666667</td>\n",
    "                <td>0.9520491743666666666666666667</td>\n",
    "                <td>0.9747447983666666666666666667</td>\n",
    "                <td>357</td>\n",
    "                <td>0.5121136173666666666666666667</td>\n",
    "                <td>0.9259056303666666666666666667</td>\n",
    "                <td>0.4878863826</td>\n",
    "                <td>0.8857494948666666666666666667</td>\n",
    "                <td>0.5722639933</td>\n",
    "                <td>0.5507196810</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "    </table>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prelim_reliability_combined_human results\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Results:\n",
    "\n",
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "\n",
    "    <h3>Author reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "        </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human</td>\n",
    "                <td>37</td>\n",
    "                <td>1</td>\n",
    "                <td>2</td>\n",
    "                <td></td>\n",
    "                <td>9</td>\n",
    "                <td>98</td>\n",
    "                <td>0.9795918367</td>\n",
    "                <td>-0.0051546392</td>\n",
    "                <td>0.9727891156</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9795918367</td>\n",
    "                <td>0.9791722296</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96</td>\n",
    "                <td>0.9795918367</td>\n",
    "                <td>-0.0051546392</td>\n",
    "                <td>0.9782312925</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human</td>\n",
    "                <td>38</td>\n",
    "                <td>1</td>\n",
    "                <td>3</td>\n",
    "                <td></td>\n",
    "                <td></td>\n",
    "                <td>98</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9863945578</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.9895861148</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9891156463</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human</td>\n",
    "                <td>39</td>\n",
    "                <td>2</td>\n",
    "                <td>3</td>\n",
    "                <td>9</td>\n",
    "                <td></td>\n",
    "                <td>98</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9863945578</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.9895816637</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "                <td>0.9897959184</td>\n",
    "                <td>0.0000000000</td>\n",
    "                <td>0.9891156463</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>97</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td><strong>Averages:</strong></td>\n",
    "                <td></td> <!-- results_instance.id -->\n",
    "                <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder1.id -->\n",
    "                <td></td> <!-- results_instance.coder2.id -->\n",
    "                <td>98</td>\n",
    "                <td>0.9863945578333333333333333333</td>\n",
    "                <td>-0.001718213066666666666666666667</td>\n",
    "                <td>0.9818594104</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9863945578333333333333333333</td>\n",
    "                <td>0.9861133360333333333333333333</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96.66666666666666666666666667</td>\n",
    "                <td>0.9863945578333333333333333333</td>\n",
    "                <td>-0.001718213066666666666666666667</td>\n",
    "                <td>0.9854875283666666666666666667</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>96.66666666666666666666666667</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "    </table>\n",
    "\n",
    "    <hr />\n",
    "\n",
    "    <h3>Subject reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "            <th>1st graf %</th>\n",
    "            <th>1st graf A</th>\n",
    "            <th>1st index %</th>\n",
    "            <th>1st index A</th>\n",
    "            <th>org hash %</th>\n",
    "            <th>org hash A</th>\n",
    "\n",
    "        </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human</td>\n",
    "                <td>37</td>\n",
    "                <td>1</td>\n",
    "                <td>2</td>\n",
    "                <td></td>\n",
    "                <td>9</td>\n",
    "                <td>398</td>\n",
    "                <td>0.9170854271</td>\n",
    "                <td>0.1524794056</td>\n",
    "                <td>0.8894472362</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9145728643</td>\n",
    "                <td>0.9142174364</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>0.9972299169</td>\n",
    "                <td>0.9972247563</td>\n",
    "                <td>361</td>\n",
    "                <td>0.8969849246</td>\n",
    "                <td>0.8038230285</td>\n",
    "                <td>0.8901172529</td>\n",
    "                <td>0.9778393352</td>\n",
    "                <td>0.9524469067</td>\n",
    "                <td>0.9750692521</td>\n",
    "                <td>361</td>\n",
    "                <td>0.5402010050</td>\n",
    "                <td>0.9575247587</td>\n",
    "                <td>0.5125628141</td>\n",
    "                <td>0.9105087189</td>\n",
    "                <td>0.5854271357</td>\n",
    "                <td>0.5645628699</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human</td>\n",
    "                <td>38</td>\n",
    "                <td>1</td>\n",
    "                <td>3</td>\n",
    "                <td></td>\n",
    "                <td></td>\n",
    "                <td>398</td>\n",
    "                <td>0.9020100503</td>\n",
    "                <td>0.2639413147</td>\n",
    "                <td>0.8693467337</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.8994974874</td>\n",
    "                <td>0.8988353338</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>0.9971428571</td>\n",
    "                <td>0.9971374163</td>\n",
    "                <td>350</td>\n",
    "                <td>0.8793969849</td>\n",
    "                <td>0.7772888300</td>\n",
    "                <td>0.8713567839</td>\n",
    "                <td>0.9742857143</td>\n",
    "                <td>0.9447435683</td>\n",
    "                <td>0.9710714286</td>\n",
    "                <td>350</td>\n",
    "                <td>0.5000000000</td>\n",
    "                <td>0.9121951220</td>\n",
    "                <td>0.4773869347</td>\n",
    "                <td>0.8752880184</td>\n",
    "                <td>0.5703517588</td>\n",
    "                <td>0.5427100012</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td>prelim_reliability_combined_human</td>\n",
    "                <td>39</td>\n",
    "                <td>2</td>\n",
    "                <td>3</td>\n",
    "                <td>9</td>\n",
    "                <td></td>\n",
    "                <td>398</td>\n",
    "                <td>0.9145728643</td>\n",
    "                <td>0.0615886682</td>\n",
    "                <td>0.8860971524</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9145728643</td>\n",
    "                <td>0.9142514529</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>1.0000000000</td>\n",
    "                <td>1.0000000000</td>\n",
    "                <td>362</td>\n",
    "                <td>0.8969849246</td>\n",
    "                <td>0.8042530448</td>\n",
    "                <td>0.8901172529</td>\n",
    "                <td>0.9806629834</td>\n",
    "                <td>0.9591258208</td>\n",
    "                <td>0.9782458564</td>\n",
    "                <td>362</td>\n",
    "                <td>0.5050251256</td>\n",
    "                <td>0.9086158161</td>\n",
    "                <td>0.4824120603</td>\n",
    "                <td>0.8724327241</td>\n",
    "                <td>0.5653266332</td>\n",
    "                <td>0.5506229232</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            <tr>\n",
    "                <td><strong>Averages:</strong></td>\n",
    "                <td></td> <!-- results_instance.id -->\n",
    "                <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "                <td></td> <!-- results_instance.coder1.id -->\n",
    "                <td></td> <!-- results_instance.coder2.id -->\n",
    "                <td>398</td>\n",
    "                <td>0.9112227805666666666666666667</td>\n",
    "                <td>0.1593364628333333333333333333</td>\n",
    "                <td>0.8816303741</td>\n",
    "                <!-- Lookup -->\n",
    "                <td>0.9095477386666666666666666667</td>\n",
    "                <td>0.9091014077</td>\n",
    "                <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "                <td>0.9981242580</td>\n",
    "                <td>0.9981207242</td>\n",
    "                <td>357.6666666666666666666666667</td>\n",
    "                <td>0.8911222780333333333333333333</td>\n",
    "                <td>0.7951216344333333333333333333</td>\n",
    "                <td>0.8838637632333333333333333333</td>\n",
    "                <td>0.9775960109666666666666666667</td>\n",
    "                <td>0.9521054319333333333333333333</td>\n",
    "                <td>0.9747955123666666666666666667</td>\n",
    "                <td>357.6666666666666666666666667</td>\n",
    "                <td>0.5150753768666666666666666667</td>\n",
    "                <td>0.9261118989333333333333333333</td>\n",
    "                <td>0.4907872697</td>\n",
    "                <td>0.8860764871333333333333333333</td>\n",
    "                <td>0.5737018425666666666666666667</td>\n",
    "                <td>0.5526319314333333333333333333</td>\n",
    "            </tr>\n",
    "\n",
    "\n",
    "\n",
    "    </table>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `prelim_month` vs. `prelim_month_human`\n",
    "\n",
    "- `prelim_month` - Reliability_Names data with label `prelim_month` where coder 1 is \"ground truth\" (corrected human coding) and coder 2 is data created by OpenCalais.\n",
    "- `prelim_month_human` - Reliability_Names data with label `prelim_month_human` where coder 1 is \"ground truth\" (corrected human coding) and coder 2 is uncorrected human coding (for comparison)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Precision and Recall - `prelim_month_human`\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Calculate precision and recall for humans versus ground truth - set it up so that coder 1 is as it was for computer (ground_truth having precedence) and then set up coder 2 up the same way, but without ground_truth...\n",
    "\n",
    "- Jupyter notebooks:\n",
    "\n",
    "    - Create Reliability_Names data where coder 1 is ground truth, coder 2 is human coding without corrections for ground truth: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/precision_recall/prelim_month-create_Reliability_Names-ground_truth_vs_human.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/precision_recall/prelim_month-create_Reliability_Names-ground_truth_vs_human.ipynb)\n",
    "\n",
    "- results are in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/precision_and_recall/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate reliability numbers for `prelim_month`...\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Run the reliability calculations for prelim_month just to get lookup assessment (since it is not classification, precision and recall make no sense).\n",
    "\n",
    "- Jupyter notebook: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/reliability/prelim_month-reliability.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/reliability/prelim_month-reliability.ipynb)\n",
    "- results are in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/prelim_month-reliability_results.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and calculate reliability numbers for `prelim_month_human`\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Run the reliability calculations for prelim_month_human just to get lookup assessment (since it is not classification, precision and recall make no sense).\n",
    "\n",
    "- Jupyter notebook of agreement between corrected and uncorrected human coding: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/reliability/prelim_month_human-reliability.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/reliability/prelim_month_human-reliability.ipynb)\n",
    "\n",
    "- results are in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/prelim_month_human-reliability_results.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Generate some basic network statistics from the ground truth and automated attribution data, characterize and compare using QAP (including explaining substantial limitations of this given sparseness of networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- Master network analysis notebook: [network_analysis/2017.11.14-work_log-prelim-network_analysis.ipynb](network_analysis/2017.11.14-work_log-prelim-network_analysis.ipynb)\n",
    "\n",
    "    - contains all notebooks and additional explanation of what each contains (now consolidated into this notebook, below).\n",
    "\n",
    "Basic Plan:\n",
    "\n",
    "- find code used to derive network information last time. - Evernote Network Analysis Notes: [https://www.evernote.com/shard/s101/nl/11379781/ef9db83f-5fd3-4bd2-bdd7-1407e2c01f9c/](https://www.evernote.com/shard/s101/nl/11379781/ef9db83f-5fd3-4bd2-bdd7-1407e2c01f9c/)\n",
    "- run it again on full month of data, rather than just a week.\n",
    "- examine traits of ground_truth and automated networks\n",
    "\n",
    "    - compare with QAP.\n",
    "    - look at average degree of reporters\n",
    "    - look at average degree, density, etc.\n",
    "\n",
    "Notebooks:\n",
    "\n",
    "- [network_analysis/methods-network_analysis-create_network_data.ipynb](network_analysis/methods-network_analysis-create_network_data.ipynb) - original Python network analysis, run for original coders, then week and month of new data - per-author source, shared, and article counts; and means of each across all authors.  Includes:\n",
    "\n",
    "    - Section 2 (2.1-2.3): Deriving network data\n",
    "\n",
    "        - 2.1 - for original week (12/06/2009-12/12/2009), original coders, networks output include:\n",
    "        \n",
    "            - combined human\n",
    "            - automated.\n",
    "        \n",
    "        - 2.2 - original week (12/06/2009-12/12/2009), new coders, networks output include:\n",
    "        \n",
    "            - ground_truth (combined human plus corrected, corrected first, then human)\n",
    "            - automated.\n",
    "            \n",
    "        - 2.3 - entire month (12/01/2009-12/31/2009).\n",
    "        \n",
    "            - includes all people for the entire month, networks for:\n",
    "            \n",
    "                - 2.3.1  nodes - full month; ties - full month\n",
    "                - 2.3.2  nodes - full month; ties - week 1 (2009-12-06 to 2009-12-12)\n",
    "                - 2.3.3  nodes - full month; ties - week 2 (2009-12-13 to 2009-12-19)\n",
    "                - 2.3.4  nodes - full month; ties - week 3 (2009-12-20 to 2009-12-26)\n",
    "                \n",
    "    - Section 3:\n",
    "    \n",
    "        - 3.1 - reproduce original analysis, but with the new data.  Success.  Modest.\n",
    "        - 3.2 - Overview of the rest of the notebooks, consolidated below.\n",
    "\n",
    "- [network_analysis/igraph](network_analysis/igraph) - R igraph analysis\n",
    "\n",
    "    - original notebook: [network_analysis/igraph/2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb](network_analysis/igraph/2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb) - basic network analysis of new month and week (nodes for all people from entire month, ties for whole month, then just first week) using igraph.  Broke out into one file per time period, and separate R data files:\n",
    "\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-full_month.ipynb](network_analysis/igraph/R-igraph-grp_month-full_month.ipynb) - full month of data, and data file `igraph-grp_month-full_month.RData`.\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-week_1.ipynb](network_analysis/igraph/R-igraph-grp_month-week_1.ipynb) - full week 1 of three (2009-12-06 to 2009-12-12), and data file `igraph-grp_month-week_1.RData`.\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-week_2.ipynb](network_analysis/igraph/R-igraph-grp_month-week_2.ipynb) - full week 2 of three (2009-12-13 to 2009-12-19), and data file `igraph-grp_month-week_2.RData`.\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-week_3.ipynb](network_analysis/igraph/R-igraph-grp_month-week_3.ipynb) - full week 3 of three (2009-12-20 to 2009-12-26), and data file `igraph-grp_month-week_3.RData`.\n",
    "        \n",
    "- [network_analysis/statnet](network_analysis/statnet) - R statnet analysis\n",
    "\n",
    "    - original notebook: [network_analysis/statnet/2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb](network_analysis/statnet/2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb) - basic network analysis of new month and week (nodes for all people from entire month, ties for whole month, then just first week) using statnet.  Broke out into one notebook per time period, and one notebook for comparisons across time periods.  All data still stored in a single RData file (`statnet-grp_month.RData`).\n",
    "    - new notebooks:\n",
    "\n",
    "        - [network_analysis/statnet/R-statnet-grp_month-full_month.ipynb](network_analysis/statnet/R-statnet-grp_month-full_month.ipynb) - full month of data.\n",
    "        - [network_analysis/statnet/R-statnet-grp_month-week_1.ipynb](network_analysis/statnet/R-statnet-grp_month-week_1.ipynb) - full week 1 of three (2009-12-06 to 2009-12-12).\n",
    "        - [network_analysis/statnet/R-statnet-grp_month-week_2.ipynb](network_analysis/statnet/R-statnet-grp_month-week_2.ipynb) - full week 2 of three (2009-12-13 to 2009-12-19).\n",
    "        - [network_analysis/statnet/R-statnet-grp_month-week_3.ipynb](network_analysis/statnet/R-statnet-grp_month-week_3.ipynb) - full week 3 of three (2009-12-20 to 2009-12-26).\n",
    "        - [network_analysis/statnet/R-statnet-grp_month-compare_graphs.ipynb](network_analysis/statnet/R-statnet-grp_month-week_3.ipynb) - QAP comparisons, both automated-to-automated and human-to-human, of:\n",
    "        \n",
    "            - week 1 to week 2\n",
    "            - week 1 to week 3\n",
    "            - week 2 to week 3\n",
    "            - full month to week 1\n",
    "            - full month to week 2\n",
    "            - full month to week 3\n",
    "            \n",
    "- [network_analysis/author_info](network_analysis/author_info) - Information on the authors in the data set and their network characteristics.\n",
    "\n",
    "    - original notebooks:\n",
    "\n",
    "        - [network_analysis/author_info/2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb](network_analysis/author_info/2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for full month of data.\n",
    "        - [network_analysis/author_info/2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb](network_analysis/author_info/2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for single week of data.\n",
    "        \n",
    "    - new notebooks:\n",
    "    \n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-full_month.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-full_month.r.ipynb)\n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-week_1.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-week_1.r.ipynb)\n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-week_2.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-week_2.r.ipynb)\n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-week_3.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-week_3.r.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network analysis TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### network analysis TODO - DEFERRED\n",
    "\n",
    "TODO: update all below so they include the two additional weeks.\n",
    "\n",
    "- [network_analysis/statnet/2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb](network_analysis/statnet/2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb) - statnet analysis when network is converted to either be 0 or 1 weight, where all weights greater than 1 are converted to 1.  No real difference here, so ignoring in paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T05:07:59.731310Z",
     "start_time": "2017-10-31T05:07:59.720302Z"
    }
   },
   "source": [
    "#### network analysis TODO - DONE\n",
    "\n",
    "DONE:\n",
    "\n",
    "- updated forms `ArticleSelectForm` and `PersonSelectForm` to include field for \"`coder_id_priority_list`\"/\"`person_coder_id_priority_list`\".\n",
    "- created method NetworkOutput.get_coder_id_list() that:\n",
    "\n",
    "    - knows about the two places where coder IDs can be set.\n",
    "    - if prioritzed list is present:\n",
    "    \n",
    "        - starts with the priotized list\n",
    "        - appends coders from other field who aren't already in the list to the end of it.\n",
    "        - stores the list in an instance variable inside the object so it can be retrieved easily.\n",
    "        \n",
    "- updated NetworkOutput.create_query_set() to use get_coder_id_list() method.\n",
    "- need to update NetworkOutput.remove_duplicate_article_data() - it is where we choose which Article_Data to omit per article where there are duplicates.  Need to go with order of list.  Might already do this...  Nope.\n",
    "\n",
    "    - get prioritized list.\n",
    "    - for first instance of Article_Data for article, store it (related by id, or unique_identifier?)\n",
    "    - on subsequent Article_Data for article, get index of coder for existing and new.\n",
    "    - Whichever has lower index you keep.\n",
    "    - **_Need to test_**\n",
    "\n",
    "        - person-coded articles:\n",
    "        \n",
    "            - 1) output networks from initial prelim (12/6/2009-12/13/2009).  Make sure they are the same now as they were then.\n",
    "            - 2) keep article specs the same, but change person lookup to use ordered ID list.  See if this is the same as the files in 1 (might not be).  If not, count rows, find and compare rows for some users to see how different they are.  Hopefully same contents, different order...?\n",
    "            - 3) then, switch the article specs to use ordered list and put person specs back to old way, see how this file compares to the others.\n",
    "            - look for differences in:\n",
    "            \n",
    "                - number of rows\n",
    "                - contents of rows\n",
    "                - IDs of those included\n",
    "            \n",
    "        - automated coder:\n",
    "\n",
    "            - 1) output networks from initial prelim (12/6/2009-12/13/2009).  Make sure they are the same now as they were then.\n",
    "            - 2) keep article specs the same, but change person lookup to use ordered ID list.  See if this is the same as the files in 1 (might not be).  If not, count rows, find and compare rows for some users to see how different they are.  Hopefully same contents, different order.\n",
    "            - 3) then, switch the article specs to use ordered list, see how this file compares to the others.\n",
    "\n",
    "        - as long as the tests above check out, then try out the whole month, with prioritized coder list.\n",
    "\n",
    "- need to update NetworkDataOutput and children?  Looks like no - all comes down to the remove_duplicate_article_data().\n",
    "- figure out how to run `sourcenet/R/sna/sna_author_info.r`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine results into spreadsheet\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Next step is to pull analysis together in an Excel spreadsheet like I did last time.\n",
    "\n",
    "For old results and more detailed notes on implementation and interpretation, see `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/archive/prelim_v1-2015/analysis_summary.xlsx`.\n",
    "\n",
    "New analysis file: `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/analysis_summary-2017.12.24.xlsx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- In general, revised procedure:\n",
    "\n",
    "    - content analysis protocol to create testing data.\n",
    "    \n",
    "        - create and test protocol.\n",
    "        - report reliability.\n",
    "        - use protocol to create testing data.\n",
    "\n",
    "    - have automated tool code same articles.\n",
    "    - for all disagreements, evaluate manually, correct the testing data when it has an error.\n",
    "    - derive confusion matrix data by comparing automated coding to testing data, assess quality of automated coding using precision and recall (etc.).\n",
    "    \n",
    "- so, won't look as much at comparing humans to computer in terms of agreement for content analysis:\n",
    "\n",
    "    - describe protocol development and reliability assessment\n",
    "    - describe process of turning the resulting data into testing data (don't use \"ground truth\").  Some discussion here of ratio of human error to machine error, proportion of human to machine errors, overall number of errors compared to all decisions, etc.\n",
    "    - outline precision and recall and evaluate.\n",
    "\n",
    "- Removed tabs:\n",
    "\n",
    "    - `agree-prelim_reliability` - old reliability coding between 2 human coders.\n",
    "    - `agree-prelim_network-mentions` - agreement between traits of network data derived from human and computer code - tie weights.\n",
    "    - `values-detect_names` - survey of name detection descriptives - counts across all names of how many were detected and not per coder.  Will see if we need to derive this again for new coders.  Probably won't.\n",
    "    - `values-count_ties` - descriptives and comparison of ties weights between human and computer, to look at something like precision and recall (confusion matrix), but just comparing human and computer, not treating human as ground truth.  No need for this with precision and recall stats.\n",
    "    - `counts_per_person` - not sure what this is...\n",
    "    - `disagreements` - similar to `values-count_ties`, but higher-level analysis.  Will have to create new disagreement information from results of disagreement analysis in creating evaluation data.\n",
    "\n",
    "Updated spreadsheet:\n",
    "\n",
    "- New analysis file: `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/analysis_summary-2017.12.24.xlsx`\n",
    "- Agreement results:\n",
    "\n",
    "    - tabs \"`CA-reliability-author`\" and \"`CA-reliability-subject`\" are derived from work labeled \"`prelim_reliability_combined`\" = articles from both Grand Rapids Press and Detroit News, to minimally test cross-paper use of protocol.\n",
    "    \n",
    "        - pulled from spreadsheet: `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/2016.08.27-reliability-prelim_reliability_combined_human.xlsx`\n",
    "    \n",
    "    - old results have \"mentions\".  Mentions are weights from network data back when I derived it and stored it in a table of my own design (\"`sourcenet_analysis_reliability_ties`\"), rather than outputting in formats readable by SNA packages.  Omitting this in favor of precision and recall and network statistics.\n",
    "\n",
    "- Network results:\n",
    "\n",
    "    - Main sources:\n",
    "    \n",
    "        - [2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb](2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb) - basic network analysis of new month and week using statnet.\n",
    "        - [2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb](2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for full month of data.\n",
    "        - [2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb](2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for single week of data.\n",
    "        - [2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb](2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb) - basic network analysis of new month and week using igraph.\n",
    "            \n",
    "            - for mean transitivity of nodes, look at igraph notebook.\n",
    "\n",
    "    - Other:\n",
    "    \n",
    "        - [2017.11.14-work_log-prelim-network_analysis.ipynb](2017.11.14-work_log-prelim-network_analysis.ipynb) - original Python network analysis, run for original coders, then week and month of new data - per-author source, shared, and article counts; and means of each across all authors.\n",
    "        - [2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb](2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb) - statnet analysis when network is converted to either be 0 or 1 weight, where all weights greater than 1 are converted to 1.  No real difference here, so ignoring in paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for automated assessment\n",
    "\n",
    "- Bacl to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In preparation for using the human coding as a standard against which data created with automated tool is assessed, I performed a couple of cleaning steps:\n",
    "\n",
    "- **[Single name removal](#Single-name-removal)** - In CA protocol, we ignored people who were referred to only with a single name part, to avoid potential for ambiguity when assigning a last name.  When preparing for assessment, I first went through and removed all people who were captured with only a single name by the automated tool.\n",
    "- **[Evaluating disagreements](#Evaluating-disagreements)** - In order to make the human-created data as good a reflection of correct data as possible, I then reviewed each disagreement between the human and computer manually.  I assessed the disagreement based on the content analysis protocol and on having been a news writer and editor.  If the human coding was in error, I fixed the human coding (and the content analysis protocol, if it turned out to have been a problem with the protocol)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single name removal\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In CA protocol, we ignored people who were referred to only with a single name part, to avoid potential for ambiguity when assigning a last name.  Removed all instances where person was only ever referenced using a single-word (really single-part - only first name, mostly) name, to remove potential source of ambiguity.  \n",
    "\n",
    "Example:  \"Joe Smith's wife Sandy\" - could assume her name is Sandy Smith, but it could be something else.  For this study, removing that potential ambiguity by discarding instances where a given person's full name is never used.\n",
    "\n",
    "- Notebook with aggregated information on what was removed, and notes: [2017.06.01-work_log-prelim_month-remove_single_names.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/2017.06.01-work_log-prelim_month-remove_single_names.ipynb)\n",
    "- Exceptions:\n",
    "\n",
    "    - If the single-name was an error on the part of either computer or human, where one party detected the full name but the other incorrectly detected just a single name, the Reliability_Names records for the two were merged so the same person being detected was captured, and then the error is subsumed in the agreement and precision-recall analysis.\n",
    "    - Since, post-reliability, the human coding is being used as the standard against which the quality of the automated coding is compared, if the human made an error, the coding was corrected to prepare for assessing the automated coding (see non-destructive method for correcting erroneous human coding below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- removed single names because of potential for ambiguity\n",
    "- Usually means you lose spouses and children of subjects who are not subjects themselves.\n",
    "- 143 instances of single name references removed from coding data.\n",
    "- 3 instances were automated errors that needed to be merged with a more accurate human-coded record.\n",
    "- 1 instance was human error, and was corrected.\n",
    "- Types of single-named entities:\n",
    "\n",
    "    - most were family members of subjects not relevant to the story (spouses, children, parents, grandparents, etc.).\n",
    "    - biblical characters (Mary, Jesus)\n",
    "    - famous people (Obama)\n",
    "    - one homeless man who wouldn't give last name (article [23982](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23982)).\n",
    "    - a few were misspellings (so a wrong spelling of a last name only used once, without first name).\n",
    "    - pets\n",
    "    - out and out automated errors - place name (Example: Saigon - Article [23921](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23921)), parts of song titles (\"Twinkle\" - Article [23491](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23491)), planet names (\"Saturn\" -  Article [23559](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23559)), or a part of a business name were detected as a person name.\n",
    "\n",
    "- Of 143 single names removed from analysis data, 15 instances were out-and-out errors (89.5% correct):\n",
    "\n",
    "    - 3 partial-name detects that had to be merged.\n",
    "    - 3 references to named pet chickens (Article [23065](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23065) - Betty, Mabel, and Violet).\n",
    "    - 9 errors where a place name (Example: Saigon - Article [23921](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23921)), parts of song titles (\"Twinkle\" - Article [23491](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23491)), planet names (\"Saturn\" -  Article [23559](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23559)), or a part of a business name were detected as a person name.\n",
    "\n",
    "- Only noted one instance where the single-name person was quoted (\"Linda\") - Article [23223](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23223) | Article_Data 3212 | 12096 (AS) - Linda ( id = 2911; capture_method = OpenCalais_REST_API_v2 ) (quoted; individual) ==> name: Linda |\n",
    "\n",
    "    - Actually was quoted, but just a one-word name, no explicit mention of last name. Need to keep track of relationship to others in story (\"wife of X\").\n",
    "\n",
    "- Assessment - OpenCalais is actually quite good at identifying single name-part references to people, for the most part.  It even sometimes tacked on a last name based on the context in the article.  But, most of the time it did not.  Appears to be built to know of this potential, but tuned to only take action when it is certain.  Not built to assume name relationships implied by things like \"survived by\" or \"Smith's children X, Y, and Z\".  This is something that could be leveraged in a post-processing step if single names were left in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error detail\n",
    "\n",
    "Errors:\n",
    "\n",
    "- Article 21116\n",
    "\n",
    "    - RANDOM - \"More...\"\n",
    "    - Paragraph 12: More than 600 works of art were added to the museum's collection under her leadership, most notably Ellsworth Kelly's \"Blue White,\" a 25-foot- tall wall sculpture that was commissioned in 2006 for the museum's entry pavilion.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Article [21116](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=21116) | 11288 (AS) - More ( id = 2817; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: More\n",
    "    \n",
    "- Article 22765\n",
    "\n",
    "    - PLACE NAME\n",
    "    - Paragraph 8: Gavin Orchards has started selling farm-direct apples to Grand Rapids and Fruitport schools. The biggest challenge is the time it takes to deliver low-volume orders, said Mike Gavin, who runs the 240-acre farm near Coopersville with his brother, Dave. \n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Article [22765](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=22765) | 11806 (AS) - Coopersville ( id = 2869; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Coopersville\n",
    "    \n",
    "- Article 23055\n",
    "\n",
    "    - PLACE NAME\n",
    "    - Paragraph 2: While they are not disputing the state DHS' recent decision to reassign longtime Kent County DHS Director Andy Zylstra from Grand Rapids to Lansing, legislators are asking state officials to improve their communications with local workers, state Rep. Robert Dean said.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Article [23055](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23055) | 12014 (AS) - Lansing ( id = 2902; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Lansing\n",
    "    \n",
    "- Article 23491\n",
    "\n",
    "    - SONG LYRIC\n",
    "    - Paragraph 39: \"As the program was wrapping up and the kids were leaving the stage, one of the 2-year-olds ran up to the microphone and started singing 'Twinkle, twinkle Christmas star ...' to the tune of 'Twinkle, Twinkle Little Star.' It was so funny and cute.\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Portion of Song title: | 10448 | Article [23491](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23491) | Article_Data [3249](http://research.local/research/sourcenet/article/article_data/view/?article_id=23491&article_data_id_select=3249) | 12299 (AS) - Twinkle ( id = 2938; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Twinkle |\n",
    "    \n",
    "- Article 23559\n",
    "\n",
    "    - PLANET NAME\n",
    "    - Paragraph 10: \"Three appear: Saturn joins Mars and Venus in March so, through spring and most of summer, there will be three naked eye planets in the evening sky. They will be joined briefly by elusive Mercury in April.\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - \"Saturn joins...\" - | 7961 | Article [23559](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23559) | Article_Data [3254](http://research.local/research/sourcenet/article/article_data/view/?article_id=23559&article_data_id_select=3254) | 12315 (AS) - Saturn ( id = 2940; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Saturn |\n",
    "\n",
    "- Article 23631\n",
    "\n",
    "    - SCHOOL NAME - \"Madonna\"\n",
    "    - Paragraph 6: \"The school is planning a tribute during halftime of the first night's Hope game Tuesday against Madonna. There will also be other activities open to former players and family members connected to DeVette.\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8120 | Article [23631](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23631) | Article_Data [3274](http://research.local/research/sourcenet/article/article_data/view/?article_id=23631&article_data_id_select=3274) | 12404 (AS) - Madonna ( id = 2946; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Madonna |\n",
    "\n",
    "- Article 23631\n",
    "\n",
    "    - SCHOOL NAME\n",
    "    - Paragraph 7: \"We have a dinner scheduled in his honor and memory during the first game of the tournament (between Davenport and Grace Bible),\" Van Wieren said. \"We had people that had a hard time getting to the funeral, so this will be a way that people attending can share memories of Russ.\" \n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8119 | Article [23631](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23631) | Article_Data [3274](http://research.local/research/sourcenet/article/article_data/view/?article_id=23631&article_data_id_select=3274) | 12405 (AS) - Davenport ( id = 2947; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Davenport |\n",
    "\n",
    "- Article 23921\n",
    "\n",
    "    - PLACE\n",
    "    - Paragraph 6: It was 1975 when he fled his native Saigon as it fell to the North Vietnamese Army.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8981 | Article [23921](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23921) | Article_Data [3283](http://research.local/research/sourcenet/article/article_data/view/?article_id=23921&article_data_id_select=3283) | 12444 (AS) - Saigon ( id = 2952; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Saigon |\n",
    "    \n",
    "- Article 23974\n",
    "\n",
    "    - BUSINESS NAME - Detected part of business name as person.\n",
    "    - Paragraph 14: Trevor Ditmar, a two-year employee at Smitty's Specialty Beverage, 1489 Lake Drive SE, said customers are vowing to quit in increasing numbers due to the product change.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8185 | Article [23974](http://research.local/research/sourcenet/article/article_data/view_with_text/?article_id=23974) | Article_Data [3292](http://research.local/research/sourcenet/article/article_data/view/?article_id=23974&article_data_id_select=3292) | 12492 (AS) - Smitty ( id = 2789; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Smitty |\n",
    "    \n",
    "- Article 21080\n",
    "\n",
    "    - MISSPELLING\n",
    "    - Paragraph 21: \"Ben was in middle school when his father was in Desert Storm, and we'd watch the developments on TV,\" Patti Vab Syzkle said. \"He'd say, 'It's OK, Mom. It's just a skirmish.'\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Made new person: 11246 (AS) - Syzkle, Patti ( id = 2813; capture_method = OpenCalais_REST_API_v2 ) (quoted; individual) ==> name: Patti Vab Syzkle\n",
    "    - Should have mapped to: 11248 (AS) - Van Syzkle, Patti ( id = 1750; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Patti Van Syzkle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating disagreements\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Moved to [2018.02.09-prelim-disagreement_analysis.ipynb](/user/jonathanmorgan/notebooks/work/django/research/work/msu_phd_work/methods/2018.02.09-prelim-disagreement_analysis.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Edits\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- path to paper: `Dropbox/academia/MSU/program_stuff/prelim_paper/paper/2017.10.30/Morgan-Prelim.docx`\n",
    "- cut the shit out of lit. review.\n",
    "- update methods\n",
    "\n",
    "    - generate content analysis data.\n",
    "    - assess reliability.\n",
    "    - generate attribution data using OpenCalais API.\n",
    "    - evaluate disagreements to establish ground truth (fix human errors).\n",
    "    - calculate precision and recall.\n",
    "    - examine resulting networks.\n",
    "\n",
    "- update results\n",
    "- update discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- brief lit. review of hybrid content analysis coding, so I can mention a few in lit. review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE:\n",
    "\n",
    "- make sure the network code can deal with multiple coders, and can prioritize in an order I specify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "689px",
    "left": "0px",
    "right": "1118px",
    "top": "111px",
    "width": "322px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
