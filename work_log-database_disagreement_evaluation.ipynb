{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# work log - database disagreement evaluation\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Setup](#Setup)\n",
    "\n",
    "    - [Setup - Imports](#Setup---Imports)\n",
    "    - [Setup - Initialize Django](#Setup---Initialize-Django)\n",
    "    - [Setup - Database](#Setup---Database)\n",
    "\n",
    "- [Work](#Work)\n",
    "- [TODO](#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import six\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings.\n",
    "\n",
    "You need to have installed your virtualenv with django as a kernel, then select that kernel for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run django_init.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import any `sourcenet` or `sourcenet_analysis` models or classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sourcenet_analysis models.\n",
    "from sourcenet_analysis.models import Reliability_Names\n",
    "from sourcenet_analysis.models import Reliability_Names_Evaluation\n",
    "\n",
    "print( \"sourcenet and sourcenet_analysis packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Database\n",
    "\n",
    "- Return to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==> PostgreSQL (psycopg2) example:\n",
    "db_type = \"postgresql\"\n",
    "db_username = \"<username>\"\n",
    "db_password = \"<password>\"\n",
    "db_host = \"research.local\"\n",
    "db_port = \"5432\"\n",
    "db_database = \"sourcenet\"\n",
    "db_encoding = \"utf8\"\n",
    "\n",
    "# create psycopg2 connection to PostgreSQL using connection variables defined above.\n",
    "pgsql_connection = psycopg2.connect( host = db_host, port = db_port, database = db_database, user = db_username, password = db_password )\n",
    "\n",
    "print( \"psycopg2 database connection created at \" + str( datetime.datetime.now() ) + \": \" + str( pgsql_connection ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create psycopg2 cursor using pgsql_connection.\n",
    "pgsql_cursor = pgsql_connection.cursor( cursor_factory = psycopg2.extras.DictCursor )\n",
    "\n",
    "print( \"psycopg2 database cursor created at \" + str( datetime.datetime.now() ) + \": \" + str( pgsql_cursor ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rollback transaction:\n",
    "pgsql_connection.rollback()\n",
    "\n",
    "print( \"connection transaction rolled back at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work\n",
    "\n",
    "- Back to [Table of contents](#Table-of-contents)\n",
    "\n",
    "Read and parse delimited file of Reliability_Names rows we've arleady processed.  Create database row for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONSTANTS-ish\n",
    "\n",
    "# header indexes:\n",
    "#ID | Name | Article | Article_Data_List | Status | Error? (SHB = Should Have Been)| Notes\n",
    "INDEX_RELIABILITY_NAMES_ID = 0\n",
    "INDEX_PERSON_NAME = 1\n",
    "INDEX_ARTICLE_INFO = 2\n",
    "INDEX_ARTICLE_DATA_LIST = 3\n",
    "INDEX_STATUS = 4\n",
    "INDEX_STATUS_MESSAGE = 5\n",
    "INDEX_NOTES = 6\n",
    "\n",
    "# declare variables\n",
    "delimited_file_path = \"\"\n",
    "delimited_file = None\n",
    "delimited_reader = None\n",
    "current_row = None\n",
    "rn_instance = None\n",
    "rne_instance = None\n",
    "row_counter = -1\n",
    "manual_counter = -1\n",
    "\n",
    "# declare variables - column values\n",
    "reliability_names_id = -1\n",
    "person_name = \"\"\n",
    "article_info = \"\"\n",
    "article_data_info = \"\"\n",
    "status = \"\"\n",
    "status_message = \"\"\n",
    "notes = \"\"\n",
    "label = \"\"\n",
    "\n",
    "# declare varibles - create by hand\n",
    "work_string = \"\"\n",
    "work_list = []\n",
    "article_id = -1\n",
    "article_data_list = []\n",
    "article_data_item = None\n",
    "article_data_id_list = []\n",
    "article_data_id = -1\n",
    "\n",
    "# file path?\n",
    "delimited_file_path = \"reliability_names_evaluations.txt\"\n",
    "\n",
    "# read file\n",
    "with open( delimited_file_path ) as delimited_file:\n",
    "    \n",
    "    # CSV reader\n",
    "    delimited_reader = csv.reader( delimited_file, delimiter='|' )\n",
    "\n",
    "    # first row is column names\n",
    "    current_row = six.next( delimited_reader )\n",
    "    \n",
    "    # init shared values\n",
    "    label = \"prelim_month\"\n",
    "    \n",
    "    # now loop over rest of rows.\n",
    "    row_counter = 0\n",
    "    manual_counter = 0\n",
    "    for current_row in delimited_reader:\n",
    "        \n",
    "        # increment row counter\n",
    "        row_counter += 1\n",
    "        \n",
    "        # print out the row.\n",
    "        column_count = len( current_row )\n",
    "        print( \"==> row column count = \" + str( column_count ) + \" ( \" + str( column_count == 7 ) + \" ) - row: \" + \",\".join( current_row ) )\n",
    "        \n",
    "        # get values\n",
    "        reliability_names_id = current_row[ INDEX_RELIABILITY_NAMES_ID ].strip()\n",
    "        reliability_names_id = int( reliability_names_id )\n",
    "        person_name = current_row[ INDEX_PERSON_NAME ].strip()\n",
    "        article_info = current_row[ INDEX_ARTICLE_INFO ].strip()\n",
    "        article_data_info = current_row[ INDEX_ARTICLE_DATA_LIST ].strip()\n",
    "        status = current_row[ INDEX_STATUS ].strip()\n",
    "        status_message = current_row[ INDEX_STATUS_MESSAGE ].strip()\n",
    "        notes = current_row[ INDEX_NOTES ].strip()\n",
    "        \n",
    "        # parse out additional data.\n",
    "        \n",
    "        # ==> article_id\n",
    "        # - Article [20645](http://research.local/sourcenet/sourcenet/article/article_data/view_with_text/?article_id=20645)\n",
    "\n",
    "        # split first on the leading square bracket around the ID.\n",
    "        work_list = article_info.split( \"[\" )\n",
    "\n",
    "        # then split item 2 (index 1) on right square bracket.\n",
    "        work_string = work_list[ 1 ]\n",
    "        work_list = work_string.split( \"]\" )\n",
    "        article_id = work_list[ 0 ].strip()\n",
    "        article_id = int( article_id )\n",
    "        print( \"----> article_id = \" + str( article_id ) )\n",
    "\n",
    "        # ==> article_data_id\n",
    "        # - Article_Data: [2322 (coder=8)](http://research.local/sourcenet/sourcenet/article/article_data/view/?article_id=20645&article_data_id_select=2322); [2984 (coder=2)](http://research.local/sourcenet/sourcenet/article/article_data/view/?article_id=20645&article_data_id_select=2984)\n",
    "\n",
    "        # split first on semi-colon\n",
    "        article_data_list = article_data_info.split( \";\" )\n",
    "        article_data_id_list = []\n",
    "        for article_data_item in article_data_list:\n",
    "\n",
    "            # use work_list to isolate the ID - first, split on left square bracket.\n",
    "            work_list = article_data_item.split( \"[\" )\n",
    "\n",
    "            # get 2nd thing in list.\n",
    "            work_string = work_list[ 1 ]\n",
    "\n",
    "            # split then on left paren\n",
    "            work_list = work_string.split( \"(\" )\n",
    "\n",
    "            # get the first item in list.\n",
    "            article_data_id = work_list[ 0 ].strip()\n",
    "            article_data_id = int( article_data_id )\n",
    "\n",
    "            # add to list.\n",
    "            article_data_id_list.append( article_data_id )\n",
    "\n",
    "            print( \"----> article_data_id = \" + str( article_data_id ) )\n",
    "\n",
    "        #-- END loop over article data items. --#\n",
    "        \n",
    "        print( \"----> status = \" + status )\n",
    "        \n",
    "        # call Reliability_Names_Evaluation.create_from_reliability_data()\n",
    "        rne_instance = Reliability_Names_Evaluation.create_from_reliability_data(\n",
    "                           reliability_names_id,\n",
    "                           label_IN = label,\n",
    "                           person_name_IN = person_name,\n",
    "                           article_id_IN = article_id,\n",
    "                           article_data_id_list_IN = article_data_id_list,\n",
    "                           status_IN = status,\n",
    "                           status_message_IN = status_message,\n",
    "                           notes_IN = notes\n",
    "                       )\n",
    "        \n",
    "    #-- END loop over rows. --#\n",
    "    \n",
    "#-- END with open( delimited_file_path ) --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DROP all rows from the table.\n",
    "table_name = \"sourcenet_analysis_reliability_names_evaluation\"\n",
    "#sql_string = \"DELETE FROM \" + table_name\n",
    "#sql_string += \";\"\n",
    "\n",
    "# run it.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "\n",
    "# loop over records in table.\n",
    "evaluation_qs = None\n",
    "evaluation_qs = Reliability_Names_Evaluation.objects.all()\n",
    "eval_record = None\n",
    "record_count = 0\n",
    "for eval_record in evaluation_qs:\n",
    "    \n",
    "    # counter\n",
    "    record_count += 1\n",
    "    \n",
    "    # output row details:\n",
    "    print( eval_record )\n",
    "    \n",
    "    # delete.\n",
    "    eval_record.delete()\n",
    "    \n",
    "#-- END loop over records. --#\n",
    "\n",
    "print( \"deleted \" + str( record_count ) + \" records.\" )\n",
    "\n",
    "# reset the unique ID sequences to 0.\n",
    "sequence_name_list = []\n",
    "sequence_name_list.append( table_name + \"_id_seq\" )\n",
    "sequence_name_list.append( \"sourcenet_analysis_reliability_names_evaluation_article__id_seq\" )\n",
    "sequence_name_list.append( \"sourcenet_analysis_reliability_names_evaluation_persons_id_seq\" )\n",
    "\n",
    "for sequence_name in sequence_name_list:\n",
    "    \n",
    "    sql_string = \"ALTER SEQUENCE \" + sequence_name + \" RESTART WITH 1;\"\n",
    "    print( \"==> \" + sql_string )\n",
    "    pgsql_cursor.execute( sql_string )\n",
    "    \n",
    "#-- END loop over sequence names to reset. --#\n",
    "\n",
    "# commit\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"reset table \" + table_name + \" at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- // check if Reliability_Names exists.  If not, parse Article, Article_Data, Persons, and make a row by hand...\n",
    "- // wipe table and re-run.\n",
    "- // go through and update by hand the flags for the other lists.\n",
    "- // make a list of those that were merged.\n",
    "- update with single name removals from \"`remove_single_names-work_log.ipynb`\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sourcenet (Python 3)",
   "language": "python",
   "name": "sourcenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
